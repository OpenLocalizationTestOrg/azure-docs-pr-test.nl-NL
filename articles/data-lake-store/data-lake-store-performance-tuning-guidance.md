---
title: Azure Data Lake Store-prestaties afstemmen richtlijnen | Microsoft Docs
description: Azure Data Lake Store-prestaties afstemmen richtlijnen
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: cgronlun
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 06/30/2017
ms.author: stewu
ms.openlocfilehash: e7ea83465328bd4c7479dec4093cd94700463854
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 07/11/2017
---
# <a name="tuning-azure-data-lake-store-for-performance"></a><span data-ttu-id="bd704-103">Azure Data Lake Store voor prestaties afstemmen</span><span class="sxs-lookup"><span data-stu-id="bd704-103">Tuning Azure Data Lake Store for performance</span></span>

<span data-ttu-id="bd704-104">Data Lake Store ondersteunt hoge gegevensdoorvoer voor i/o-intensieve analyse en gegevensverplaatsing.</span><span class="sxs-lookup"><span data-stu-id="bd704-104">Data Lake Store supports high-throughput for I/O intensive analytics and data movement.</span></span>  <span data-ttu-id="bd704-105">In Azure Data Lake Store is het belangrijk om de beste prestaties met behulp van alle beschikbare doorvoer – de hoeveelheid gegevens die kunnen worden gelezen of geschreven per seconde –.</span><span class="sxs-lookup"><span data-stu-id="bd704-105">In Azure Data Lake Store, using all available throughput – the amount of data that can be read or written per second – is important to get the best performance.</span></span>  <span data-ttu-id="bd704-106">Dit wordt bereikt door het uitvoeren van zoveel leest en schrijft parallel mogelijk.</span><span class="sxs-lookup"><span data-stu-id="bd704-106">This is achieved by performing as many reads and writes in parallel as possible.</span></span>

![Data Lake Store-prestaties](./media/data-lake-store-performance-tuning-guidance/throughput.png)

<span data-ttu-id="bd704-108">Azure Data Lake Store kunnen worden geschaald om de benodigde doorvoer voor alle analytics scenario.</span><span class="sxs-lookup"><span data-stu-id="bd704-108">Azure Data Lake Store can scale to provide the necessary throughput for all analytics scenario.</span></span> <span data-ttu-id="bd704-109">Een Azure Data Lake Store-account biedt standaard automatisch voldoende doorvoer om te voldoen aan de behoeften van een categorie gebruiksvoorbeelden.</span><span class="sxs-lookup"><span data-stu-id="bd704-109">By default, an Azure Data Lake Store account provides automatically enough throughput to meet the needs of a broad category of use cases.</span></span> <span data-ttu-id="bd704-110">Voor de gevallen waarin klanten wordt uitgevoerd in de standaardlimiet worden ADLS-account geconfigureerd om meer doorvoer contact opnemen met Microsoft ondersteuning.</span><span class="sxs-lookup"><span data-stu-id="bd704-110">For the cases where customers run into the default limit, the ADLS account can be configured to provide more throughput by contacting Microsoft support.</span></span>

## <a name="data-ingestion"></a><span data-ttu-id="bd704-111">Gegevensopname</span><span class="sxs-lookup"><span data-stu-id="bd704-111">Data ingestion</span></span>

<span data-ttu-id="bd704-112">Bij het ophalen van gegevens uit een bronsysteem naar ADLS, is het belangrijk in de bron hardware, de netwerkhardware bron en de netwerkverbinding met ADLS het knelpunt kunnen worden.</span><span class="sxs-lookup"><span data-stu-id="bd704-112">When ingesting data from a source system to ADLS, it is important to consider that the source hardware, source network hardware, and network connectivity to ADLS can be the bottleneck.</span></span>  

![Data Lake Store-prestaties](./media/data-lake-store-performance-tuning-guidance/bottleneck.png)

<span data-ttu-id="bd704-114">Het is belangrijk om ervoor te zorgen dat de gegevensverplaatsing wordt niet beïnvloed door deze factoren.</span><span class="sxs-lookup"><span data-stu-id="bd704-114">It is important to ensure that the data movement is not affected by these factors.</span></span>

### <a name="source-hardware"></a><span data-ttu-id="bd704-115">Bron-Hardware</span><span class="sxs-lookup"><span data-stu-id="bd704-115">Source Hardware</span></span>

<span data-ttu-id="bd704-116">Of u van lokale machines of virtuele machines in Azure gebruikmaakt, moet u zorgvuldig de juiste hardware.</span><span class="sxs-lookup"><span data-stu-id="bd704-116">Whether you are using on-premises machines or VMs in Azure, you should carefully select the appropriate hardware.</span></span> <span data-ttu-id="bd704-117">HDD's van SSD's liever voor bron schijfhardware, en kies vervolgens schijfhardware met sneller aandrijfassen.</span><span class="sxs-lookup"><span data-stu-id="bd704-117">For Source Disk Hardware, prefer SSDs to HDDs and pick disk hardware with faster spindles.</span></span> <span data-ttu-id="bd704-118">Voor bron netwerkhardware, gebruikt u de snelste NIC's mogelijk.</span><span class="sxs-lookup"><span data-stu-id="bd704-118">For Source Network Hardware, use the fastest NICs possible.</span></span>  <span data-ttu-id="bd704-119">In Azure, wordt aangeraden Azure D14 virtuele machines die op de juiste wijze krachtige schijf- en netwerkhardware.</span><span class="sxs-lookup"><span data-stu-id="bd704-119">On Azure, we recommend Azure D14 VMs which have the appropriately powerful disk and networking hardware.</span></span>

### <a name="network-connectivity-to-azure-data-lake-store"></a><span data-ttu-id="bd704-120">Netwerkverbindingen met Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="bd704-120">Network Connectivity to Azure Data Lake Store</span></span>

<span data-ttu-id="bd704-121">Het knelpunt kan soms worden door de netwerkverbinding tussen de brongegevens en Azure Data Lake store.</span><span class="sxs-lookup"><span data-stu-id="bd704-121">The network connectivity between your source data and Azure Data Lake store can sometimes be the bottleneck.</span></span> <span data-ttu-id="bd704-122">Wanneer de brongegevens On-Premises is, overweeg het gebruik van een specifieke verbinding met [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span><span class="sxs-lookup"><span data-stu-id="bd704-122">When your source data is On-Premises, consider using a dedicated link with [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span></span> <span data-ttu-id="bd704-123">Als de brongegevens in Azure, de prestaties worden aanbevolen als de gegevens zich in dezelfde Azure-regio als de Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="bd704-123">If your source data is in Azure, the performance will be best when the data is in the same Azure region as the Data Lake Store.</span></span>

### <a name="configure-data-ingestion-tools-for-maximum-parallelization"></a><span data-ttu-id="bd704-124">Gegevensopname hulpprogramma's voor maximale garandeert configureren</span><span class="sxs-lookup"><span data-stu-id="bd704-124">Configure Data Ingestion tools for maximum parallelization</span></span>

<span data-ttu-id="bd704-125">Nadat u de bron-hardware hebt opgelost en network connectivity knelpunten hierboven, bent u klaar voor het configureren van de opname-hulpprogramma's.</span><span class="sxs-lookup"><span data-stu-id="bd704-125">Once you have addressed the source hardware and network connectivity bottlenecks above, you are ready to configure your ingestion tools.</span></span> <span data-ttu-id="bd704-126">De volgende tabel bevat een overzicht van de instellingen voor de sleutel voor verschillende hulpprogramma's van populaire opname en biedt uitgebreide prestaties artikelen voor hen afstemmen.</span><span class="sxs-lookup"><span data-stu-id="bd704-126">The following table summarizes the key settings for several popular ingestion tools and provides in-depth performance tuning articles for them.</span></span>  <span data-ttu-id="bd704-127">Voor meer informatie over het hulpprogramma dat moet worden gebruikt voor uw scenario, gaat u naar dit [artikel](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span><span class="sxs-lookup"><span data-stu-id="bd704-127">To learn more about which tool to use for your scenario, visit this [article](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span></span>

| <span data-ttu-id="bd704-128">Hulpprogramma</span><span class="sxs-lookup"><span data-stu-id="bd704-128">Tool</span></span>               | <span data-ttu-id="bd704-129">Instellingen</span><span class="sxs-lookup"><span data-stu-id="bd704-129">Settings</span></span>     | <span data-ttu-id="bd704-130">Meer informatie</span><span class="sxs-lookup"><span data-stu-id="bd704-130">More Details</span></span>                                                                 |
|--------------------|------------------------------------------------------|------------------------------|
| <span data-ttu-id="bd704-131">PowerShell</span><span class="sxs-lookup"><span data-stu-id="bd704-131">Powershell</span></span>       | <span data-ttu-id="bd704-132">PerFileThreadCount, ConcurrentFileCount</span><span class="sxs-lookup"><span data-stu-id="bd704-132">PerFileThreadCount, ConcurrentFileCount</span></span> |  [<span data-ttu-id="bd704-133">Koppeling</span><span class="sxs-lookup"><span data-stu-id="bd704-133">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-get-started-powershell#performance-guidance-while-using-powershell)   |
| <span data-ttu-id="bd704-134">AdlCopy</span><span class="sxs-lookup"><span data-stu-id="bd704-134">AdlCopy</span></span>    | <span data-ttu-id="bd704-135">Azure Data Lake Analytics-eenheden</span><span class="sxs-lookup"><span data-stu-id="bd704-135">Azure Data Lake Analytics units</span></span>  |   [<span data-ttu-id="bd704-136">Koppeling</span><span class="sxs-lookup"><span data-stu-id="bd704-136">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob#performance-considerations-for-using-adlcopy)         |
| <span data-ttu-id="bd704-137">DistCp</span><span class="sxs-lookup"><span data-stu-id="bd704-137">DistCp</span></span>            | <span data-ttu-id="bd704-138">-m (toewijzen)</span><span class="sxs-lookup"><span data-stu-id="bd704-138">-m (mapper)</span></span>   | [<span data-ttu-id="bd704-139">Koppeling</span><span class="sxs-lookup"><span data-stu-id="bd704-139">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-wasb-distcp#performance-considerations-while-using-distcp)                             |
| <span data-ttu-id="bd704-140">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="bd704-140">Azure Data Factory</span></span>| <span data-ttu-id="bd704-141">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="bd704-141">parallelCopies</span></span>    | [<span data-ttu-id="bd704-142">Koppeling</span><span class="sxs-lookup"><span data-stu-id="bd704-142">Link</span></span>](../data-factory/data-factory-copy-activity-performance.md)                          |
| <span data-ttu-id="bd704-143">Sqoop</span><span class="sxs-lookup"><span data-stu-id="bd704-143">Sqoop</span></span>           | <span data-ttu-id="bd704-144">FS.Azure.Block.Size, -m (toewijzen)</span><span class="sxs-lookup"><span data-stu-id="bd704-144">fs.azure.block.size, -m (mapper)</span></span>    |   [<span data-ttu-id="bd704-145">Koppeling</span><span class="sxs-lookup"><span data-stu-id="bd704-145">Link</span></span>](https://blogs.msdn.microsoft.com/bigdatasupport/2015/02/17/sqoop-job-performance-tuning-in-hdinsight-hadoop/)        |

## <a name="structure-your-data-set"></a><span data-ttu-id="bd704-146">Structuur van uw gegevensset</span><span class="sxs-lookup"><span data-stu-id="bd704-146">Structure your data set</span></span>

<span data-ttu-id="bd704-147">Wanneer gegevens worden opgeslagen in Data Lake Store, de grootte van het aantal bestanden en de mappenstructuur van invloed zijn op de prestaties.</span><span class="sxs-lookup"><span data-stu-id="bd704-147">When data is stored in Data Lake Store, the file size, number of files, and folder structure have an impact on performance.</span></span>  <span data-ttu-id="bd704-148">De volgende sectie beschreven procedures in de volgende gebieden.</span><span class="sxs-lookup"><span data-stu-id="bd704-148">The following section describes best practices in these areas.</span></span>  

### <a name="file-size"></a><span data-ttu-id="bd704-149">Bestandsgrootte</span><span class="sxs-lookup"><span data-stu-id="bd704-149">File size</span></span>

<span data-ttu-id="bd704-150">Analytics-engines zoals HDInsight en Azure Data Lake Analytics hebben doorgaans een overhead per bestand.</span><span class="sxs-lookup"><span data-stu-id="bd704-150">Typically, analytics engines such as HDInsight and Azure Data Lake Analytics have a per-file overhead.</span></span>  <span data-ttu-id="bd704-151">Als u uw gegevens zo veel kleine bestanden opslaat, kan dit de prestaties negatief beïnvloeden.</span><span class="sxs-lookup"><span data-stu-id="bd704-151">If you store your data as many small files, this can negatively affect performance.</span></span>  

<span data-ttu-id="bd704-152">Uw gegevens in het algemeen zijn ingedeeld in grotere grootte bestanden voor betere prestaties.</span><span class="sxs-lookup"><span data-stu-id="bd704-152">In general, organize your data into larger sized files for better performance.</span></span>  <span data-ttu-id="bd704-153">Als een vuistregel organiseert gegevenssets in bestanden van 256MB of hoger.</span><span class="sxs-lookup"><span data-stu-id="bd704-153">As a rule of thumb, organize data sets in files of 256MB or larger.</span></span> <span data-ttu-id="bd704-154">In sommige gevallen, zoals afbeeldingen en binaire gegevens is het niet mogelijk ze parallel te verwerken.</span><span class="sxs-lookup"><span data-stu-id="bd704-154">In some cases such as images and binary data, it is not possible to process them in parallel.</span></span>  <span data-ttu-id="bd704-155">In dergelijke gevallen is het aanbevolen om minder dan 2GB voor afzonderlijke bestanden te houden.</span><span class="sxs-lookup"><span data-stu-id="bd704-155">In these cases, it is recommended to keep individual files under 2GB.</span></span>

<span data-ttu-id="bd704-156">Soms beperkt gegevenspijplijnen controle over de onbewerkte gegevens met een groot aantal kleine bestanden.</span><span class="sxs-lookup"><span data-stu-id="bd704-156">Sometimes, data pipelines have limited control over the raw data which has lots of small files.</span></span>  <span data-ttu-id="bd704-157">Het is raadzaam een 'koken' proces die grotere bestanden moet worden gebruikt voor downstream toepassingen worden gegenereerd.</span><span class="sxs-lookup"><span data-stu-id="bd704-157">It is recommended to have a “cooking” process that generates larger files to use for downstream applications.</span></span>  

### <a name="organizing-time-series-data-in-folders"></a><span data-ttu-id="bd704-158">Time Series-gegevens in mappen ordenen</span><span class="sxs-lookup"><span data-stu-id="bd704-158">Organizing Time Series data in folders</span></span>

<span data-ttu-id="bd704-159">Hive en ADLA werkbelastingen kunt partitie verwijderen van de tijdreeks gegevens enkele query's bij het lezen van slechts een subset van de gegevens die zorgt voor betere prestaties.</span><span class="sxs-lookup"><span data-stu-id="bd704-159">For Hive and ADLA workloads, partition pruning of time-series data can help some queries read only a subset of the data which improves performance.</span></span>    

<span data-ttu-id="bd704-160">Deze pijplijnen die timeseries gegevens opnemen, plaatst u vaak hun bestanden met een zeer gestructureerd naamgeving voor bestanden en mappen.</span><span class="sxs-lookup"><span data-stu-id="bd704-160">Those pipelines that ingest time-series data, often place their files with a very structured naming for files and folders.</span></span> <span data-ttu-id="bd704-161">Hieronder vindt u een voorbeeld van een zeer gangbaar zien we voor gegevens die is geordend op datum:</span><span class="sxs-lookup"><span data-stu-id="bd704-161">Below is a very common example we see for data that is structured by date:</span></span>

    \DataSet\YYYY\MM\DD\datafile_YYYY_MM_DD.tsv

<span data-ttu-id="bd704-162">U ziet dat de datum/tijd-gegevens worden weergegeven als de mappen en in de bestandsnaam.</span><span class="sxs-lookup"><span data-stu-id="bd704-162">Notice that the datetime information appears both as folders and in the filename.</span></span>

<span data-ttu-id="bd704-163">Voor de datum en tijd waarop is het volgende een algemene patroon</span><span class="sxs-lookup"><span data-stu-id="bd704-163">For date and time, the following is a common pattern</span></span>

    \DataSet\YYYY\MM\DD\HH\mm\datafile_YYYY_MM_DD_HH_mm.tsv

<span data-ttu-id="bd704-164">Opnieuw de keuze die u maakt met de map en Bestandsorganisatie moet optimaliseren voor een redelijke aantal bestanden in elke map en de bestandsgrootte.</span><span class="sxs-lookup"><span data-stu-id="bd704-164">Again, the choice you make with the folder and file organization should optimize for the larger file sizes and a reasonable number of files in each folder.</span></span>

## <a name="optimizing-io-intensive-jobs-on-hadoop-and-spark-workloads-on-hdinsight"></a><span data-ttu-id="bd704-165">I/o-intensieve taken op de werkbelastingen voor Hadoop en Spark in HDInsight optimaliseren</span><span class="sxs-lookup"><span data-stu-id="bd704-165">Optimizing I/O intensive jobs on Hadoop and Spark workloads on HDInsight</span></span>

<span data-ttu-id="bd704-166">Taken kunnen worden onderverdeeld in een van de volgende drie categorieën:</span><span class="sxs-lookup"><span data-stu-id="bd704-166">Jobs fall into one of the following three categories:</span></span>

* <span data-ttu-id="bd704-167">**CPU-intensief.**</span><span class="sxs-lookup"><span data-stu-id="bd704-167">**CPU intensive.**</span></span>  <span data-ttu-id="bd704-168">Deze taken zijn lang berekening tijdstippen met minimale i/o-tijden.</span><span class="sxs-lookup"><span data-stu-id="bd704-168">These jobs have long computation times with minimal I/O times.</span></span>  <span data-ttu-id="bd704-169">Voorbeelden zijn machine learning en natuurlijke taal taken verwerken.</span><span class="sxs-lookup"><span data-stu-id="bd704-169">Examples include machine learning and natural language processing jobs.</span></span>  
* <span data-ttu-id="bd704-170">**Geheugenintensief.**</span><span class="sxs-lookup"><span data-stu-id="bd704-170">**Memory intensive.**</span></span>  <span data-ttu-id="bd704-171">Deze taken veel geheugen gebruiken.</span><span class="sxs-lookup"><span data-stu-id="bd704-171">These jobs use lots of memory.</span></span>  <span data-ttu-id="bd704-172">Voorbeelden zijn PageRank en realtime analytics-taken.</span><span class="sxs-lookup"><span data-stu-id="bd704-172">Examples include PageRank and real-time analytics jobs.</span></span>  
* <span data-ttu-id="bd704-173">**I/o-intensieve.**</span><span class="sxs-lookup"><span data-stu-id="bd704-173">**I/O intensive.**</span></span>  <span data-ttu-id="bd704-174">Deze taken te besteden aan de meeste van de tijd die tijdens het doorzoeken van i/o.</span><span class="sxs-lookup"><span data-stu-id="bd704-174">These jobs spend most of their time doing I/O.</span></span>  <span data-ttu-id="bd704-175">Een veelvoorkomend voorbeeld is een kopieertaak die alleen lezen en schrijfbewerkingen.</span><span class="sxs-lookup"><span data-stu-id="bd704-175">A common example is a copy job which does only read and write operations.</span></span>  <span data-ttu-id="bd704-176">Andere voorbeelden zijn gegevens voorbereiding taken die veel gegevens lezen, voert de gegevenstransformatie van sommige uit en schrijft de gegevens terug naar de store.</span><span class="sxs-lookup"><span data-stu-id="bd704-176">Other examples include data preparation jobs that read a lot of data, performs some data transformation, and then writes the data back to the store.</span></span>  

<span data-ttu-id="bd704-177">De volgende richtlijnen zijn alleen van toepassing op i/o-intensieve taken.</span><span class="sxs-lookup"><span data-stu-id="bd704-177">The following guidance is only applicable to I/O intensive jobs.</span></span>

### <a name="general-considerations-for-an-hdinsight-cluster"></a><span data-ttu-id="bd704-178">Algemene overwegingen voor een HDInsight-cluster</span><span class="sxs-lookup"><span data-stu-id="bd704-178">General Considerations for an HDInsight cluster</span></span>

* <span data-ttu-id="bd704-179">**HDInsight-versies.**</span><span class="sxs-lookup"><span data-stu-id="bd704-179">**HDInsight versions.**</span></span> <span data-ttu-id="bd704-180">Gebruik de nieuwste versie van HDInsight voor de beste prestaties.</span><span class="sxs-lookup"><span data-stu-id="bd704-180">For best performance, use the latest release of HDInsight.</span></span>
* <span data-ttu-id="bd704-181">**Regio's.**</span><span class="sxs-lookup"><span data-stu-id="bd704-181">**Regions.**</span></span> <span data-ttu-id="bd704-182">De Data Lake Store in dezelfde regio bevinden als het HDInsight-cluster plaatsen.</span><span class="sxs-lookup"><span data-stu-id="bd704-182">Place the Data Lake Store in the same region as the HDInsight cluster.</span></span>  

<span data-ttu-id="bd704-183">Een HDInsight-cluster bestaat uit twee hoofdknooppunten en een aantal worker-knooppunten.</span><span class="sxs-lookup"><span data-stu-id="bd704-183">An HDInsight cluster is composed of two head nodes and some worker nodes.</span></span> <span data-ttu-id="bd704-184">Elk werkrolknooppunt biedt een aantal kernen en het geheugen dat wordt bepaald door het VM-type.</span><span class="sxs-lookup"><span data-stu-id="bd704-184">Each worker node provides a specific number of cores and memory, which is determined by the VM-type.</span></span>  <span data-ttu-id="bd704-185">Wanneer een taak wordt uitgevoerd, is YARN de resource-onderhandelaar waarmee het beschikbare geheugen en kernen containers maken wordt toegewezen.</span><span class="sxs-lookup"><span data-stu-id="bd704-185">When running a job, YARN is the resource negotiator that allocates the available memory and cores to create containers.</span></span>  <span data-ttu-id="bd704-186">Elke container wordt uitgevoerd voor de taken die nodig zijn om de taak te voltooien.</span><span class="sxs-lookup"><span data-stu-id="bd704-186">Each container runs the tasks needed to complete the job.</span></span>  <span data-ttu-id="bd704-187">Containers parallel worden verwerkt taken snel worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="bd704-187">Containers run in parallel to process tasks quickly.</span></span> <span data-ttu-id="bd704-188">Daarom wordt de prestaties verbeterd door het uitvoeren van parallelle-containers zoveel mogelijk.</span><span class="sxs-lookup"><span data-stu-id="bd704-188">Therefore, performance is improved by running as many parallel containers as possible.</span></span>

<span data-ttu-id="bd704-189">Er zijn drie lagen in een HDInsight-cluster kunnen worden afgestemd Verhoog het aantal containers en het gebruik van alle beschikbare doorvoer.</span><span class="sxs-lookup"><span data-stu-id="bd704-189">There are three layers within an HDInsight cluster that can be tuned to increase the number of containers and use all available throughput.</span></span>  

* <span data-ttu-id="bd704-190">**Fysieke laag**</span><span class="sxs-lookup"><span data-stu-id="bd704-190">**Physical layer**</span></span>
* <span data-ttu-id="bd704-191">**YARN-laag**</span><span class="sxs-lookup"><span data-stu-id="bd704-191">**YARN layer**</span></span>
* <span data-ttu-id="bd704-192">**Laag van de werkbelasting**</span><span class="sxs-lookup"><span data-stu-id="bd704-192">**Workload layer**</span></span>

### <a name="physical-layer"></a><span data-ttu-id="bd704-193">Fysieke laag</span><span class="sxs-lookup"><span data-stu-id="bd704-193">Physical Layer</span></span>

<span data-ttu-id="bd704-194">**Voer een cluster met meer knooppunten en/of groter formaat virtuele machines.**</span><span class="sxs-lookup"><span data-stu-id="bd704-194">**Run cluster with more nodes and/or larger sized VMs.**</span></span>  <span data-ttu-id="bd704-195">Een groter cluster, kunt u meer YARN-containers zoals weergegeven in de volgende afbeelding worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="bd704-195">A larger cluster will enable you to run more YARN containers as shown in the picture below.</span></span>

![Data Lake Store-prestaties](./media/data-lake-store-performance-tuning-guidance/VM.png)

<span data-ttu-id="bd704-197">**Virtuele machines met meer netwerkbandbreedte gebruiken.**</span><span class="sxs-lookup"><span data-stu-id="bd704-197">**Use VMs with more network bandwidth.**</span></span>  <span data-ttu-id="bd704-198">De hoeveelheid netwerkbandbreedte kan een knelpunt zijn als er minder netwerkbandbreedte dan een Data Lake Store-doorvoer.</span><span class="sxs-lookup"><span data-stu-id="bd704-198">The amount of network bandwidth can be a bottleneck if there is less network bandwidth than Data Lake Store throughput.</span></span>  <span data-ttu-id="bd704-199">Andere virtuele machines hebben verschillende grootten voor netwerk-bandbreedte.</span><span class="sxs-lookup"><span data-stu-id="bd704-199">Different VMs will have varying network bandwidth sizes.</span></span>  <span data-ttu-id="bd704-200">Kies een VM-type met de grootste mogelijke netwerkbandbreedte.</span><span class="sxs-lookup"><span data-stu-id="bd704-200">Choose a VM-type that has the largest possible network bandwidth.</span></span>

### <a name="yarn-layer"></a><span data-ttu-id="bd704-201">YARN-laag</span><span class="sxs-lookup"><span data-stu-id="bd704-201">YARN Layer</span></span>

<span data-ttu-id="bd704-202">**Kleinere YARN-containers gebruiken.**</span><span class="sxs-lookup"><span data-stu-id="bd704-202">**Use smaller YARN containers.**</span></span>  <span data-ttu-id="bd704-203">Reduceer de grootte van elke container YARN meer containers maken met dezelfde mate van resources.</span><span class="sxs-lookup"><span data-stu-id="bd704-203">Reduce the size of each YARN container to create more containers with the same amount of resources.</span></span>

![Data Lake Store-prestaties](./media/data-lake-store-performance-tuning-guidance/small-containers.png)

<span data-ttu-id="bd704-205">Afhankelijk van uw werkbelasting moet altijd er een YARN container minimumgrootte die nodig is.</span><span class="sxs-lookup"><span data-stu-id="bd704-205">Depending on your workload, there will always be a minimum YARN container size that is needed.</span></span> <span data-ttu-id="bd704-206">Als u een container te klein kiest, worden de taken worden uitgevoerd in-geheugen problemen.</span><span class="sxs-lookup"><span data-stu-id="bd704-206">If you pick too small a container, your jobs will run into out-of-memory issues.</span></span> <span data-ttu-id="bd704-207">Doorgaans moet YARN containers niet kleiner zijn dan 1GB.</span><span class="sxs-lookup"><span data-stu-id="bd704-207">Typically YARN containers should be no smaller than 1GB.</span></span> <span data-ttu-id="bd704-208">Het is gebruikelijk om te zien van 3GB YARN containers.</span><span class="sxs-lookup"><span data-stu-id="bd704-208">It’s common to see 3GB YARN containers.</span></span> <span data-ttu-id="bd704-209">Voor sommige werkbelastingen moet u grotere YARN-containers.</span><span class="sxs-lookup"><span data-stu-id="bd704-209">For some workloads, you may need larger YARN containers.</span></span>  

<span data-ttu-id="bd704-210">**Kernen per YARN-container verhogen.**</span><span class="sxs-lookup"><span data-stu-id="bd704-210">**Increase cores per YARN container.**</span></span>  <span data-ttu-id="bd704-211">Verhoog het aantal kernen dat is toegewezen aan elke container om het aantal parallelle taken die worden uitgevoerd in elke container te vergroten.</span><span class="sxs-lookup"><span data-stu-id="bd704-211">Increase the number of cores allocated to each container to increase the number of parallel tasks that run in each container.</span></span>  <span data-ttu-id="bd704-212">Dit werkt voor toepassingen zoals Spark die meerdere taken per container worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="bd704-212">This works for applications like Spark which run multiple tasks per container.</span></span>  <span data-ttu-id="bd704-213">Voor toepassingen zoals Hive die een enkele thread in elke container worden uitgevoerd, is het beter om meer containers in plaats van meer kernen per container hebt.</span><span class="sxs-lookup"><span data-stu-id="bd704-213">For applications like Hive which run a single thread in each container, it is better to have more containers rather than more cores per container.</span></span>   

### <a name="workload-layer"></a><span data-ttu-id="bd704-214">Laag van de werkbelasting</span><span class="sxs-lookup"><span data-stu-id="bd704-214">Workload Layer</span></span>

<span data-ttu-id="bd704-215">**Alle beschikbare containers gebruiken.**</span><span class="sxs-lookup"><span data-stu-id="bd704-215">**Use all available containers.**</span></span>  <span data-ttu-id="bd704-216">Stel het aantal taken moet gelijk zijn of groter zijn dan het aantal beschikbare containers, zodat alle resources worden gebruikt.</span><span class="sxs-lookup"><span data-stu-id="bd704-216">Set the number of tasks to be equal or larger than the number of available containers so that all resources are utilized.</span></span>

![Data Lake Store-prestaties](./media/data-lake-store-performance-tuning-guidance/use-containers.png)

<span data-ttu-id="bd704-218">**Mislukte taken zijn kostbaar.**</span><span class="sxs-lookup"><span data-stu-id="bd704-218">**Failed tasks are costly.**</span></span> <span data-ttu-id="bd704-219">Als u elke taak heeft een grote hoeveelheid gegevens verwerken, klikt u vervolgens resulteert mislukken van een taak in een dure probeer het opnieuw.</span><span class="sxs-lookup"><span data-stu-id="bd704-219">If each task has a large amount of data to process, then failure of a task results in an expensive retry.</span></span>  <span data-ttu-id="bd704-220">Daarom is het beter om het maken van meer taken, die elk een kleine hoeveelheid gegevens verwerkt.</span><span class="sxs-lookup"><span data-stu-id="bd704-220">Therefore, it is better to create more tasks, each of which processes a small amount of data.</span></span>

<span data-ttu-id="bd704-221">Naast de bovenstaande algemene richtlijnen heeft elke toepassing andere parameters die beschikbaar zijn om af te stemmen voor die specifieke toepassing.</span><span class="sxs-lookup"><span data-stu-id="bd704-221">In addition to the general guidelines above, each application has different parameters available to tune for that specific application.</span></span> <span data-ttu-id="bd704-222">De volgende tabel bevat enkele van de parameters en koppelingen naar aan de slag met prestaties afstemmen voor elke toepassing.</span><span class="sxs-lookup"><span data-stu-id="bd704-222">The table below lists some of the parameters and links to get started with performance tuning for each application.</span></span>

| <span data-ttu-id="bd704-223">Workload</span><span class="sxs-lookup"><span data-stu-id="bd704-223">Workload</span></span>               | <span data-ttu-id="bd704-224">Parameter om taken te stellen</span><span class="sxs-lookup"><span data-stu-id="bd704-224">Parameter to set tasks</span></span>                                                         |
|--------------------|-------------------------------------------------------------------------------------|
| [<span data-ttu-id="bd704-225">Spark in HDInisight</span><span class="sxs-lookup"><span data-stu-id="bd704-225">Spark on HDInisight</span></span>](data-lake-store-performance-tuning-spark.md)       | <ul><li><span data-ttu-id="bd704-226">NUM Executor</span><span class="sxs-lookup"><span data-stu-id="bd704-226">Num-executors</span></span></li><li><span data-ttu-id="bd704-227">Executor-geheugen</span><span class="sxs-lookup"><span data-stu-id="bd704-227">Executor-memory</span></span></li><li><span data-ttu-id="bd704-228">Executor kernen</span><span class="sxs-lookup"><span data-stu-id="bd704-228">Executor-cores</span></span></li></ul> |
| [<span data-ttu-id="bd704-229">Hive in HDInsight</span><span class="sxs-lookup"><span data-stu-id="bd704-229">Hive on HDInsight</span></span>](data-lake-store-performance-tuning-hive.md)    | <ul><li><span data-ttu-id="bd704-230">hive.tez.container.Size</span><span class="sxs-lookup"><span data-stu-id="bd704-230">hive.tez.container.size</span></span></li></ul>         |
| [<span data-ttu-id="bd704-231">MapReduce in HDInsight</span><span class="sxs-lookup"><span data-stu-id="bd704-231">MapReduce on HDInsight</span></span>](data-lake-store-performance-tuning-mapreduce.md)            | <ul><li><span data-ttu-id="bd704-232">mapreduce.map.Memory</span><span class="sxs-lookup"><span data-stu-id="bd704-232">Mapreduce.map.memory</span></span></li><li><span data-ttu-id="bd704-233">Mapreduce.job.Maps</span><span class="sxs-lookup"><span data-stu-id="bd704-233">Mapreduce.job.maps</span></span></li><li><span data-ttu-id="bd704-234">mapreduce.reduce.Memory</span><span class="sxs-lookup"><span data-stu-id="bd704-234">Mapreduce.reduce.memory</span></span></li><li><span data-ttu-id="bd704-235">Mapreduce.job.reduces</span><span class="sxs-lookup"><span data-stu-id="bd704-235">Mapreduce.job.reduces</span></span></li></ul> |
| [<span data-ttu-id="bd704-236">Storm op HDInsight</span><span class="sxs-lookup"><span data-stu-id="bd704-236">Storm on HDInsight</span></span>](data-lake-store-performance-tuning-storm.md)| <ul><li><span data-ttu-id="bd704-237">Aantal werkprocessen</span><span class="sxs-lookup"><span data-stu-id="bd704-237">Number of worker processes</span></span></li><li><span data-ttu-id="bd704-238">Aantal exemplaren van spout executor</span><span class="sxs-lookup"><span data-stu-id="bd704-238">Number of spout executor instances</span></span></li><li><span data-ttu-id="bd704-239">Aantal exemplaren van bolt executor</span><span class="sxs-lookup"><span data-stu-id="bd704-239">Number of bolt executor instances</span></span> </li><li><span data-ttu-id="bd704-240">Aantal spout taken</span><span class="sxs-lookup"><span data-stu-id="bd704-240">Number of spout tasks</span></span></li><li><span data-ttu-id="bd704-241">Aantal bolt taken</span><span class="sxs-lookup"><span data-stu-id="bd704-241">Number of bolt tasks</span></span></li></ul>|

## <a name="see-also"></a><span data-ttu-id="bd704-242">Zie ook</span><span class="sxs-lookup"><span data-stu-id="bd704-242">See also</span></span>
* [<span data-ttu-id="bd704-243">Overzicht van Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="bd704-243">Overview of Azure Data Lake Store</span></span>](data-lake-store-overview.md)
* [<span data-ttu-id="bd704-244">Aan de slag met Azure Data Lake Analytics</span><span class="sxs-lookup"><span data-stu-id="bd704-244">Get Started with Azure Data Lake Analytics</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)
