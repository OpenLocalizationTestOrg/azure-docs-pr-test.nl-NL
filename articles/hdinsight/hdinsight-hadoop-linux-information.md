---
title: Tips voor het gebruik van Hadoop op Linux gebaseerde HDInsight - Azure | Microsoft Docs
description: Implementatie van tips voor het gebruik van HDInsight (Hadoop) op basis van Linux-clusters op een vertrouwde Linux-omgeving uitgevoerd in de Azure-cloud.
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: c41c611c-5798-4c14-81cc-bed1e26b5609
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/12/2017
ms.author: larryfr
ms.openlocfilehash: 8c6ff4a6b8617cda9b12be060c7c7bed62cb3f44
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/03/2017
---
# <a name="information-about-using-hdinsight-on-linux"></a><span data-ttu-id="53b66-103">Informatie over het gebruik van HDInsight op Linux</span><span class="sxs-lookup"><span data-stu-id="53b66-103">Information about using HDInsight on Linux</span></span>

<span data-ttu-id="53b66-104">Azure HDInsight-clusters bieden Hadoop op een vertrouwde Linux-omgeving worden uitgevoerd in de Azure-cloud.</span><span class="sxs-lookup"><span data-stu-id="53b66-104">Azure HDInsight clusters provide Hadoop on a familiar Linux environment, running in the Azure cloud.</span></span> <span data-ttu-id="53b66-105">Voor de meeste zaken werkt deze moet exact als elke andere Hadoop op Linux-installatie.</span><span class="sxs-lookup"><span data-stu-id="53b66-105">For most things, it should work exactly as any other Hadoop-on-Linux installation.</span></span> <span data-ttu-id="53b66-106">Dit document is illustreert van specifieke verschillen die u houden moet rekening.</span><span class="sxs-lookup"><span data-stu-id="53b66-106">This document calls out specific differences that you should be aware of.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="53b66-107">Linux is het enige besturingssysteem dat wordt gebruikt in HDInsight-versie 3.4 of hoger.</span><span class="sxs-lookup"><span data-stu-id="53b66-107">Linux is the only operating system used on HDInsight version 3.4 or greater.</span></span> <span data-ttu-id="53b66-108">Zie [HDInsight retirement on Windows](hdinsight-component-versioning.md#hdinsight-windows-retirement) (HDInsight buiten gebruik gestel voor Windows) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="53b66-108">For more information, see [HDInsight retirement on Windows](hdinsight-component-versioning.md#hdinsight-windows-retirement).</span></span>

## <a name="prerequisites"></a><span data-ttu-id="53b66-109">Vereisten</span><span class="sxs-lookup"><span data-stu-id="53b66-109">Prerequisites</span></span>

<span data-ttu-id="53b66-110">Veel van de stappen in dit document met de volgende hulpprogramma's, die mogelijk moeten worden geïnstalleerd op uw systeem.</span><span class="sxs-lookup"><span data-stu-id="53b66-110">Many of the steps in this document use the following utilities, which may need to be installed on your system.</span></span>

* <span data-ttu-id="53b66-111">[cURL](https://curl.haxx.se/) : wordt gebruikt om te communiceren met webservices</span><span class="sxs-lookup"><span data-stu-id="53b66-111">[cURL](https://curl.haxx.se/) - used to communicate with web-based services</span></span>
* <span data-ttu-id="53b66-112">[jq](https://stedolan.github.io/jq/) : wordt gebruikt voor het parseren van JSON-documenten</span><span class="sxs-lookup"><span data-stu-id="53b66-112">[jq](https://stedolan.github.io/jq/) - used to parse JSON documents</span></span>
* <span data-ttu-id="53b66-113">[Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) (preview): gebruikt voor het extern beheren van Azure-services</span><span class="sxs-lookup"><span data-stu-id="53b66-113">[Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) (preview) - used to remotely manage Azure services</span></span>

## <a name="users"></a><span data-ttu-id="53b66-114">Gebruikers</span><span class="sxs-lookup"><span data-stu-id="53b66-114">Users</span></span>

<span data-ttu-id="53b66-115">Tenzij [domein](hdinsight-domain-joined-introduction.md), HDInsight moet worden beschouwd als een **één gebruiker** system.</span><span class="sxs-lookup"><span data-stu-id="53b66-115">Unless [domain-joined](hdinsight-domain-joined-introduction.md), HDInsight should be considered a **single-user** system.</span></span> <span data-ttu-id="53b66-116">Een SSH-account voor één gebruiker is gemaakt met het cluster, met de beheerdersmachtigingen.</span><span class="sxs-lookup"><span data-stu-id="53b66-116">A single SSH user account is created with the cluster, with administrator level permissions.</span></span> <span data-ttu-id="53b66-117">Aanvullende SSH-accounts kunnen worden gemaakt, maar ze hebben beheerderstoegang tot het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-117">Additional SSH accounts can be created, but they also have administrator access to the cluster.</span></span>

<span data-ttu-id="53b66-118">Domein HDInsight biedt ondersteuning voor meerdere gebruikers en meer gedetailleerde instellingen voor machtigingen en de rol.</span><span class="sxs-lookup"><span data-stu-id="53b66-118">Domain-joined HDInsight supports multiple users and more granular permission and role settings.</span></span> <span data-ttu-id="53b66-119">Zie voor meer informatie [beheren domein HDInsight-clusters](hdinsight-domain-joined-manage.md).</span><span class="sxs-lookup"><span data-stu-id="53b66-119">For more information, see [Manage Domain-joined HDInsight clusters](hdinsight-domain-joined-manage.md).</span></span>

## <a name="domain-names"></a><span data-ttu-id="53b66-120">Domeinnamen</span><span class="sxs-lookup"><span data-stu-id="53b66-120">Domain names</span></span>

<span data-ttu-id="53b66-121">De volledig gekwalificeerde domeinnaam (FQDN) te gebruiken bij het verbinden met het cluster van het internet is  **&lt;clustername >. azurehdinsight.net** of (voor SSH)  **&lt;clustername-ssh >. azurehdinsight.NET**.</span><span class="sxs-lookup"><span data-stu-id="53b66-121">The fully qualified domain name (FQDN) to use when connecting to the cluster from the internet is **&lt;clustername>.azurehdinsight.net** or (for SSH only) **&lt;clustername-ssh>.azurehdinsight.net**.</span></span>

<span data-ttu-id="53b66-122">Intern maakt heeft elk knooppunt in het cluster een naam die is toegewezen tijdens de configuratie van het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-122">Internally, each node in the cluster has a name that is assigned during cluster configuration.</span></span> <span data-ttu-id="53b66-123">De clusternamen van de, Zie de **Hosts** pagina op de Ambari-Webgebruikersinterface.</span><span class="sxs-lookup"><span data-stu-id="53b66-123">To find the cluster names, see the **Hosts** page on the Ambari Web UI.</span></span> <span data-ttu-id="53b66-124">U kunt ook het volgende gebruiken om te retourneren van een lijst met hosts uit de Ambari REST-API:</span><span class="sxs-lookup"><span data-stu-id="53b66-124">You can also use the following to return a list of hosts from the Ambari REST API:</span></span>

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/hosts" | jq '.items[].Hosts.host_name'

<span data-ttu-id="53b66-125">Vervang **wachtwoord** met het wachtwoord van het beheerdersaccount en **CLUSTERNAME** met de naam van het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-125">Replace **PASSWORD** with the password of the admin account, and **CLUSTERNAME** with the name of your cluster.</span></span> <span data-ttu-id="53b66-126">Deze opdracht retourneert een JSON-document met een lijst van de hosts in het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-126">This command returns a JSON document that contains a list of the hosts in the cluster.</span></span> <span data-ttu-id="53b66-127">Jq wordt gebruikt om op te halen de `host_name` elementwaarde voor elke host.</span><span class="sxs-lookup"><span data-stu-id="53b66-127">Jq is used to extract the `host_name` element value for each host.</span></span>

<span data-ttu-id="53b66-128">Als u moet de naam van het knooppunt vinden voor een bepaalde service, kunt u Ambari voor dat onderdeel opvragen.</span><span class="sxs-lookup"><span data-stu-id="53b66-128">If you need to find the name of the node for a specific service, you can query Ambari for that component.</span></span> <span data-ttu-id="53b66-129">Bijvoorbeeld, als u wilt de hosts vinden voor het knooppunt HDFS-naam, gebruik de volgende opdracht:</span><span class="sxs-lookup"><span data-stu-id="53b66-129">For example, to find the hosts for the HDFS name node, use the following command:</span></span>

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/services/HDFS/components/NAMENODE" | jq '.host_components[].HostRoles.host_name'

<span data-ttu-id="53b66-130">Met deze opdracht retourneert een JSON-document met een beschrijving van de service en jq vervolgens haalt uit alleen de `host_name` waarde voor de hosts.</span><span class="sxs-lookup"><span data-stu-id="53b66-130">This command returns a JSON document describing the service, and then jq pulls out only the `host_name` value for the hosts.</span></span>

## <a name="remote-access-to-services"></a><span data-ttu-id="53b66-131">Externe toegang tot services</span><span class="sxs-lookup"><span data-stu-id="53b66-131">Remote access to services</span></span>

* <span data-ttu-id="53b66-132">**Ambari (web)** -https://&lt;clustername >. azurehdinsight.net</span><span class="sxs-lookup"><span data-stu-id="53b66-132">**Ambari (web)** - https://&lt;clustername>.azurehdinsight.net</span></span>

    <span data-ttu-id="53b66-133">Verifiëren met behulp van de cluster-beheerder en het wachtwoord en vervolgens weer aanmelden bij Ambari.</span><span class="sxs-lookup"><span data-stu-id="53b66-133">Authenticate by using the cluster administrator user and password, and then log in to Ambari.</span></span>

    <span data-ttu-id="53b66-134">Verificatie is tekst zonder opmaak - altijd gebruik van HTTPS om ervoor te zorgen dat de verbinding beveiligd is.</span><span class="sxs-lookup"><span data-stu-id="53b66-134">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</span></span>

    > [!IMPORTANT]
    > <span data-ttu-id="53b66-135">Sommige van de web-UI beschikbaar via Ambari toegang tot de knooppunten met de naam van een interne domein.</span><span class="sxs-lookup"><span data-stu-id="53b66-135">Some of the web UIs available through Ambari access nodes using an internal domain name.</span></span> <span data-ttu-id="53b66-136">Interne domeinnamen zijn niet openbaar toegankelijk via het internet.</span><span class="sxs-lookup"><span data-stu-id="53b66-136">Internal domain names are not publicly accessible over the internet.</span></span> <span data-ttu-id="53b66-137">Het foutbericht 'de server is niet gevonden'-fouten bij het toegang krijgen tot sommige functies via het Internet.</span><span class="sxs-lookup"><span data-stu-id="53b66-137">You may receive "server not found" errors when trying to access some features over the Internet.</span></span>
    >
    > <span data-ttu-id="53b66-138">U kunt de volledige functionaliteit van de Ambari-webgebruikersinterface, gebruiken een SSH-tunnel naar de proxy-webverkeer met het hoofdknooppunt van het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-138">To use the full functionality of the Ambari web UI, use an SSH tunnel to proxy web traffic to the cluster head node.</span></span> <span data-ttu-id="53b66-139">Zie [SSH-Tunneling gebruiken voor toegang tot de Ambari-webgebruikersinterface, ResourceManager JobHistory, NameNode, Oozie en andere web-UI](hdinsight-linux-ambari-ssh-tunnel.md)</span><span class="sxs-lookup"><span data-stu-id="53b66-139">See [Use SSH Tunneling to access Ambari web UI, ResourceManager, JobHistory, NameNode, Oozie, and other web UIs](hdinsight-linux-ambari-ssh-tunnel.md)</span></span>

* <span data-ttu-id="53b66-140">**Ambari (REST)** -https://&lt;clustername >.azurehdinsight.net/ambari</span><span class="sxs-lookup"><span data-stu-id="53b66-140">**Ambari (REST)** - https://&lt;clustername>.azurehdinsight.net/ambari</span></span>

    > [!NOTE]
    > <span data-ttu-id="53b66-141">Verifiëren met behulp van de cluster-beheerder en het wachtwoord.</span><span class="sxs-lookup"><span data-stu-id="53b66-141">Authenticate by using the cluster administrator user and password.</span></span>
    >
    > <span data-ttu-id="53b66-142">Verificatie is tekst zonder opmaak - altijd gebruik van HTTPS om ervoor te zorgen dat de verbinding beveiligd is.</span><span class="sxs-lookup"><span data-stu-id="53b66-142">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</span></span>

* <span data-ttu-id="53b66-143">**WebHCat (Templeton)** -https://&lt;clustername >.azurehdinsight.net/templeton</span><span class="sxs-lookup"><span data-stu-id="53b66-143">**WebHCat (Templeton)** - https://&lt;clustername>.azurehdinsight.net/templeton</span></span>

    > [!NOTE]
    > <span data-ttu-id="53b66-144">Verifiëren met behulp van de cluster-beheerder en het wachtwoord.</span><span class="sxs-lookup"><span data-stu-id="53b66-144">Authenticate by using the cluster administrator user and password.</span></span>
    >
    > <span data-ttu-id="53b66-145">Verificatie is tekst zonder opmaak - altijd gebruik van HTTPS om ervoor te zorgen dat de verbinding beveiligd is.</span><span class="sxs-lookup"><span data-stu-id="53b66-145">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</span></span>

* <span data-ttu-id="53b66-146">**SSH** - &lt;clustername >-ssh.azurehdinsight.net op poort 22 of 23.</span><span class="sxs-lookup"><span data-stu-id="53b66-146">**SSH** - &lt;clustername>-ssh.azurehdinsight.net on port 22 or 23.</span></span> <span data-ttu-id="53b66-147">Verbinding maken met de primaire headnode terwijl 23 wordt gebruikt voor het verbinding maken met de secundaire poort 22 gebruikt.</span><span class="sxs-lookup"><span data-stu-id="53b66-147">Port 22 is used to connect to the primary headnode, while 23 is used to connect to the secondary.</span></span> <span data-ttu-id="53b66-148">Zie [Beschikbaarheid en betrouwbaarheid van Hadoop-clusters in HDInsight](hdinsight-high-availability-linux.md) voor meer informatie over de hoofdknooppunten.</span><span class="sxs-lookup"><span data-stu-id="53b66-148">For more information on the head nodes, see [Availability and reliability of Hadoop clusters in HDInsight](hdinsight-high-availability-linux.md).</span></span>

    > [!NOTE]
    > <span data-ttu-id="53b66-149">U kunt alleen toegang tot de hoofdknooppunten van het cluster via SSH vanaf een clientcomputer.</span><span class="sxs-lookup"><span data-stu-id="53b66-149">You can only access the cluster head nodes through SSH from a client machine.</span></span> <span data-ttu-id="53b66-150">Eenmaal zijn verbonden, kunt u de worker-knooppunten met behulp van SSH uit een headnode benaderen.</span><span class="sxs-lookup"><span data-stu-id="53b66-150">Once connected, you can then access the worker nodes by using SSH from a headnode.</span></span>

## <a name="file-locations"></a><span data-ttu-id="53b66-151">Bestandslocaties</span><span class="sxs-lookup"><span data-stu-id="53b66-151">File locations</span></span>

<span data-ttu-id="53b66-152">Hadoop-bestanden kunnen u vinden op de clusterknooppunten op `/usr/hdp`.</span><span class="sxs-lookup"><span data-stu-id="53b66-152">Hadoop-related files can be found on the cluster nodes at `/usr/hdp`.</span></span> <span data-ttu-id="53b66-153">Deze map bevat de volgende submappen:</span><span class="sxs-lookup"><span data-stu-id="53b66-153">This directory contains the following subdirectories:</span></span>

* <span data-ttu-id="53b66-154">**2.2.4.9-1**: naam van de map is de versie van het Hortonworks Data Platform die door HDInsight worden gebruikt.</span><span class="sxs-lookup"><span data-stu-id="53b66-154">**2.2.4.9-1**: The directory name is the version of the Hortonworks Data Platform used by HDInsight.</span></span> <span data-ttu-id="53b66-155">Het nummer op het cluster is mogelijk anders dan hier vermeld.</span><span class="sxs-lookup"><span data-stu-id="53b66-155">The number on your cluster may be different than the one listed here.</span></span>
* <span data-ttu-id="53b66-156">**huidige**: deze map bevat koppelingen naar submappen onder de **2.2.4.9-1** directory.</span><span class="sxs-lookup"><span data-stu-id="53b66-156">**current**: This directory contains links to subdirectories under the **2.2.4.9-1** directory.</span></span> <span data-ttu-id="53b66-157">Deze map bestaat, zodat u niet hoeft te onthouden het versienummer.</span><span class="sxs-lookup"><span data-stu-id="53b66-157">This directory exists so that you don't have to remember the version number.</span></span>

<span data-ttu-id="53b66-158">Van de voorbeeldgegevens en JAR-bestanden kunnen u vinden op Hadoop Distributed File System op `/example` en`/HdiSamples`</span><span class="sxs-lookup"><span data-stu-id="53b66-158">Example data and JAR files can be found on Hadoop Distributed File System at `/example` and `/HdiSamples`</span></span>

## <a name="hdfs-azure-storage-and-data-lake-store"></a><span data-ttu-id="53b66-159">HDFS-, Azure-opslag- en Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="53b66-159">HDFS, Azure Storage, and Data Lake Store</span></span>

<span data-ttu-id="53b66-160">In de meeste Hadoop-distributies HDFS ondersteund door de lokale opslag op de virtuele machines in het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-160">In most Hadoop distributions, HDFS is backed by local storage on the machines in the cluster.</span></span> <span data-ttu-id="53b66-161">Lokale opslag kan worden voor een cloud-gebaseerde oplossing kostbare waar u in rekening worden gebracht per uur of per minuut voor rekenresources.</span><span class="sxs-lookup"><span data-stu-id="53b66-161">Using local storage can be costly for a cloud-based solution where you are charged hourly or by minute for compute resources.</span></span>

<span data-ttu-id="53b66-162">HDInsight gebruikt ofwel blobs in Azure Storage of Azure Data Lake Store als het standaardarchief van.</span><span class="sxs-lookup"><span data-stu-id="53b66-162">HDInsight uses either blobs in Azure Storage or Azure Data Lake Store as the default store.</span></span> <span data-ttu-id="53b66-163">Deze services bieden de volgende voordelen:</span><span class="sxs-lookup"><span data-stu-id="53b66-163">These services provide the following benefits:</span></span>

* <span data-ttu-id="53b66-164">Goedkope langdurige opslag</span><span class="sxs-lookup"><span data-stu-id="53b66-164">Cheap long-term storage</span></span>
* <span data-ttu-id="53b66-165">Toegankelijkheid van externe services zoals websites, bestand uploaden/downloaden van hulpprogramma's, verschillende SDK's van taal en webbrowsers</span><span class="sxs-lookup"><span data-stu-id="53b66-165">Accessibility from external services such as websites, file upload/download utilities, various language SDKs, and web browsers</span></span>

> [!WARNING]
> <span data-ttu-id="53b66-166">HDInsight biedt alleen ondersteuning voor __algemeen__ Azure Storage-accounts.</span><span class="sxs-lookup"><span data-stu-id="53b66-166">HDInsight only supports __General-purpose__ Azure Storage accounts.</span></span> <span data-ttu-id="53b66-167">Het momenteel geen ondersteunt de __Blob storage__ accounttype.</span><span class="sxs-lookup"><span data-stu-id="53b66-167">It does not currently support the __Blob storage__ account type.</span></span>

<span data-ttu-id="53b66-168">Een Azure Storage-account kan tot 4.75 TB bevatten, hoewel afzonderlijke blobs (of bestanden vanuit het perspectief van een HDInsight) alleen 195 GB kunnen gaan.</span><span class="sxs-lookup"><span data-stu-id="53b66-168">An Azure Storage account can hold up to 4.75 TB, though individual blobs (or files from an HDInsight perspective) can only go up to 195 GB.</span></span> <span data-ttu-id="53b66-169">Azure Data Lake Store kunnen dynamisch worden uitgebreid voor het opslaan van trillions van bestanden met afzonderlijke bestanden groter zijn dan een petabyte.</span><span class="sxs-lookup"><span data-stu-id="53b66-169">Azure Data Lake Store can grow dynamically to hold trillions of files, with individual files greater than a petabyte.</span></span> <span data-ttu-id="53b66-170">Zie voor meer informatie [Understanding blobs](https://docs.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs) en [Data Lake Store](https://azure.microsoft.com/services/data-lake-store/).</span><span class="sxs-lookup"><span data-stu-id="53b66-170">For more information, see [Understanding blobs](https://docs.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs) and [Data Lake Store](https://azure.microsoft.com/services/data-lake-store/).</span></span>

<span data-ttu-id="53b66-171">Wanneer u Azure Storage of Data Lake Store, hebt u niet verder niets te doen speciale uit HDInsight toegang tot de gegevens.</span><span class="sxs-lookup"><span data-stu-id="53b66-171">When using either Azure Storage or Data Lake Store, you don't have to do anything special from HDInsight to access the data.</span></span> <span data-ttu-id="53b66-172">Bijvoorbeeld de volgende opdracht geeft een lijst van bestanden in de `/example/data` map ongeacht of deze wordt opgeslagen op Azure Storage of de Data Lake Store:</span><span class="sxs-lookup"><span data-stu-id="53b66-172">For example, the following command lists files in the `/example/data` folder regardless of whether it is stored on Azure Storage or Data Lake Store:</span></span>

    hdfs dfs -ls /example/data

### <a name="uri-and-scheme"></a><span data-ttu-id="53b66-173">URI- en schema</span><span class="sxs-lookup"><span data-stu-id="53b66-173">URI and scheme</span></span>

<span data-ttu-id="53b66-174">Sommige opdrachten moet u mogelijk het schema als onderdeel van de URI opgeven bij het openen van een bestand.</span><span class="sxs-lookup"><span data-stu-id="53b66-174">Some commands may require you to specify the scheme as part of the URI when accessing a file.</span></span> <span data-ttu-id="53b66-175">Het Storm-HDFS-onderdeel vereist u het schema opgeven.</span><span class="sxs-lookup"><span data-stu-id="53b66-175">For example, the Storm-HDFS component requires you to specify the scheme.</span></span> <span data-ttu-id="53b66-176">Wanneer u niet-standaard-opslag (opslag als 'Extra' opslag toegevoegd aan het cluster) gebruikt, moet u het schema altijd gebruiken als onderdeel van de URI.</span><span class="sxs-lookup"><span data-stu-id="53b66-176">When using non-default storage (storage added as "additional" storage to the cluster), you must always use the scheme as part of the URI.</span></span>

<span data-ttu-id="53b66-177">Wanneer u __Azure Storage__, gebruikt u een van de volgende URI-schema's:</span><span class="sxs-lookup"><span data-stu-id="53b66-177">When using __Azure Storage__, use one of the following URI schemes:</span></span>

* <span data-ttu-id="53b66-178">`wasb:///`: Toegang standaard opslag met behulp van niet-gecodeerde communicatie.</span><span class="sxs-lookup"><span data-stu-id="53b66-178">`wasb:///`: Access default storage using unencrypted communication.</span></span>

* <span data-ttu-id="53b66-179">`wasbs:///`: Toegang standaard opslag met behulp van gecodeerde communicatie.</span><span class="sxs-lookup"><span data-stu-id="53b66-179">`wasbs:///`: Access default storage using encrypted communication.</span></span>  <span data-ttu-id="53b66-180">Het schema wasbs wordt alleen ondersteund vanuit HDInsight versie 3.6 en hoger.</span><span class="sxs-lookup"><span data-stu-id="53b66-180">The wasbs scheme is supported only from HDInsight version 3.6 onwards.</span></span>

* <span data-ttu-id="53b66-181">`wasb://<container-name>@<account-name>.blob.core.windows.net/`: Wordt gebruikt om te communiceren met een niet-standaard opslagaccount.</span><span class="sxs-lookup"><span data-stu-id="53b66-181">`wasb://<container-name>@<account-name>.blob.core.windows.net/`: Used when communicating with a non-default storage account.</span></span> <span data-ttu-id="53b66-182">Bijvoorbeeld, wanneer u hebt een extra storage-account of wanneer toegang tot gegevens opgeslagen in een openbaar toegankelijke storage-account.</span><span class="sxs-lookup"><span data-stu-id="53b66-182">For example, when you have an additional storage account or when accessing data stored in a publicly accessible storage account.</span></span>

<span data-ttu-id="53b66-183">Wanneer u __Data Lake Store__, gebruikt u een van de volgende URI-schema's:</span><span class="sxs-lookup"><span data-stu-id="53b66-183">When using __Data Lake Store__, use one of the following URI schemes:</span></span>

* <span data-ttu-id="53b66-184">`adl:///`: Toegang tot de standaard Data Lake Store voor het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-184">`adl:///`: Access the default Data Lake Store for the cluster.</span></span>

* <span data-ttu-id="53b66-185">`adl://<storage-name>.azuredatalakestore.net/`: Wordt gebruikt om te communiceren met een niet-standaard Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="53b66-185">`adl://<storage-name>.azuredatalakestore.net/`: Used when communicating with a non-default Data Lake Store.</span></span> <span data-ttu-id="53b66-186">Ook gebruikt voor toegang tot gegevens buiten de hoofdmap van uw HDInsight-cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-186">Also used to access data outside the root directory of your HDInsight cluster.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="53b66-187">Wanneer u de Data Lake Store als het standaardarchief voor HDInsight, moet u een pad in het archief te gebruiken als de hoofdmap van het HDInsight-opslag.</span><span class="sxs-lookup"><span data-stu-id="53b66-187">When using Data Lake Store as the default store for HDInsight, you must specify a path within the store to use as the root of HDInsight storage.</span></span> <span data-ttu-id="53b66-188">Het standaardpad is `/clusters/<cluster-name>/`.</span><span class="sxs-lookup"><span data-stu-id="53b66-188">The default path is `/clusters/<cluster-name>/`.</span></span>
>
> <span data-ttu-id="53b66-189">Wanneer u `/` of `adl:///` toegang tot gegevens u kunt alleen toegang tot gegevens die zijn opgeslagen in de hoofdmap (bijvoorbeeld `/clusters/<cluster-name>/`) van het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-189">When using `/` or `adl:///` to access data, you can only access data stored in the root (for example, `/clusters/<cluster-name>/`) of the cluster.</span></span> <span data-ttu-id="53b66-190">Toegang tot gegevens overal in de store gebruiken de `adl://<storage-name>.azuredatalakestore.net/` indeling.</span><span class="sxs-lookup"><span data-stu-id="53b66-190">To access data anywhere in the store, use the `adl://<storage-name>.azuredatalakestore.net/` format.</span></span>

### <a name="what-storage-is-the-cluster-using"></a><span data-ttu-id="53b66-191">Welke opslag wordt gebruikt voor het cluster</span><span class="sxs-lookup"><span data-stu-id="53b66-191">What storage is the cluster using</span></span>

<span data-ttu-id="53b66-192">U kunt Ambari gebruiken voor het ophalen van de standaardconfiguratie voor de opslag voor het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-192">You can use Ambari to retrieve the default storage configuration for the cluster.</span></span> <span data-ttu-id="53b66-193">Gebruik de volgende opdracht voor het ophalen van HDFS-configuratiegegevens met curl en filteren met behulp van [jq](https://stedolan.github.io/jq/):</span><span class="sxs-lookup"><span data-stu-id="53b66-193">Use the following command to retrieve HDFS configuration information using curl, and filter it using [jq](https://stedolan.github.io/jq/):</span></span>

```curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["fs.defaultFS"] | select(. != null)'```

> [!NOTE]
> <span data-ttu-id="53b66-194">Hiermee wordt de eerste configuratie is toegepast op de server (`service_config_version=1`), die deze informatie bevat.</span><span class="sxs-lookup"><span data-stu-id="53b66-194">This returns the first configuration applied to the server (`service_config_version=1`), which contains this information.</span></span> <span data-ttu-id="53b66-195">Mogelijk moet u alle versies van de configuratie om te zoeken naar het recentste is.</span><span class="sxs-lookup"><span data-stu-id="53b66-195">You may need to list all configuration versions to find the latest one.</span></span>

<span data-ttu-id="53b66-196">Met deze opdracht retourneert een waarde die vergelijkbaar is met de volgende URI's:</span><span class="sxs-lookup"><span data-stu-id="53b66-196">This command returns a value similar to the following URIs:</span></span>

* <span data-ttu-id="53b66-197">`wasb://<container-name>@<account-name>.blob.core.windows.net`Als een Azure Storage-account wordt gebruikt.</span><span class="sxs-lookup"><span data-stu-id="53b66-197">`wasb://<container-name>@<account-name>.blob.core.windows.net` if using an Azure Storage account.</span></span>

    <span data-ttu-id="53b66-198">De accountnaam is de naam van de Azure Storage-account, terwijl de containernaam van de is de blob-container is de hoofdmap van de clusteropslag.</span><span class="sxs-lookup"><span data-stu-id="53b66-198">The account name is the name of the Azure Storage account, while the container name is the blob container that is the root of the cluster storage.</span></span>

* <span data-ttu-id="53b66-199">`adl://home`Als u Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="53b66-199">`adl://home` if using Azure Data Lake Store.</span></span> <span data-ttu-id="53b66-200">Als u de naam van de Data Lake Store, gebruikt u de volgende REST-aanroep:</span><span class="sxs-lookup"><span data-stu-id="53b66-200">To get the Data Lake Store name, use the following REST call:</span></span>

    ```curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["dfs.adls.home.hostname"] | select(. != null)'```

    <span data-ttu-id="53b66-201">Met deze opdracht retourneert de volgende hostnaam: `<data-lake-store-account-name>.azuredatalakestore.net`.</span><span class="sxs-lookup"><span data-stu-id="53b66-201">This command returns the following host name: `<data-lake-store-account-name>.azuredatalakestore.net`.</span></span>

    <span data-ttu-id="53b66-202">Als u de map in het archief is de hoofdmap voor HDInsight, gebruikt u de volgende REST-aanroep:</span><span class="sxs-lookup"><span data-stu-id="53b66-202">To get the directory within the store that is the root for HDInsight, use the following REST call:</span></span>

    ```curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["dfs.adls.home.mountpoint"] | select(. != null)'```

    <span data-ttu-id="53b66-203">Met deze opdracht retourneert het pad van een vergelijkbaar met het volgende pad: `/clusters/<hdinsight-cluster-name>/`.</span><span class="sxs-lookup"><span data-stu-id="53b66-203">This command returns a path similar to the following path: `/clusters/<hdinsight-cluster-name>/`.</span></span>

<span data-ttu-id="53b66-204">U vindt ook de storage-gegevens met behulp van de Azure-portal met behulp van de volgende stappen uit:</span><span class="sxs-lookup"><span data-stu-id="53b66-204">You can also find the storage information using the Azure portal by using the following steps:</span></span>

1. <span data-ttu-id="53b66-205">In de [Azure-portal](https://portal.azure.com/), selecteer uw HDInsight-cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-205">In the [Azure portal](https://portal.azure.com/), select your HDInsight cluster.</span></span>

2. <span data-ttu-id="53b66-206">Van de **eigenschappen** sectie **Opslagaccounts**.</span><span class="sxs-lookup"><span data-stu-id="53b66-206">From the **Properties** section, select **Storage Accounts**.</span></span> <span data-ttu-id="53b66-207">De storage-gegevens voor het cluster wordt weergegeven.</span><span class="sxs-lookup"><span data-stu-id="53b66-207">The storage information for the cluster is displayed.</span></span>

### <a name="how-do-i-access-files-from-outside-hdinsight"></a><span data-ttu-id="53b66-208">Hoe krijg ik toegang tot bestanden uit buiten HDInsight</span><span class="sxs-lookup"><span data-stu-id="53b66-208">How do I access files from outside HDInsight</span></span>

<span data-ttu-id="53b66-209">Er zijn een verschillende manieren toegang krijgen tot gegevens van buiten het HDInsight-cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-209">There are a various ways to access data from outside the HDInsight cluster.</span></span> <span data-ttu-id="53b66-210">Hier volgen enkele koppelingen naar hulpprogramma's en SDK's die kunnen worden gebruikt om te werken met uw gegevens:</span><span class="sxs-lookup"><span data-stu-id="53b66-210">The following are a few links to utilities and SDKs that can be used to work with your data:</span></span>

<span data-ttu-id="53b66-211">Als u __Azure Storage__, Zie de volgende koppelingen voor dat u toegang hebt tot uw gegevens manieren:</span><span class="sxs-lookup"><span data-stu-id="53b66-211">If using __Azure Storage__, see the following links for ways that you can access your data:</span></span>

* <span data-ttu-id="53b66-212">[Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2): opdrachtregelinterface opdrachten voor het werken met Azure.</span><span class="sxs-lookup"><span data-stu-id="53b66-212">[Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2): Command-Line interface commands for working with Azure.</span></span> <span data-ttu-id="53b66-213">Na het installeren, gebruiken de `az storage` opdracht voor hulp bij het gebruik van opslag, of `az storage blob` voor blob-specifieke opdrachten.</span><span class="sxs-lookup"><span data-stu-id="53b66-213">After installing, use the `az storage` command for help on using storage, or `az storage blob` for blob-specific commands.</span></span>
* <span data-ttu-id="53b66-214">[blobxfer.PY](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage): een python-script voor het werken met blobs in Azure Storage.</span><span class="sxs-lookup"><span data-stu-id="53b66-214">[blobxfer.py](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage): A python script for working with blobs in Azure Storage.</span></span>
* <span data-ttu-id="53b66-215">Verschillende SDK's:</span><span class="sxs-lookup"><span data-stu-id="53b66-215">Various SDKs:</span></span>

    * [<span data-ttu-id="53b66-216">Java</span><span class="sxs-lookup"><span data-stu-id="53b66-216">Java</span></span>](https://github.com/Azure/azure-sdk-for-java)
    * [<span data-ttu-id="53b66-217">Node.js</span><span class="sxs-lookup"><span data-stu-id="53b66-217">Node.js</span></span>](https://github.com/Azure/azure-sdk-for-node)
    * [<span data-ttu-id="53b66-218">PHP</span><span class="sxs-lookup"><span data-stu-id="53b66-218">PHP</span></span>](https://github.com/Azure/azure-sdk-for-php)
    * [<span data-ttu-id="53b66-219">Python</span><span class="sxs-lookup"><span data-stu-id="53b66-219">Python</span></span>](https://github.com/Azure/azure-sdk-for-python)
    * [<span data-ttu-id="53b66-220">Ruby</span><span class="sxs-lookup"><span data-stu-id="53b66-220">Ruby</span></span>](https://github.com/Azure/azure-sdk-for-ruby)
    * [<span data-ttu-id="53b66-221">.NET</span><span class="sxs-lookup"><span data-stu-id="53b66-221">.NET</span></span>](https://github.com/Azure/azure-sdk-for-net)
    * [<span data-ttu-id="53b66-222">Opslag-REST-API</span><span class="sxs-lookup"><span data-stu-id="53b66-222">Storage REST API</span></span>](https://msdn.microsoft.com/library/azure/dd135733.aspx)

<span data-ttu-id="53b66-223">Als u __Azure Data Lake Store__, Zie de volgende koppelingen voor dat u toegang hebt tot uw gegevens manieren:</span><span class="sxs-lookup"><span data-stu-id="53b66-223">If using __Azure Data Lake Store__, see the following links for ways that you can access your data:</span></span>

* [<span data-ttu-id="53b66-224">Webbrowser</span><span class="sxs-lookup"><span data-stu-id="53b66-224">Web browser</span></span>](../data-lake-store/data-lake-store-get-started-portal.md)
* [<span data-ttu-id="53b66-225">PowerShell</span><span class="sxs-lookup"><span data-stu-id="53b66-225">PowerShell</span></span>](../data-lake-store/data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="53b66-226">Azure CLI 2.0</span><span class="sxs-lookup"><span data-stu-id="53b66-226">Azure CLI 2.0</span></span>](../data-lake-store/data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="53b66-227">WebHDFS REST-API</span><span class="sxs-lookup"><span data-stu-id="53b66-227">WebHDFS REST API</span></span>](../data-lake-store/data-lake-store-get-started-rest-api.md)
* [<span data-ttu-id="53b66-228">Data Lake Tools voor Visual Studio</span><span class="sxs-lookup"><span data-stu-id="53b66-228">Data Lake Tools for Visual Studio</span></span>](https://www.microsoft.com/download/details.aspx?id=49504)
* [<span data-ttu-id="53b66-229">.NET</span><span class="sxs-lookup"><span data-stu-id="53b66-229">.NET</span></span>](../data-lake-store/data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="53b66-230">Java</span><span class="sxs-lookup"><span data-stu-id="53b66-230">Java</span></span>](../data-lake-store/data-lake-store-get-started-java-sdk.md)
* [<span data-ttu-id="53b66-231">Python</span><span class="sxs-lookup"><span data-stu-id="53b66-231">Python</span></span>](../data-lake-store/data-lake-store-get-started-python.md)

## <span data-ttu-id="53b66-232"><a name="scaling"></a>Uw cluster schalen</span><span class="sxs-lookup"><span data-stu-id="53b66-232"><a name="scaling"></a>Scaling your cluster</span></span>

<span data-ttu-id="53b66-233">Het schalen van de functie cluster kunt u het aantal gegevensknooppunten die worden gebruikt door een cluster dynamisch te wijzigen.</span><span class="sxs-lookup"><span data-stu-id="53b66-233">The cluster scaling feature allows you to dynamically change the number of data nodes used by a cluster.</span></span> <span data-ttu-id="53b66-234">U kunt vergroten/verkleinen bewerkingen terwijl andere taken uitvoeren of processen worden uitgevoerd op een cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-234">You can perform scaling operations while other jobs or processes are running on a cluster.</span></span>

<span data-ttu-id="53b66-235">De verschillende clustertypen worden beïnvloed door de schaal als volgt:</span><span class="sxs-lookup"><span data-stu-id="53b66-235">The different cluster types are affected by scaling as follows:</span></span>

* <span data-ttu-id="53b66-236">**Hadoop**: bij het verkleinen van het aantal knooppunten in een cluster, zijn sommige van de services in het cluster opnieuw gestart.</span><span class="sxs-lookup"><span data-stu-id="53b66-236">**Hadoop**: When scaling down the number of nodes in a cluster, some of the services in the cluster are restarted.</span></span> <span data-ttu-id="53b66-237">Schalen operations kan leiden tot taken actief of in behandeling mislukken na het voltooien van de bewerking uit te schalen.</span><span class="sxs-lookup"><span data-stu-id="53b66-237">Scaling operations can cause jobs running or pending to fail at the completion of the scaling operation.</span></span> <span data-ttu-id="53b66-238">Nadat de bewerking voltooid is, kunt u de taken opnieuw indienen.</span><span class="sxs-lookup"><span data-stu-id="53b66-238">You can resubmit the jobs once the operation is complete.</span></span>
* <span data-ttu-id="53b66-239">**HBase**: regionale servers automatisch worden verdeeld binnen een paar minuten na voltooiing van de bewerking uit te schalen.</span><span class="sxs-lookup"><span data-stu-id="53b66-239">**HBase**: Regional servers are automatically balanced within a few minutes after completion of the scaling operation.</span></span> <span data-ttu-id="53b66-240">Handmatig evenwichtige regionale servers, gebruikt u de volgende stappen uit:</span><span class="sxs-lookup"><span data-stu-id="53b66-240">To manually balance regional servers, use the following steps:</span></span>

    1. <span data-ttu-id="53b66-241">Verbinding maken met het HDInsight-cluster via SSH.</span><span class="sxs-lookup"><span data-stu-id="53b66-241">Connect to the HDInsight cluster using SSH.</span></span> <span data-ttu-id="53b66-242">Zie [SSH gebruiken met HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="53b66-242">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

    2. <span data-ttu-id="53b66-243">Gebruik de volgende de HBase-shell starten:</span><span class="sxs-lookup"><span data-stu-id="53b66-243">Use the following to start the HBase shell:</span></span>

            hbase shell

    3. <span data-ttu-id="53b66-244">Nadat de HBase-shell is geladen, gebruikt u de volgende om handmatig de regionale servers:</span><span class="sxs-lookup"><span data-stu-id="53b66-244">Once the HBase shell has loaded, use the following to manually balance the regional servers:</span></span>

            balancer

* <span data-ttu-id="53b66-245">**Storm**: U moet eventuele actieve Storm-topologieën opnieuw verdelen nadat een vergroten/verkleinen-bewerking is uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="53b66-245">**Storm**: You should rebalance any running Storm topologies after a scaling operation has been performed.</span></span> <span data-ttu-id="53b66-246">Herverdeling, kunt de topologie past u instellingen voor parallelle uitvoering op basis van het nieuwe aantal knooppunten in het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-246">Rebalancing allows the topology to readjust parallelism settings based on the new number of nodes in the cluster.</span></span> <span data-ttu-id="53b66-247">Om actieve topologieën opnieuw verdelen, gebruikt u een van de volgende opties:</span><span class="sxs-lookup"><span data-stu-id="53b66-247">To rebalance running topologies, use one of the following options:</span></span>

    * <span data-ttu-id="53b66-248">**SSH**: verbinding maken met de server en gebruik de volgende opdracht opnieuw verdelen een topologie:</span><span class="sxs-lookup"><span data-stu-id="53b66-248">**SSH**: Connect to the server and use the following command to rebalance a topology:</span></span>

            storm rebalance TOPOLOGYNAME

        <span data-ttu-id="53b66-249">U kunt ook parameters voor het overschrijven van de parallelle uitvoering hints oorspronkelijk is geleverd door de topologie opgeven.</span><span class="sxs-lookup"><span data-stu-id="53b66-249">You can also specify parameters to override the parallelism hints originally provided by the topology.</span></span> <span data-ttu-id="53b66-250">Bijvoorbeeld, `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` de topologie 5 werkprocessen, 3 Executor voor het onderdeel blauw spout en 10 Executor voor het onderdeel geel bolt geconfigureerd.</span><span class="sxs-lookup"><span data-stu-id="53b66-250">For example, `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` reconfigures the topology to 5 worker processes, 3 executors for the blue-spout component, and 10 executors for the yellow-bolt component.</span></span>

    * <span data-ttu-id="53b66-251">**Storm-gebruikersinterface**: Gebruik de volgende stappen een topologie met behulp van de Storm-gebruikersinterface opnieuw verdelen.</span><span class="sxs-lookup"><span data-stu-id="53b66-251">**Storm UI**: Use the following steps to rebalance a topology using the Storm UI.</span></span>

        1. <span data-ttu-id="53b66-252">Open **https://CLUSTERNAME.azurehdinsight.NET/stormui** in uw webbrowser, waarbij CLUSTERNAME de naam van uw Storm-cluster is.</span><span class="sxs-lookup"><span data-stu-id="53b66-252">Open **https://CLUSTERNAME.azurehdinsight.net/stormui** in your web browser, where CLUSTERNAME is the name of your Storm cluster.</span></span> <span data-ttu-id="53b66-253">Als u wordt gevraagd, voert u de HDInsight-cluster (admin) beheerdersnaam en het wachtwoord die u hebt opgegeven bij het maken van het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-253">If prompted, enter the HDInsight cluster administrator (admin) name and password you specified when creating the cluster.</span></span>
        2. <span data-ttu-id="53b66-254">Selecteer de topologie die u wilt opnieuw verdelen en selecteer vervolgens de **opnieuw verdelen** knop.</span><span class="sxs-lookup"><span data-stu-id="53b66-254">Select the topology you wish to rebalance, then select the **Rebalance** button.</span></span> <span data-ttu-id="53b66-255">Voer de wachttijd voordat de bewerking deel opnieuw wordt uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="53b66-255">Enter the delay before the rebalance operation is performed.</span></span>

<span data-ttu-id="53b66-256">Zie voor specifieke informatie over het schalen van uw HDInsight-cluster:</span><span class="sxs-lookup"><span data-stu-id="53b66-256">For specific information on scaling your HDInsight cluster, see:</span></span>

* [<span data-ttu-id="53b66-257">Hadoop-clusters in HDInsight beheren met behulp van de Azure-portal</span><span class="sxs-lookup"><span data-stu-id="53b66-257">Manage Hadoop clusters in HDInsight by using the Azure portal</span></span>](hdinsight-administer-use-portal-linux.md#scale-clusters)
* [<span data-ttu-id="53b66-258">Hadoop-clusters in HDInsight met behulp van Azure PowerShell beheren</span><span class="sxs-lookup"><span data-stu-id="53b66-258">Manage Hadoop clusters in HDInsight by using Azure PowerShell</span></span>](hdinsight-administer-use-command-line.md#scale-clusters)

## <a name="how-do-i-install-hue-or-other-hadoop-component"></a><span data-ttu-id="53b66-259">Hoe installeer ik Hue (of andere onderdelen van Hadoop)?</span><span class="sxs-lookup"><span data-stu-id="53b66-259">How do I install Hue (or other Hadoop component)?</span></span>

<span data-ttu-id="53b66-260">HDInsight is een beheerde service.</span><span class="sxs-lookup"><span data-stu-id="53b66-260">HDInsight is a managed service.</span></span> <span data-ttu-id="53b66-261">Als Azure een probleem met het cluster detecteert, kan het verwijderen van het knooppunt mislukt en maakt u een knooppunt om deze te vervangen.</span><span class="sxs-lookup"><span data-stu-id="53b66-261">If Azure detects a problem with the cluster, it may delete the failing node and create a node to replace it.</span></span> <span data-ttu-id="53b66-262">Als u dingen handmatig op het cluster installeren, worden ze niet behouden als deze bewerking doet zich.</span><span class="sxs-lookup"><span data-stu-id="53b66-262">If you manually install things on the cluster, they are not persisted when this operation occurs.</span></span> <span data-ttu-id="53b66-263">Gebruik in plaats daarvan [HDInsight scriptacties](hdinsight-hadoop-customize-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="53b66-263">Instead, use [HDInsight Script Actions](hdinsight-hadoop-customize-cluster.md).</span></span> <span data-ttu-id="53b66-264">Een scriptactie kan worden gebruikt om de volgende wijzigingen:</span><span class="sxs-lookup"><span data-stu-id="53b66-264">A script action can be used to make the following changes:</span></span>

* <span data-ttu-id="53b66-265">Installeren en configureren van een service of de website zoals Spark of Hue.</span><span class="sxs-lookup"><span data-stu-id="53b66-265">Install and configure a service or web site such as Spark or Hue.</span></span>
* <span data-ttu-id="53b66-266">Installeren en configureren van een onderdeel dat wijzigingen in de configuratie op meerdere knooppunten in het cluster vereist.</span><span class="sxs-lookup"><span data-stu-id="53b66-266">Install and configure a component that requires configuration changes on multiple nodes in the cluster.</span></span> <span data-ttu-id="53b66-267">Een vereiste omgeving-variabele, maken van een map voor logboekregistratie of maken van een configuratiebestand.</span><span class="sxs-lookup"><span data-stu-id="53b66-267">For example, a required environment variable, creating of a logging directory, or creation of a configuration file.</span></span>

<span data-ttu-id="53b66-268">Scriptacties zijn Bash-scripts.</span><span class="sxs-lookup"><span data-stu-id="53b66-268">Script Actions are Bash scripts.</span></span> <span data-ttu-id="53b66-269">De scripts uitgevoerd tijdens de clusterinrichting en kunnen worden gebruikt voor het installeren en configureren van extra onderdelen op het cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-269">The scripts run during cluster provisioning, and can be used to install and configure additional components on the cluster.</span></span> <span data-ttu-id="53b66-270">Van de voorbeeldscripts zijn beschikbaar voor het installeren van de volgende onderdelen:</span><span class="sxs-lookup"><span data-stu-id="53b66-270">Example scripts are provided for installing the following components:</span></span>

* [<span data-ttu-id="53b66-271">HUE</span><span class="sxs-lookup"><span data-stu-id="53b66-271">Hue</span></span>](hdinsight-hadoop-hue-linux.md)
* [<span data-ttu-id="53b66-272">Giraph</span><span class="sxs-lookup"><span data-stu-id="53b66-272">Giraph</span></span>](hdinsight-hadoop-giraph-install-linux.md)
* [<span data-ttu-id="53b66-273">Solr</span><span class="sxs-lookup"><span data-stu-id="53b66-273">Solr</span></span>](hdinsight-hadoop-solr-install-linux.md)

<span data-ttu-id="53b66-274">Zie [Ontwikkeling van scriptacties met HDInsight](hdinsight-hadoop-script-actions-linux.md) voor informatie over het ontwikkelen van uw eigen scriptacties.</span><span class="sxs-lookup"><span data-stu-id="53b66-274">For information on developing your own Script Actions, see [Script Action development with HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span>

### <a name="jar-files"></a><span data-ttu-id="53b66-275">JAR-bestanden</span><span class="sxs-lookup"><span data-stu-id="53b66-275">Jar files</span></span>

<span data-ttu-id="53b66-276">Bij sommige technologieën Hadoop vindt u in zelfstandige jar-bestanden met functies die worden gebruikt als onderdeel van een MapReduce-taak of in Pig- of Hive.</span><span class="sxs-lookup"><span data-stu-id="53b66-276">Some Hadoop technologies are provided in self-contained jar files that contain functions used as part of a MapReduce job, or from inside Pig or Hive.</span></span> <span data-ttu-id="53b66-277">Terwijl deze kunnen worden geïnstalleerd met behulp van scriptacties, kunnen vaak geen geen installatie vereist en worden geüpload naar het cluster na het inrichten en rechtstreeks worden gebruikt.</span><span class="sxs-lookup"><span data-stu-id="53b66-277">While these can be installed using Script Actions, they often don't require any setup and can be uploaded to the cluster after provisioning and used directly.</span></span> <span data-ttu-id="53b66-278">Als u wilt controleren of dat het onderdeel blijft installatiekopie van het cluster, kunt u het jar-bestand opslaan in de standaard-opslag voor uw cluster (WASB of ADL).</span><span class="sxs-lookup"><span data-stu-id="53b66-278">If you want to make sure the component survives reimaging of the cluster, you can store the jar file in the default storage for your cluster (WASB or ADL).</span></span>

<span data-ttu-id="53b66-279">Bijvoorbeeld, als u wilt gebruiken, de nieuwste versie van [DataFu](http://datafu.incubator.apache.org/), kunt u downloaden van een jar dat het project bevat en dit uploaden naar het HDInsight-cluster.</span><span class="sxs-lookup"><span data-stu-id="53b66-279">For example, if you want to use the latest version of [DataFu](http://datafu.incubator.apache.org/), you can download a jar containing the project and upload it to the HDInsight cluster.</span></span> <span data-ttu-id="53b66-280">Volg de documentatie van DataFu op het gebruik van Pig- of Hive.</span><span class="sxs-lookup"><span data-stu-id="53b66-280">Then follow the DataFu documentation on how to use it from Pig or Hive.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="53b66-281">Sommige onderdelen die zelfstandige jar-bestanden zijn worden voorzien van HDInsight, maar zijn niet in het pad.</span><span class="sxs-lookup"><span data-stu-id="53b66-281">Some components that are standalone jar files are provided with HDInsight, but are not in the path.</span></span> <span data-ttu-id="53b66-282">Als u naar een specifiek onderdeel zoekt, kunt u de volgende zoekt op het cluster:</span><span class="sxs-lookup"><span data-stu-id="53b66-282">If you are looking for a specific component, you can use the follow to search for it on your cluster:</span></span>
>
> ```find / -name *componentname*.jar 2>/dev/null```
>
> <span data-ttu-id="53b66-283">Deze opdracht retourneert het pad van alle overeenkomende jar-bestanden.</span><span class="sxs-lookup"><span data-stu-id="53b66-283">This command returns the path of any matching jar files.</span></span>

<span data-ttu-id="53b66-284">Upload de versie die u nodig hebt en deze gebruiken in uw taken voor het gebruik van een andere versie van een onderdeel.</span><span class="sxs-lookup"><span data-stu-id="53b66-284">To use a different version of a component, upload the version you need and use it in your jobs.</span></span>

> [!WARNING]
> <span data-ttu-id="53b66-285">Onderdelen van het HDInsight-cluster worden volledig ondersteund en Microsoft Support kunt opsporen en oplossen van problemen met betrekking tot deze onderdelen.</span><span class="sxs-lookup"><span data-stu-id="53b66-285">Components provided with the HDInsight cluster are fully supported and Microsoft Support helps to isolate and resolve issues related to these components.</span></span>
>
> <span data-ttu-id="53b66-286">Aangepaste onderdelen ontvangt binnen commercieel redelijke ondersteuning u helpen het probleem verder op te lossen.</span><span class="sxs-lookup"><span data-stu-id="53b66-286">Custom components receive commercially reasonable support to help you to further troubleshoot the issue.</span></span> <span data-ttu-id="53b66-287">Dit kan leiden tot het oplossen van het probleem of vraag of u benaderen beschikbare kanalen voor de open-source technologieën waar grondige kennis van deze technologie kan worden gevonden.</span><span class="sxs-lookup"><span data-stu-id="53b66-287">This might result in resolving the issue OR asking you to engage available channels for the open source technologies where deep expertise for that technology is found.</span></span> <span data-ttu-id="53b66-288">Bijvoorbeeld: Er zijn veel community-sites die kunnen worden gebruikt, zoals: [MSDN-forum voor HDInsight](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight), [http://stackoverflow.com](http://stackoverflow.com).</span><span class="sxs-lookup"><span data-stu-id="53b66-288">For example, there are many community sites that can be used, like: [MSDN forum for HDInsight](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight), [http://stackoverflow.com](http://stackoverflow.com).</span></span> <span data-ttu-id="53b66-289">Ook hebben Apache projecten project-sites op [http://apache.org](http://apache.org), bijvoorbeeld: [Hadoop](http://hadoop.apache.org/), [Spark](http://spark.apache.org/).</span><span class="sxs-lookup"><span data-stu-id="53b66-289">Also Apache projects have project sites on [http://apache.org](http://apache.org), for example: [Hadoop](http://hadoop.apache.org/), [Spark](http://spark.apache.org/).</span></span>

## <a name="next-steps"></a><span data-ttu-id="53b66-290">Volgende stappen</span><span class="sxs-lookup"><span data-stu-id="53b66-290">Next steps</span></span>

* [<span data-ttu-id="53b66-291">Migreren van HDInsight op basis van Windows naar op basis van Linux</span><span class="sxs-lookup"><span data-stu-id="53b66-291">Migrate from Windows-based HDInsight to Linux-based</span></span>](hdinsight-migrate-from-windows-to-linux.md)
* [<span data-ttu-id="53b66-292">Hive gebruiken met HDInsight</span><span class="sxs-lookup"><span data-stu-id="53b66-292">Use Hive with HDInsight</span></span>](hdinsight-use-hive.md)
* [<span data-ttu-id="53b66-293">Pig gebruiken met HDInsight</span><span class="sxs-lookup"><span data-stu-id="53b66-293">Use Pig with HDInsight</span></span>](hdinsight-use-pig.md)
* [<span data-ttu-id="53b66-294">MapReduce-taken gebruiken met HDInsight</span><span class="sxs-lookup"><span data-stu-id="53b66-294">Use MapReduce jobs with HDInsight</span></span>](hdinsight-use-mapreduce.md)
