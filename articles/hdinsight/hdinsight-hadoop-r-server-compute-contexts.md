---
title: Opties van de context voor R Server op HDInsight - Azure COMPUTE | Microsoft Docs
description: Meer informatie over de verschillende rekenscenario context opties beschikbaar voor gebruikers met R Server op HDInsight
services: HDInsight
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 0deb0b1c-4094-459b-94fc-ec9b774c1f8a
ms.service: HDInsight
ms.custom: hdinsightactive
ms.devlang: R
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/19/2017
ms.author: bradsev
ms.openlocfilehash: 47f4441612be4f363ba82cc22b09786a6f3bfdc3
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/29/2017
---
# <a name="compute-context-options-for-r-server-on-hdinsight"></a><span data-ttu-id="4ccd8-103">COMPUTE context opties voor R Server op HDInsight</span><span class="sxs-lookup"><span data-stu-id="4ccd8-103">Compute context options for R Server on HDInsight</span></span>

<span data-ttu-id="4ccd8-104">Microsoft R Server op Azure HDInsight bepaalt hoe aanroepen worden uitgevoerd door de instelling van de compute-context.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-104">Microsoft R Server on Azure HDInsight controls how calls are executed by setting the compute context.</span></span> <span data-ttu-id="4ccd8-105">In dit artikel bevat een overzicht van de opties die beschikbaar zijn om op te geven of en hoe de uitvoering is geparallelliseerde over kernen van de edge-knooppunt of de HDInsight-cluster.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-105">This article outlines the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span>

<span data-ttu-id="4ccd8-106">Het edge-knooppunt van een cluster is een handige locatie verbinding maken met het cluster en voor het uitvoeren van uw R-scripts.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-106">The edge node of a cluster provides a convenient place to connect to the cluster and to run your R scripts.</span></span> <span data-ttu-id="4ccd8-107">Met een edge-knooppunt hebt u de optie van de parallelized gedistribueerde functies van ScaleR over de kernen van de edge-knooppunt server wordt uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-107">With an edge node, you have the option of running the parallelized distributed functions of ScaleR across the cores of the edge node server.</span></span> <span data-ttu-id="4ccd8-108">U kunt ook deze uitvoeren op de knooppunten van het cluster met behulp van ScaleR Hadoop kaart verminderen of Spark compute-contexten.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-108">You can also run them across the nodes of the cluster by using ScaleR’s Hadoop Map Reduce or Spark compute contexts.</span></span>

## <a name="microsoft-r-server-on-azure-hdinsight"></a><span data-ttu-id="4ccd8-109">Microsoft R Server op Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="4ccd8-109">Microsoft R Server on Azure HDInsight</span></span>
<span data-ttu-id="4ccd8-110">[Microsoft R Server op Azure HDInsight](hdinsight-hadoop-r-server-overview.md) biedt de nieuwste mogelijkheden voor analyses op basis van R.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-110">[Microsoft R Server on Azure HDInsight](hdinsight-hadoop-r-server-overview.md) provides the latest capabilities for R-based analytics.</span></span> <span data-ttu-id="4ccd8-111">Het kan gebruiken gegevens die zijn opgeslagen in een HDFS-container in uw [Azure Blob](../storage/common/storage-introduction.md "Azure Blob storage") storage-account, een Data Lake store of het lokale bestandssysteem van Linux.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-111">It can use data that is stored in an HDFS container in your [Azure Blob](../storage/common/storage-introduction.md "Azure Blob storage") storage account, a Data Lake store, or the local Linux file system.</span></span> <span data-ttu-id="4ccd8-112">Aangezien R Server is gebouwd op open-source R, wordt in de R-toepassingen die u bouwt de 8000 + open-source R-pakketten kunnen toepassen.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-112">Since R Server is built on open source R, the R-based applications you build can apply any of the 8000+ open source R packages.</span></span> <span data-ttu-id="4ccd8-113">Ze kunnen ook de routines in gebruiken [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), van Microsoft big analytics gegevenspakket die is opgenomen in R Server.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-113">They can also use the routines in [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), Microsoft’s big data analytics package that is included with R Server.</span></span>  

## <a name="compute-contexts-for-an-edge-node"></a><span data-ttu-id="4ccd8-114">COMPUTE contexten voor een edge-knooppunt</span><span class="sxs-lookup"><span data-stu-id="4ccd8-114">Compute contexts for an edge node</span></span>
<span data-ttu-id="4ccd8-115">In het algemeen een R-script wordt uitgevoerd in R Server op de edge-knooppunt uitgevoerd binnen de R-interpreter op dat knooppunt.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-115">In general, an R script that's run in R Server on the edge node runs within the R interpreter on that node.</span></span> <span data-ttu-id="4ccd8-116">De uitzonderingen zijn de stappen die een ScaleR functie aanroept.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-116">The exceptions are those steps that call a ScaleR function.</span></span> <span data-ttu-id="4ccd8-117">Het aanroepen van de ScaleR uitgevoerd in een compute-omgeving die wordt bepaald door de manier waarop u de context van de compute ScaleR instelt.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-117">The ScaleR calls run in a compute environment that is determined by how you set the ScaleR compute context.</span></span>  <span data-ttu-id="4ccd8-118">Wanneer u uw R-script vanaf een edge-knooppunt uitvoeren, wordt de mogelijke waarden van de compute-context zijn:</span><span class="sxs-lookup"><span data-stu-id="4ccd8-118">When you run your R script from an edge node, the possible values of the compute context are:</span></span>

- <span data-ttu-id="4ccd8-119">lokale opeenvolgende (*'local'*)</span><span class="sxs-lookup"><span data-stu-id="4ccd8-119">local sequential (*‘local’*)</span></span>
- <span data-ttu-id="4ccd8-120">lokale parallel (*'localpar'*)</span><span class="sxs-lookup"><span data-stu-id="4ccd8-120">local parallel (*‘localpar’*)</span></span>
- <span data-ttu-id="4ccd8-121">Kaart verminderen</span><span class="sxs-lookup"><span data-stu-id="4ccd8-121">Map Reduce</span></span>
- <span data-ttu-id="4ccd8-122">Spark</span><span class="sxs-lookup"><span data-stu-id="4ccd8-122">Spark</span></span>

<span data-ttu-id="4ccd8-123">De *'local'* en *'localpar'* opties verschillen alleen in het **rxExec** aanroepen uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-123">The *‘local’* and *‘localpar’* options differ only in how **rxExec** calls are executed.</span></span> <span data-ttu-id="4ccd8-124">Ze beide uitgevoerd andere rx-functieaanroepen op een parallelle manier over alle beschikbare kernen tenzij anders is aangegeven door het gebruik van de ScaleR **numCoresToUse** optie, bijvoorbeeld `rxOptions(numCoresToUse=6)`.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-124">They both execute other rx-function calls in a parallel manner across all available cores unless specified otherwise through use of the ScaleR **numCoresToUse** option, for example `rxOptions(numCoresToUse=6)`.</span></span> <span data-ttu-id="4ccd8-125">Parallelle uitvoeringsopties bieden optimale prestaties.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-125">Parallel execution options offer optimal performance.</span></span>

<span data-ttu-id="4ccd8-126">De volgende tabel geeft een overzicht van de verschillende compute context opties in te stellen hoe aanroepen uitgevoerd:</span><span class="sxs-lookup"><span data-stu-id="4ccd8-126">The following table summarizes the various compute context options to set how calls are executed:</span></span>

| <span data-ttu-id="4ccd8-127">COMPUTE-context</span><span class="sxs-lookup"><span data-stu-id="4ccd8-127">Compute context</span></span>  | <span data-ttu-id="4ccd8-128">Het instellen</span><span class="sxs-lookup"><span data-stu-id="4ccd8-128">How to set</span></span>                      | <span data-ttu-id="4ccd8-129">Uitvoeringscontext</span><span class="sxs-lookup"><span data-stu-id="4ccd8-129">Execution context</span></span>                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| <span data-ttu-id="4ccd8-130">Lokale sequentiële</span><span class="sxs-lookup"><span data-stu-id="4ccd8-130">Local sequential</span></span> | <span data-ttu-id="4ccd8-131">rxSetComputeContext('local')</span><span class="sxs-lookup"><span data-stu-id="4ccd8-131">rxSetComputeContext(‘local’)</span></span>    | <span data-ttu-id="4ccd8-132">Uitvoering geparallelliseerde over de kernen van de edge-knooppunt server, met uitzondering van rxExec-aanroepen, opeenvolgend worden uitgevoerd</span><span class="sxs-lookup"><span data-stu-id="4ccd8-132">Parallelized execution across the cores of the edge node server, except for rxExec calls, which are executed serially</span></span> |
| <span data-ttu-id="4ccd8-133">Lokale parallel</span><span class="sxs-lookup"><span data-stu-id="4ccd8-133">Local parallel</span></span>   | <span data-ttu-id="4ccd8-134">rxSetComputeContext('localpar')</span><span class="sxs-lookup"><span data-stu-id="4ccd8-134">rxSetComputeContext(‘localpar’)</span></span> | <span data-ttu-id="4ccd8-135">Uitvoering geparallelliseerde over de kernen van de edge-knooppunt-server</span><span class="sxs-lookup"><span data-stu-id="4ccd8-135">Parallelized execution across the cores of the edge node server</span></span> |
| <span data-ttu-id="4ccd8-136">Spark</span><span class="sxs-lookup"><span data-stu-id="4ccd8-136">Spark</span></span>            | <span data-ttu-id="4ccd8-137">RxSpark()</span><span class="sxs-lookup"><span data-stu-id="4ccd8-137">RxSpark()</span></span>                       | <span data-ttu-id="4ccd8-138">Geparallelliseerde gedistribueerde uit te voeren via Spark op de knooppunten van het HDI-cluster</span><span class="sxs-lookup"><span data-stu-id="4ccd8-138">Parallelized distributed execution via Spark across the nodes of the HDI cluster</span></span> |
| <span data-ttu-id="4ccd8-139">Kaart verminderen</span><span class="sxs-lookup"><span data-stu-id="4ccd8-139">Map Reduce</span></span>       | <span data-ttu-id="4ccd8-140">RxHadoopMR()</span><span class="sxs-lookup"><span data-stu-id="4ccd8-140">RxHadoopMR()</span></span>                    | <span data-ttu-id="4ccd8-141">Geparallelliseerde gedistribueerde worden uitgevoerd via toewijzing verminderen op de knooppunten van het HDI-cluster</span><span class="sxs-lookup"><span data-stu-id="4ccd8-141">Parallelized distributed execution via Map Reduce across the nodes of the HDI cluster</span></span> |

## <a name="guidelines-for-deciding-on-a-compute-context"></a><span data-ttu-id="4ccd8-142">Richtlijnen voor het kiezen van een compute-context</span><span class="sxs-lookup"><span data-stu-id="4ccd8-142">Guidelines for deciding on a compute context</span></span>

<span data-ttu-id="4ccd8-143">Welke van de drie opties die u kiest die geparallelliseerde uitvoering bieden is afhankelijk van de aard van uw werk analytics, de grootte en de locatie van uw gegevens.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-143">Which of the three options you choose that provide parallelized execution depends on the nature of your analytics work, the size, and the location of your data.</span></span> <span data-ttu-id="4ccd8-144">Er is geen eenvoudige formule waarin wordt uitgelegd welke compute context moet worden gebruikt.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-144">There is no simple formula that tells you which compute context to use.</span></span> <span data-ttu-id="4ccd8-145">Er zijn echter enkele principes kunt u de juiste keuze te maken of ten minste, zodat u kunt beperken uw keuzes gemaakt voordat u een benchmark uitvoert.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-145">There are, however, some guiding principles that can help you make the right choice, or, at least, help you narrow down your choices before you run a benchmark.</span></span> <span data-ttu-id="4ccd8-146">Deze richtsnoer omvatten:</span><span class="sxs-lookup"><span data-stu-id="4ccd8-146">These guiding principles include:</span></span>

- <span data-ttu-id="4ccd8-147">Het lokale Linux-bestandssysteem is sneller dan HDFS.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-147">The local Linux file system is faster than HDFS.</span></span>
- <span data-ttu-id="4ccd8-148">Herhaalde analyses zijn sneller als de gegevens lokaal is en als het zich in XDF.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-148">Repeated analyses are faster if the data is local, and if it's in XDF.</span></span>
- <span data-ttu-id="4ccd8-149">Is het raadzaam om te streamen kleine hoeveelheden gegevens uit een tekst-gegevensbron.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-149">It's preferable to stream small amounts of data from a text data source.</span></span> <span data-ttu-id="4ccd8-150">Als de hoeveelheid gegevens groter is, deze converteren naar XDF voor analyse.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-150">If the amount of data is larger, convert it to XDF before analysis.</span></span>
- <span data-ttu-id="4ccd8-151">De overhead voor het kopiëren van of de gegevens naar het edge-knooppunt voor analyse streaming wordt voor zeer grote hoeveelheden gegevens.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-151">The overhead of copying or streaming the data to the edge node for analysis becomes unmanageable for very large amounts of data.</span></span>
- <span data-ttu-id="4ccd8-152">Spark is sneller dan kaart verminderen voor analyse in Hadoop.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-152">Spark is faster than Map Reduce for analysis in Hadoop.</span></span>

<span data-ttu-id="4ccd8-153">Deze principes gezien, bieden de volgende secties een aantal algemene regels van miniatuur voor het selecteren van een compute-context.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-153">Given these principles, the following sections offer some general rules of thumb for selecting a compute context.</span></span>

### <a name="local"></a><span data-ttu-id="4ccd8-154">Lokaal</span><span class="sxs-lookup"><span data-stu-id="4ccd8-154">Local</span></span>
* <span data-ttu-id="4ccd8-155">Als de hoeveelheid gegevens te analyseren klein is en geen herhaalde analyse vereist, klikt u vervolgens stream deze rechtstreeks in de analysis routinematige via *'local'* of *'localpar'*.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-155">If the amount of data to analyze is small and does not require repeated analysis, then stream it directly into the analysis routine using *'local'* or *'localpar'*.</span></span>
* <span data-ttu-id="4ccd8-156">Als de hoeveelheid gegevens te analyseren kleine of middelgrote en herhaalde analyse is vereist, klikt u vervolgens kopiëren naar het lokale bestandssysteem op XDF importeren en analyseren via *'local'* of *'localpar'*.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-156">If the amount of data to analyze is small or medium-sized and requires repeated analysis, then copy it to the local file system, import it to XDF, and analyze it via *'local'* or *'localpar'*.</span></span>

### <a name="hadoop-spark"></a><span data-ttu-id="4ccd8-157">Hadoop, Spark</span><span class="sxs-lookup"><span data-stu-id="4ccd8-157">Hadoop Spark</span></span>
* <span data-ttu-id="4ccd8-158">Als de hoeveelheid gegevens te analyseren groot is, dan importeren naar een Spark-DataFrame met **RxHiveData** of **RxParquetData**, of XDF in HDFS (tenzij er een probleem is met de opslag), en analyseren met behulp van de compute Spark context.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-158">If the amount of data to analyze is large, then import it to a Spark DataFrame using **RxHiveData** or **RxParquetData**, or to XDF in HDFS (unless storage is an issue), and analyze it using the Spark compute context.</span></span>

### <a name="hadoop-map-reduce"></a><span data-ttu-id="4ccd8-159">Beperken van Hadoop-kaart</span><span class="sxs-lookup"><span data-stu-id="4ccd8-159">Hadoop Map Reduce</span></span>
* <span data-ttu-id="4ccd8-160">De kaart verminderen compute-context alleen gebruiken als u een onoverkomelijke probleem met de compute-context voor Spark optreden omdat in het algemeen langzamer.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-160">Use the Map Reduce compute context only if you encounter an insurmountable problem with the Spark compute context since it is generally slower.</span></span>  

## <a name="inline-help-on-rxsetcomputecontext"></a><span data-ttu-id="4ccd8-161">Inline-help op rxSetComputeContext</span><span class="sxs-lookup"><span data-stu-id="4ccd8-161">Inline help on rxSetComputeContext</span></span>
<span data-ttu-id="4ccd8-162">Zie voor meer informatie over en voorbeelden van ScaleR compute contexten, de inline in R help bij de methode rxSetComputeContext, bijvoorbeeld:</span><span class="sxs-lookup"><span data-stu-id="4ccd8-162">For more information and examples of ScaleR compute contexts, see the inline help in R on the rxSetComputeContext method, for example:</span></span>

    > ?rxSetComputeContext

<span data-ttu-id="4ccd8-163">U kunt ook verwijzen naar de '[ScaleR gedistribueerde Computing handleiding](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)' die beschikbaar is in de [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server op MSDN") bibliotheek.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-163">You can also refer to the “[ScaleR Distributed Computing Guide](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)” that's available from the [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server on MSDN") library.</span></span>

## <a name="next-steps"></a><span data-ttu-id="4ccd8-164">Volgende stappen</span><span class="sxs-lookup"><span data-stu-id="4ccd8-164">Next steps</span></span>
<span data-ttu-id="4ccd8-165">In dit artikel hebt u geleerd over de opties die beschikbaar zijn om op te geven of en hoe de uitvoering is geparallelliseerde over kernen van de edge-knooppunt of de HDInsight-cluster.</span><span class="sxs-lookup"><span data-stu-id="4ccd8-165">In this article, you learned about the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span> <span data-ttu-id="4ccd8-166">Zie de volgende onderwerpen voor meer informatie over het gebruik van R Server met HDInsight-clusters:</span><span class="sxs-lookup"><span data-stu-id="4ccd8-166">To learn more about how to use R Server with HDInsight clusters, see the following topics:</span></span>

* [<span data-ttu-id="4ccd8-167">Overzicht van R Server voor Hadoop</span><span class="sxs-lookup"><span data-stu-id="4ccd8-167">Overview of R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-overview.md)
* [<span data-ttu-id="4ccd8-168">Aan de slag met R Server voor Hadoop</span><span class="sxs-lookup"><span data-stu-id="4ccd8-168">Get started with R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-get-started.md)
* [<span data-ttu-id="4ccd8-169">RStudio Server toevoegen aan HDInsight (indien niet toegevoegd tijdens het maken van het cluster)</span><span class="sxs-lookup"><span data-stu-id="4ccd8-169">Add RStudio Server to HDInsight (if not added during cluster creation)</span></span>](hdinsight-hadoop-r-server-install-r-studio.md)
* [<span data-ttu-id="4ccd8-170">Opties voor Azure-opslag voor R Server op HDInsight</span><span class="sxs-lookup"><span data-stu-id="4ccd8-170">Azure Storage options for R Server on HDInsight</span></span>](hdinsight-hadoop-r-server-storage.md)

