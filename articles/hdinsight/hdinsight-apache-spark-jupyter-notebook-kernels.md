---
title: aaaKernels voor Jupyter-notebook in Spark-clusters in Azure HDInsight | Microsoft Docs
description: Meer informatie over Hallo PySpark PySpark3 en Spark kernels voor Jupyter-notebook met Spark op Azure HDInsight-clusters.
keywords: jupyter-notebook in spark, jupyter spark
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="a2d58-104">Kernels voor Jupyter-notebook in Spark-clusters in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="a2d58-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="a2d58-105">HDInsight Spark-clusters bieden kernels die u met Jupyter-notebook in Spark Hallo gebruiken kunt voor het testen van uw toepassingen.</span><span class="sxs-lookup"><span data-stu-id="a2d58-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="a2d58-106">Een kernel is een programma dat wordt uitgevoerd en interpreteert uw code.</span><span class="sxs-lookup"><span data-stu-id="a2d58-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="a2d58-107">Er zijn drie kernels Hallo:</span><span class="sxs-lookup"><span data-stu-id="a2d58-107">hello three kernels are:</span></span>

- <span data-ttu-id="a2d58-108">**PySpark** - voor toepassingen die zijn geschreven in Python2</span><span class="sxs-lookup"><span data-stu-id="a2d58-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="a2d58-109">**PySpark3** - voor toepassingen die zijn geschreven in Python3</span><span class="sxs-lookup"><span data-stu-id="a2d58-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="a2d58-110">**Spark** - voor toepassingen die zijn geschreven in Scala</span><span class="sxs-lookup"><span data-stu-id="a2d58-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="a2d58-111">In dit artikel leert u hoe toouse deze kernels en Hallo voordelen van het gebruik ervan.</span><span class="sxs-lookup"><span data-stu-id="a2d58-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="a2d58-112">Vereisten</span><span class="sxs-lookup"><span data-stu-id="a2d58-112">Prerequisites</span></span>

* <span data-ttu-id="a2d58-113">Een Apache Spark-cluster in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="a2d58-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="a2d58-114">Zie voor instructies [maken Apache Spark-clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="a2d58-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="a2d58-115">Maken van een Jupyter-notebook in Spark HDInsight</span><span class="sxs-lookup"><span data-stu-id="a2d58-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="a2d58-116">Van Hallo [Azure-portal](https://portal.azure.com/), opent u het cluster.</span><span class="sxs-lookup"><span data-stu-id="a2d58-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="a2d58-117">Zie [lijst en geeft weer clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) voor Hallo-instructies.</span><span class="sxs-lookup"><span data-stu-id="a2d58-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="a2d58-118">Hallo-cluster wordt geopend in een nieuwe portalblade.</span><span class="sxs-lookup"><span data-stu-id="a2d58-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="a2d58-119">Van Hallo **snelle koppelingen** sectie, klikt u op **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span><span class="sxs-lookup"><span data-stu-id="a2d58-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="a2d58-120">Als er geen **snelkoppelingen**, klikt u op **overzicht** in Hallo linkermenu op Hallo-blade.</span><span class="sxs-lookup"><span data-stu-id="a2d58-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="a2d58-121">![Jupyter-notebook in Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter-notebook in Spark")</span><span class="sxs-lookup"><span data-stu-id="a2d58-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="a2d58-122">Klik op **Jupyter-Notebook**.</span><span class="sxs-lookup"><span data-stu-id="a2d58-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="a2d58-123">Voer desgevraagd Hallo beheerdersreferenties voor Hallo-cluster.</span><span class="sxs-lookup"><span data-stu-id="a2d58-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="a2d58-124">U kunt ook Hallo Jupyter-notebook in Spark-cluster door de volgende URL in uw browser openen-Hallo bereiken.</span><span class="sxs-lookup"><span data-stu-id="a2d58-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="a2d58-125">Vervang **CLUSTERNAME** met Hallo-naam van het cluster:</span><span class="sxs-lookup"><span data-stu-id="a2d58-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="a2d58-126">Klik op **nieuw**, en klikt u ofwel **Pyspark**, **PySpark3**, of **Spark** toocreate een laptop.</span><span class="sxs-lookup"><span data-stu-id="a2d58-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="a2d58-127">Hallo Spark kernel voor Scala-toepassingen, PySpark-kernel voor Python2 toepassingen en PySpark3 kernel voor Python3 toepassingen gebruiken.</span><span class="sxs-lookup"><span data-stu-id="a2d58-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="a2d58-128">![Kernels voor Jupyter-notebook in Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels voor Jupyter-notebook in Spark")</span><span class="sxs-lookup"><span data-stu-id="a2d58-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="a2d58-129">Een laptop wordt geopend met Hallo kernel die u hebt geselecteerd.</span><span class="sxs-lookup"><span data-stu-id="a2d58-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="a2d58-130">Voordelen van het gebruik van Hallo kernels</span><span class="sxs-lookup"><span data-stu-id="a2d58-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="a2d58-131">Hier volgen enkele voordelen van het gebruik van Hallo nieuwe kernels op Jupyter-notebook op HDInsight Spark-clusters.</span><span class="sxs-lookup"><span data-stu-id="a2d58-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="a2d58-132">**Voorinstelling contexten**.</span><span class="sxs-lookup"><span data-stu-id="a2d58-132">**Preset contexts**.</span></span> <span data-ttu-id="a2d58-133">Met **PySpark**, **PySpark3**, of Hallo **Spark** kernels, hoeft u geen tooset Hallo Spark of Hive-contexten expliciet voordat u begint te werken met uw toepassingen.</span><span class="sxs-lookup"><span data-stu-id="a2d58-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="a2d58-134">Dit zijn standaard beschikbaar.</span><span class="sxs-lookup"><span data-stu-id="a2d58-134">These are available by default.</span></span> <span data-ttu-id="a2d58-135">Deze contexten zijn:</span><span class="sxs-lookup"><span data-stu-id="a2d58-135">These contexts are:</span></span>
   
   * <span data-ttu-id="a2d58-136">**sc** : voor het Spark-context</span><span class="sxs-lookup"><span data-stu-id="a2d58-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="a2d58-137">**sqlContext** - voor Hive-context</span><span class="sxs-lookup"><span data-stu-id="a2d58-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="a2d58-138">Dus hebt u geen instructies voor het toorun zoals Hallo tooset Hallo contexten te volgen:</span><span class="sxs-lookup"><span data-stu-id="a2d58-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="a2d58-139">SC SparkContext('yarn-client') sqlContext = HiveContext(sc) =</span><span class="sxs-lookup"><span data-stu-id="a2d58-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="a2d58-140">In plaats daarvan u rechtstreeks kunt Hallo voorinstelling contexten in uw toepassing.</span><span class="sxs-lookup"><span data-stu-id="a2d58-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="a2d58-141">**Cel-magics**.</span><span class="sxs-lookup"><span data-stu-id="a2d58-141">**Cell magics**.</span></span> <span data-ttu-id="a2d58-142">Hallo PySpark-kernel biedt een aantal vooraf gedefinieerde 'magics', die zijn speciale opdrachten die u met aanroepen kunt `%%` (bijvoorbeeld `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="a2d58-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="a2d58-143">Hallo magische opdracht moet worden Hallo eerste woord in een codecel en toestaan voor meerdere regels van inhoud.</span><span class="sxs-lookup"><span data-stu-id="a2d58-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="a2d58-144">Hallo magische word moet Hallo eerste woord in Hallo cel.</span><span class="sxs-lookup"><span data-stu-id="a2d58-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="a2d58-145">Alles voordat Hallo magic, zelfs opmerkingen toevoegen, veroorzaakt een fout.</span><span class="sxs-lookup"><span data-stu-id="a2d58-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="a2d58-146">Zie voor meer informatie over magics [hier](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="a2d58-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="a2d58-147">Hallo bevat volgende tabel andere magics Hallo beschikbaar via Hallo kernels.</span><span class="sxs-lookup"><span data-stu-id="a2d58-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="a2d58-148">Verwerkt Magic-pakket</span><span class="sxs-lookup"><span data-stu-id="a2d58-148">Magic</span></span> | <span data-ttu-id="a2d58-149">Voorbeeld</span><span class="sxs-lookup"><span data-stu-id="a2d58-149">Example</span></span> | <span data-ttu-id="a2d58-150">Beschrijving</span><span class="sxs-lookup"><span data-stu-id="a2d58-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="a2d58-151">Help</span><span class="sxs-lookup"><span data-stu-id="a2d58-151">help</span></span> |`%%help` |<span data-ttu-id="a2d58-152">Genereert een lijst met alle beschikbare Hallo-magics met voorbeeld en beschrijving</span><span class="sxs-lookup"><span data-stu-id="a2d58-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="a2d58-153">Info</span><span class="sxs-lookup"><span data-stu-id="a2d58-153">info</span></span> |`%%info` |<span data-ttu-id="a2d58-154">Sessie-informatie van uitvoer voor de huidige Livy eindpunt Hallo</span><span class="sxs-lookup"><span data-stu-id="a2d58-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="a2d58-155">Configureren</span><span class="sxs-lookup"><span data-stu-id="a2d58-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="a2d58-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="a2d58-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="a2d58-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="a2d58-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="a2d58-158">Hiermee configureert u Hallo parameters voor het maken van een sessie.</span><span class="sxs-lookup"><span data-stu-id="a2d58-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="a2d58-159">vlag force Hallo (-f) is verplicht als een sessie al is gemaakt, waardoor die sessie Hallo is verwijderd en opnieuw gemaakt.</span><span class="sxs-lookup"><span data-stu-id="a2d58-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="a2d58-160">Bekijk [van Livy POST /sessions aanvraagtekst](https://github.com/cloudera/livy#request-body) voor een lijst met geldige parameters op.</span><span class="sxs-lookup"><span data-stu-id="a2d58-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="a2d58-161">Parameters moeten worden doorgegeven als een JSON-tekenreeks en moeten op de volgende regel Hallo na Hallo magic, zoals weergegeven in Hallo voorbeeldkolom.</span><span class="sxs-lookup"><span data-stu-id="a2d58-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="a2d58-162">SQL</span><span class="sxs-lookup"><span data-stu-id="a2d58-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="a2d58-163">Een Hive-query op Hallo sqlContext worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="a2d58-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="a2d58-164">Als hello `-o` parameter is doorgegeven, Hallo resultaat van Hallo query wordt bewaard in Hallo %% lokale Python context als een [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="a2d58-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="a2d58-165">lokale</span><span class="sxs-lookup"><span data-stu-id="a2d58-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="a2d58-166">Alle Hallo-code in de volgende regels wordt lokaal uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="a2d58-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="a2d58-167">De sitecode moet geldige Python2 code zelfs ongeacht Hallo kernel die u gebruikt.</span><span class="sxs-lookup"><span data-stu-id="a2d58-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="a2d58-168">Zo is, zelfs als u **PySpark3** of **Spark** kernels tijdens het maken van Hallo laptop, als u Hallo `%%local` magische in een cel, die cel moet alleen code bevatten, geldige Python2...</span><span class="sxs-lookup"><span data-stu-id="a2d58-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="a2d58-169">logboeken</span><span class="sxs-lookup"><span data-stu-id="a2d58-169">logs</span></span> |`%%logs` |<span data-ttu-id="a2d58-170">Uitvoer Hallo logboeken voor de huidige Livy sessie Hallo.</span><span class="sxs-lookup"><span data-stu-id="a2d58-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="a2d58-171">verwijderen</span><span class="sxs-lookup"><span data-stu-id="a2d58-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="a2d58-172">Hiermee verwijdert u een bepaalde sessie van de huidige Livy eindpunt Hallo.</span><span class="sxs-lookup"><span data-stu-id="a2d58-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="a2d58-173">Houd er rekening mee dat u Hallo-sessie die is gestart voor Hallo kernel zichzelf niet verwijderen.</span><span class="sxs-lookup"><span data-stu-id="a2d58-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="a2d58-174">Opruimen</span><span class="sxs-lookup"><span data-stu-id="a2d58-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="a2d58-175">Hiermee verwijdert u alle Hallo-sessies voor Hallo huidige Livy eindpunt, waaronder deze laptop-sessie.</span><span class="sxs-lookup"><span data-stu-id="a2d58-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="a2d58-176">Hallo force vlag -f is verplicht.</span><span class="sxs-lookup"><span data-stu-id="a2d58-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="a2d58-177">Bovendien toohello magics toegevoegd door de PySpark-kernel Hallo, u kunt ook Hallo [ingebouwde IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), inclusief `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="a2d58-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="a2d58-178">U kunt Hallo `%%sh` magic toorun scripts en codeblok op Hallo cluster headnode.</span><span class="sxs-lookup"><span data-stu-id="a2d58-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="a2d58-179">**Visualisatie automatisch**.</span><span class="sxs-lookup"><span data-stu-id="a2d58-179">**Auto visualization**.</span></span> <span data-ttu-id="a2d58-180">Hallo **Pyspark** kernel visualiseren automatisch Hallo-uitvoer van Hive en SQL-query's.</span><span class="sxs-lookup"><span data-stu-id="a2d58-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="a2d58-181">U kunt kiezen tussen verschillende soorten visualisaties, met inbegrip van de tabel, cirkel, regel, gebied, balk.</span><span class="sxs-lookup"><span data-stu-id="a2d58-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="a2d58-182">Parameters die worden ondersteund door hello %% sql verwerkt Magic-pakket</span><span class="sxs-lookup"><span data-stu-id="a2d58-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="a2d58-183">Hallo `%%sql` magic ondersteunt verschillende parameters kunt u toocontrol Hallo type uitvoer dat wordt weergegeven wanneer u query's uitvoeren.</span><span class="sxs-lookup"><span data-stu-id="a2d58-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="a2d58-184">Hallo volgende tabel geeft een lijst Hallo uitvoer.</span><span class="sxs-lookup"><span data-stu-id="a2d58-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="a2d58-185">Parameter</span><span class="sxs-lookup"><span data-stu-id="a2d58-185">Parameter</span></span> | <span data-ttu-id="a2d58-186">Voorbeeld</span><span class="sxs-lookup"><span data-stu-id="a2d58-186">Example</span></span> | <span data-ttu-id="a2d58-187">Beschrijving</span><span class="sxs-lookup"><span data-stu-id="a2d58-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="a2d58-188">-o</span><span class="sxs-lookup"><span data-stu-id="a2d58-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="a2d58-189">Gebruik deze parameter toopersist Hallo-resultaat van het Hallo-query in Hallo %% lokale Python-context, als een [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="a2d58-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="a2d58-190">Hallo-naam van Hallo dataframe variabele is Hallo variabele naam die u opgeeft.</span><span class="sxs-lookup"><span data-stu-id="a2d58-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="a2d58-191">-q</span><span class="sxs-lookup"><span data-stu-id="a2d58-191">-q</span></span> |`-q` |<span data-ttu-id="a2d58-192">Gebruik deze tooturn uit visualisaties voor Hallo cel.</span><span class="sxs-lookup"><span data-stu-id="a2d58-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="a2d58-193">Als u niet tooauto wilt-inhoud van een cel Hallo visualiseren en alleen wilt toocapture als een dataframe vervolgens gebruiken `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="a2d58-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="a2d58-194">Als u wilt dat tooturn uitschakelen visualisaties zonder Hallo resultaten opnemen (bijvoorbeeld voor het uitvoeren van een SQL-query, zoals een `CREATE TABLE` instructie), gebruik `-q` zonder op te geven een `-o` argument.</span><span class="sxs-lookup"><span data-stu-id="a2d58-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="a2d58-195">-m</span><span class="sxs-lookup"><span data-stu-id="a2d58-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="a2d58-196">Waar **methode** is **nemen** of **voorbeeld** (standaardwaarde is **nemen**).</span><span class="sxs-lookup"><span data-stu-id="a2d58-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="a2d58-197">Als u de methode Hallo **nemen**, Hallo kernel uitgelicht elementen vanaf de bovenkant Hallo van Hallo gegevens resultatenset opgegeven door MAXROWS (Zie verderop in deze tabel).</span><span class="sxs-lookup"><span data-stu-id="a2d58-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="a2d58-198">Als u de methode Hallo **voorbeeld**, Hallo kernel willekeurig samples elementen van de set gegevens Hallo volgens te`-r` parameter hieronder wordt beschreven in deze tabel.</span><span class="sxs-lookup"><span data-stu-id="a2d58-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="a2d58-199">-r</span><span class="sxs-lookup"><span data-stu-id="a2d58-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="a2d58-200">Hier **FRACTIE** is een getal met drijvende komma tussen 0,0 en 1,0 liggen.</span><span class="sxs-lookup"><span data-stu-id="a2d58-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="a2d58-201">Als Hallo voorbeeldmethode voor de SQL-query Hallo `sample`, en vervolgens Hallo kernel willekeurig samples Hallo opgegeven fractie van Hallo elementen van het Hallo-resultaat voor u ingesteld.</span><span class="sxs-lookup"><span data-stu-id="a2d58-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="a2d58-202">Bijvoorbeeld, als u een SQL-query uitvoeren met Hallo argumenten `-m sample -r 0.01`, en vervolgens 1% van de Hallo Resultatenrijen willekeurig worden vastgelegd.</span><span class="sxs-lookup"><span data-stu-id="a2d58-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="a2d58-203">**MAXROWS** is een geheel getal.</span><span class="sxs-lookup"><span data-stu-id="a2d58-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="a2d58-204">Hallo kernel beperkt het aantal rijen dat uitvoer hello te**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="a2d58-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="a2d58-205">Als **MAXROWS** is een negatief getal zoals **-1**, en vervolgens het aantal rijen in de resultatenset Hallo Hallo niet beperkt is.</span><span class="sxs-lookup"><span data-stu-id="a2d58-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="a2d58-206">**Voorbeeld:**</span><span class="sxs-lookup"><span data-stu-id="a2d58-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="a2d58-207">Hallo-instructie hiervoor Hallo te volgen:</span><span class="sxs-lookup"><span data-stu-id="a2d58-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="a2d58-208">Hiermee selecteert u alle records uit **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="a2d58-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="a2d58-209">Omdat we - q, schakelt automatisch visualisatie.</span><span class="sxs-lookup"><span data-stu-id="a2d58-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="a2d58-210">Omdat we `-m sample -r 0.1 -n 500` het willekeurig 10% Hallo rijen in Hallo hivesampletable voorbeelden en limieten Hallo grootte van Hallo resultaat set too500 rijen.</span><span class="sxs-lookup"><span data-stu-id="a2d58-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="a2d58-211">Ten slotte omdat we gebruikt `-o query2` Bovendien bespaart u Hallo-uitvoer in een dataframe aangeroepen **query2**.</span><span class="sxs-lookup"><span data-stu-id="a2d58-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="a2d58-212">Overwegingen bij het gebruik van nieuwe kernels Hallo</span><span class="sxs-lookup"><span data-stu-id="a2d58-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="a2d58-213">De kernel dat u gebruikt, verbruikt verlaten Hallo laptops met Hallo clusterbronnen.</span><span class="sxs-lookup"><span data-stu-id="a2d58-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="a2d58-214">Met deze kernels omdat Hallo contexten worden vooraf ingesteld, gewoon afgesloten Hallo notitieblokken Hallo context niet beëindigen en daarom Hallo clusterbronnen toobe blijven in gebruik.</span><span class="sxs-lookup"><span data-stu-id="a2d58-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="a2d58-215">Het wordt aangeraden toouse hello **sluiten en stoppen** optie uit Hallo-notebook **bestand** menu wanneer u klaar bent met Hallo laptop, die is funest Hallo context en vervolgens uitgangen notebook Hallo.</span><span class="sxs-lookup"><span data-stu-id="a2d58-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="a2d58-216">Sommige voorbeelden weergeven</span><span class="sxs-lookup"><span data-stu-id="a2d58-216">Show me some examples</span></span>

<span data-ttu-id="a2d58-217">Als u een Jupyter-notebook opent, ziet u twee mappen op hoofdniveau Hallo beschikbaar.</span><span class="sxs-lookup"><span data-stu-id="a2d58-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="a2d58-218">Hallo **PySpark** map bevat voorbeeldquery notitieblokken die gebruik Hallo nieuwe **Python** kernel.</span><span class="sxs-lookup"><span data-stu-id="a2d58-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="a2d58-219">Hallo **Scala** map bevat voorbeeldquery notitieblokken die gebruik Hallo nieuwe **Spark** kernel.</span><span class="sxs-lookup"><span data-stu-id="a2d58-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="a2d58-220">U kunt openen Hallo **00 - [Lees mij eerst] Spark Magic Kernel-functies** notebook van Hallo **PySpark** of **Spark** map toolearn over andere magics Hallo beschikbaar.</span><span class="sxs-lookup"><span data-stu-id="a2d58-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="a2d58-221">U kunt ook andere voorbeeldquery notitieblokken onder Hallo twee mappen toolearn hoe Hallo tooachieve verschillende scenario's met Jupyter-notebooks met HDInsight Spark-clusters.</span><span class="sxs-lookup"><span data-stu-id="a2d58-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="a2d58-222">Waar kan ik Hallo notitieblokken opgeslagen?</span><span class="sxs-lookup"><span data-stu-id="a2d58-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="a2d58-223">Jupyter-notebooks toohello storage-account die is gekoppeld aan het cluster onder Hallo Hallo worden opgeslagen **/HdiNotebooks** map.</span><span class="sxs-lookup"><span data-stu-id="a2d58-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="a2d58-224">Notitieblokken, bestanden en mappen die u vanuit Jupyter maakt zijn toegankelijk is vanaf Hallo storage-account.</span><span class="sxs-lookup"><span data-stu-id="a2d58-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="a2d58-225">Bijvoorbeeld, als u Jupyter toocreate een map **mijnmap** en een laptop **myfolder/mynotebook.ipynb**, u toegang hebt tot die laptop `/HdiNotebooks/myfolder/mynotebook.ipynb` binnen Hallo-opslagaccount.</span><span class="sxs-lookup"><span data-stu-id="a2d58-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="a2d58-226">Hallo omgekeerde geldt ook, dat wil zeggen, als u een laptop uploadt direct tooyour storage-account op `/HdiNotebooks/mynotebook1.ipynb`, Hallo laptop evenals van Jupyter zichtbaar is.</span><span class="sxs-lookup"><span data-stu-id="a2d58-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="a2d58-227">Notitieblokken blijven in Hallo storage-account, zelfs nadat het Hallo-cluster is verwijderd.</span><span class="sxs-lookup"><span data-stu-id="a2d58-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="a2d58-228">Hallo manier notitieblokken toohello storage-account worden opgeslagen is compatibel met HDFS.</span><span class="sxs-lookup"><span data-stu-id="a2d58-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="a2d58-229">Dus als u SSH in Hallo cluster die kunt u opdrachten voor het beheer zoals weergegeven in het volgende codefragment Hallo:</span><span class="sxs-lookup"><span data-stu-id="a2d58-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="a2d58-230">Als er problemen met toegang tot Hallo storage-account voor Hallo-cluster zijn, Hallo notitieblokken worden ook opgeslagen op Hallo headnode `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="a2d58-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="a2d58-231">Ondersteunde browser</span><span class="sxs-lookup"><span data-stu-id="a2d58-231">Supported browser</span></span>

<span data-ttu-id="a2d58-232">Jupyter-notebooks op HDInsight Spark-clusters worden alleen ondersteund op Google Chrome.</span><span class="sxs-lookup"><span data-stu-id="a2d58-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="a2d58-233">Feedback</span><span class="sxs-lookup"><span data-stu-id="a2d58-233">Feedback</span></span>
<span data-ttu-id="a2d58-234">nieuwe kernels Hallo zijn in de fase in ontwikkeling en zal vervallen gedurende een bepaalde periode.</span><span class="sxs-lookup"><span data-stu-id="a2d58-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="a2d58-235">Dit kan ook betekenen dat API's wijzigen kan, omdat deze kernels vervallen.</span><span class="sxs-lookup"><span data-stu-id="a2d58-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="a2d58-236">We zouden feedback die u hebt tijdens het gebruik van deze nieuwe kernels stellen.</span><span class="sxs-lookup"><span data-stu-id="a2d58-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="a2d58-237">Dit is handig in Hallo definitieve versie van deze kernels vormgeven.</span><span class="sxs-lookup"><span data-stu-id="a2d58-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="a2d58-238">U kunt feedback uw opmerkingen/onder Hallo **opmerkingen** sectie op Hallo onder aan dit artikel.</span><span class="sxs-lookup"><span data-stu-id="a2d58-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="a2d58-239"><a name="seealso"></a>Zie ook</span><span class="sxs-lookup"><span data-stu-id="a2d58-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="a2d58-240">Overzicht: Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="a2d58-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="a2d58-241">Scenario's</span><span class="sxs-lookup"><span data-stu-id="a2d58-241">Scenarios</span></span>
* [<span data-ttu-id="a2d58-242">Spark met BI: interactieve gegevensanalyses uitvoeren met behulp van Spark in HDInsight met BI-tools</span><span class="sxs-lookup"><span data-stu-id="a2d58-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="a2d58-243">Spark met Machine Learning: Spark in HDInsight gebruiken voor het analyseren van de gebouwtemperatuur met behulp van HVAC-gegevens</span><span class="sxs-lookup"><span data-stu-id="a2d58-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="a2d58-244">Spark met Machine Learning: Spark in HDInsight toopredict voedselinspectieresultaten gebruiken</span><span class="sxs-lookup"><span data-stu-id="a2d58-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="a2d58-245">Spark-streaming: Spark in HDInsight gebruiken voor het bouwen van realtime streamingtoepassingen</span><span class="sxs-lookup"><span data-stu-id="a2d58-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="a2d58-246">Websitelogboekanalyse met Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="a2d58-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="a2d58-247">Toepassingen maken en uitvoeren</span><span class="sxs-lookup"><span data-stu-id="a2d58-247">Create and run applications</span></span>
* [<span data-ttu-id="a2d58-248">Een zelfstandige toepassing maken met behulp van Scala</span><span class="sxs-lookup"><span data-stu-id="a2d58-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="a2d58-249">Taken op afstand uitvoeren in een Spark-cluster met behulp van Livy</span><span class="sxs-lookup"><span data-stu-id="a2d58-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="a2d58-250">Tools en uitbreidingen</span><span class="sxs-lookup"><span data-stu-id="a2d58-250">Tools and extensions</span></span>
* [<span data-ttu-id="a2d58-251">De invoegtoepassing HDInsight Tools voor IntelliJ IDEA toocreate en verzenden van Spark Scala-toepassingen</span><span class="sxs-lookup"><span data-stu-id="a2d58-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="a2d58-252">De invoegtoepassing HDInsight Tools for IntelliJ IDEA toodebug Spark applications op afstand gebruiken</span><span class="sxs-lookup"><span data-stu-id="a2d58-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="a2d58-253">Zeppelin-notebooks gebruiken met een Spark-cluster in HDInsight</span><span class="sxs-lookup"><span data-stu-id="a2d58-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="a2d58-254">Externe pakketten gebruiken met Jupyter-notebooks</span><span class="sxs-lookup"><span data-stu-id="a2d58-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="a2d58-255">Jupyter op uw computer installeren en verbinding maken met tooan HDInsight Spark-cluster</span><span class="sxs-lookup"><span data-stu-id="a2d58-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="a2d58-256">Resources beheren</span><span class="sxs-lookup"><span data-stu-id="a2d58-256">Manage resources</span></span>
* [<span data-ttu-id="a2d58-257">Resources beheren voor Hallo Apache Spark-cluster in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="a2d58-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="a2d58-258">Taken die worden uitgevoerd in een Apache Spark-cluster in HDInsight, traceren en er fouten in oplossen</span><span class="sxs-lookup"><span data-stu-id="a2d58-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
