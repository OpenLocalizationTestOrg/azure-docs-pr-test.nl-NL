---
title: Migreren van HDInsight op basis van Windows naar Linux gebaseerde HDInsight - Azure | Microsoft Docs
description: Informatie over het migreren van een HDInsight op basis van Windows-cluster naar een Linux gebaseerde HDInsight-cluster.
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: ff35be59-bae3-42fd-9edc-77f0041bab93
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/12/2017
ms.author: larryfr
ms.openlocfilehash: 35e80efe27081cd43243f488fa60447b76a20c32
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/03/2017
---
# <a name="migrate-from-a-windows-based-hdinsight-cluster-to-a-linux-based-cluster"></a><span data-ttu-id="471b2-103">Migreren van een HDInsight op basis van Windows-cluster naar een cluster op basis van Linux</span><span class="sxs-lookup"><span data-stu-id="471b2-103">Migrate from a Windows-based HDInsight cluster to a Linux-based cluster</span></span>

<span data-ttu-id="471b2-104">Dit document bevat informatie over de verschillen tussen HDInsight op Windows- en Linux- en instructies voor het migreren van bestaande werkbelastingen naar een cluster op basis van Linux.</span><span class="sxs-lookup"><span data-stu-id="471b2-104">This document provides details on the differences between HDInsight on Windows and Linux, and guidance on how to migrate existing workloads to a Linux-based cluster.</span></span>

<span data-ttu-id="471b2-105">Hoewel HDInsight op basis van Windows een eenvoudige manier biedt om het gebruik van Hadoop in de cloud, moet u wellicht migreren naar een cluster op basis van Linux.</span><span class="sxs-lookup"><span data-stu-id="471b2-105">While Windows-based HDInsight provides an easy way to use Hadoop in the cloud, you may need to migrate to a Linux-based cluster.</span></span> <span data-ttu-id="471b2-106">Als u bijvoorbeeld om te profiteren van Linux-gebaseerde hulpprogramma's en -technologieën die nodig voor uw oplossing zijn.</span><span class="sxs-lookup"><span data-stu-id="471b2-106">For example, to take advantage of Linux-based tools and technologies that are required for your solution.</span></span> <span data-ttu-id="471b2-107">Groot aantal dingen in het Hadoop-ecosysteem op Linux gebaseerde systemen zijn ontwikkeld en mogelijk niet beschikbaar voor gebruik met HDInsight op basis van Windows.</span><span class="sxs-lookup"><span data-stu-id="471b2-107">Many things in the Hadoop ecosystem are developed on Linux-based systems, and may not be available for use with Windows-based HDInsight.</span></span> <span data-ttu-id="471b2-108">Bovendien veel boeken, video's en andere trainingsmateriaal wordt ervan uitgegaan dat u van een Linux-systeem gebruikmaakt bij het werken met Hadoop.</span><span class="sxs-lookup"><span data-stu-id="471b2-108">Additionally, many books, videos, and other training material assume that you are using a Linux system when working with Hadoop.</span></span>

> [!NOTE]
> <span data-ttu-id="471b2-109">HDInsight-clusters gebruiken op lange termijn Ubuntu-ondersteuning (TNS) als het besturingssysteem voor de knooppunten in het cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-109">HDInsight clusters use Ubuntu long-term support (LTS) as the operating system for the nodes in the cluster.</span></span> <span data-ttu-id="471b2-110">Zie voor informatie over de versie van Ubuntu beschikbaar met HDInsight, samen met andere versiegegevens onderdeel, [HDInsight onderdeel versies](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-110">For information on the version of Ubuntu available with HDInsight, along with other component versioning information, see [HDInsight component versions](hdinsight-component-versioning.md).</span></span>

## <a name="migration-tasks"></a><span data-ttu-id="471b2-111">Migratietaken</span><span class="sxs-lookup"><span data-stu-id="471b2-111">Migration tasks</span></span>

<span data-ttu-id="471b2-112">De algemene werkstroom voor de migratie is als volgt.</span><span class="sxs-lookup"><span data-stu-id="471b2-112">The general workflow for migration is as follows.</span></span>

![Werkstroomdiagram van migratie](./media/hdinsight-migrate-from-windows-to-linux/workflow.png)

1. <span data-ttu-id="471b2-114">Elke sectie van dit document om te begrijpen wijzigingen die mogelijk vereist zijn wanneer u uw bestaande werkstroom, taken, enz. migreert naar een cluster op basis van Linux worden gelezen.</span><span class="sxs-lookup"><span data-stu-id="471b2-114">Read each section of this document to understand changes that may be required when migrating your existing workflow, jobs, etc. to a Linux-based cluster.</span></span>

2. <span data-ttu-id="471b2-115">Een cluster op basis van Linux maken als een test/quality assurance-omgeving.</span><span class="sxs-lookup"><span data-stu-id="471b2-115">Create a Linux-based cluster as a test/quality assurance environment.</span></span> <span data-ttu-id="471b2-116">Zie voor meer informatie over het maken van een cluster op basis van Linux [clusters in HDInsight op basis van Linux maken](hdinsight-hadoop-provision-linux-clusters.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-116">For more information on creating a Linux-based cluster, see [Create Linux-based clusters in HDInsight](hdinsight-hadoop-provision-linux-clusters.md).</span></span>

3. <span data-ttu-id="471b2-117">Bestaande projecten, gegevensbronnen en put kopiëren naar de nieuwe omgeving.</span><span class="sxs-lookup"><span data-stu-id="471b2-117">Copy existing jobs, data sources, and sinks to the new environment.</span></span>

4. <span data-ttu-id="471b2-118">Voer de validatie testen om ervoor te zorgen dat uw taken werken zoals verwacht op het nieuwe cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-118">Perform validation testing to make sure that your jobs work as expected on the new cluster.</span></span>

<span data-ttu-id="471b2-119">Zodra u hebt gecontroleerd dat alles werkt zoals verwacht, plant u uitvaltijd voor de migratie.</span><span class="sxs-lookup"><span data-stu-id="471b2-119">Once you have verified that everything works as expected, schedule downtime for the migration.</span></span> <span data-ttu-id="471b2-120">Tijdens deze uitvaltijd, moet u de volgende acties uitvoeren:</span><span class="sxs-lookup"><span data-stu-id="471b2-120">During this downtime, perform the following actions:</span></span>

1. <span data-ttu-id="471b2-121">Back-up tijdelijke gegevens die lokaal zijn opgeslagen op de clusterknooppunten.</span><span class="sxs-lookup"><span data-stu-id="471b2-121">Back up any transient data stored locally on the cluster nodes.</span></span> <span data-ttu-id="471b2-122">Bijvoorbeeld, als u gegevens hebt opgeslagen rechtstreeks op een hoofdknooppunt.</span><span class="sxs-lookup"><span data-stu-id="471b2-122">For example, if you have data stored directly on a head node.</span></span>

2. <span data-ttu-id="471b2-123">Verwijdert het cluster op basis van Windows.</span><span class="sxs-lookup"><span data-stu-id="471b2-123">Delete the Windows-based cluster.</span></span>

3. <span data-ttu-id="471b2-124">Maak een cluster op basis van Linux met hetzelfde standaard gegevensarchief die het cluster op basis van Windows gebruikt.</span><span class="sxs-lookup"><span data-stu-id="471b2-124">Create a Linux-based cluster using the same default data store that the Windows-based cluster used.</span></span> <span data-ttu-id="471b2-125">Het cluster op basis van Linux kunt blijven werken met uw bestaande productiegegevens.</span><span class="sxs-lookup"><span data-stu-id="471b2-125">The Linux-based cluster can continue working against your existing production data.</span></span>

4. <span data-ttu-id="471b2-126">Importeer tijdelijke gegevens die u een back-up.</span><span class="sxs-lookup"><span data-stu-id="471b2-126">Import any transient data you backed up.</span></span>

5. <span data-ttu-id="471b2-127">Start taken/doorgaan met het verwerken met behulp van het nieuwe cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-127">Start jobs/continue processing using the new cluster.</span></span>

### <a name="copy-data-to-the-test-environment"></a><span data-ttu-id="471b2-128">Gegevens kopiëren naar de testomgeving</span><span class="sxs-lookup"><span data-stu-id="471b2-128">Copy data to the test environment</span></span>

<span data-ttu-id="471b2-129">Er zijn veel methoden om de gegevens en taken te kopiëren, de twee besproken in deze sectie zijn echter de eenvoudigste methoden voor het rechtstreeks verplaatsen van bestanden naar een testcluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-129">There are many methods to copy the data and jobs, however the two discussed in this section are the simplest methods to directly move files to a test cluster.</span></span>

#### <a name="hdfs-copy"></a><span data-ttu-id="471b2-130">HDFS kopiëren</span><span class="sxs-lookup"><span data-stu-id="471b2-130">HDFS copy</span></span>

<span data-ttu-id="471b2-131">Gebruik de volgende stappen uit om gegevens te kopiëren uit het productiecluster voor de testcluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-131">Use the following steps to copy data from the production cluster to the test cluster.</span></span> <span data-ttu-id="471b2-132">Deze stappen wordt gebruik de `hdfs dfs` hulpprogramma dat wordt meegeleverd met HDInsight.</span><span class="sxs-lookup"><span data-stu-id="471b2-132">These steps use the `hdfs dfs` utility that is included with HDInsight.</span></span>

1. <span data-ttu-id="471b2-133">De storage-account en het standaard container informatie vinden voor het bestaande cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-133">Find the storage account and default container information for your existing cluster.</span></span> <span data-ttu-id="471b2-134">PowerShell wordt het volgende voorbeeld deze informatie op te halen:</span><span class="sxs-lookup"><span data-stu-id="471b2-134">The following example uses PowerShell to retrieve this information:</span></span>

    ```powershell
    $clusterName="Your existing HDInsight cluster name"
    $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName
    write-host "Storage account name: $clusterInfo.DefaultStorageAccount.split('.')[0]"
    write-host "Default container: $clusterInfo.DefaultStorageContainer"
    ```

2. <span data-ttu-id="471b2-135">Volg de stappen in de clusters op basis van Linux maken in HDInsight document voor het maken van een testomgeving.</span><span class="sxs-lookup"><span data-stu-id="471b2-135">To create a test environment, follow the steps in the Create Linux-based clusters in HDInsight document.</span></span> <span data-ttu-id="471b2-136">Beëindigen voordat het maken van het cluster en selecteert u in plaats daarvan **optionele configuratie**.</span><span class="sxs-lookup"><span data-stu-id="471b2-136">Stop before creating the cluster, and instead select **Optional Configuration**.</span></span>

3. <span data-ttu-id="471b2-137">Selecteer in de blade optionele configuratie **gekoppelde Storage-Accounts**.</span><span class="sxs-lookup"><span data-stu-id="471b2-137">From the Optional Configuration blade, select **Linked Storage Accounts**.</span></span>

4. <span data-ttu-id="471b2-138">Selecteer **opslag van een sleutel**, en wanneer u wordt gevraagd, selecteert u het opslagaccount dat is geretourneerd door het PowerShell-script in stap 1.</span><span class="sxs-lookup"><span data-stu-id="471b2-138">Select **Add a storage key**, and when prompted, select the storage account that was returned by the PowerShell script in step 1.</span></span> <span data-ttu-id="471b2-139">Klik op **Selecteer** op elk blade.</span><span class="sxs-lookup"><span data-stu-id="471b2-139">Click **Select** on each blade.</span></span> <span data-ttu-id="471b2-140">Maak ten slotte het cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-140">Finally, create the cluster.</span></span>

5. <span data-ttu-id="471b2-141">Zodra het cluster is gemaakt, verbinding maken met de **SSH.**</span><span class="sxs-lookup"><span data-stu-id="471b2-141">Once the cluster has been created, connect to it using **SSH.**</span></span> <span data-ttu-id="471b2-142">Zie [SSH gebruiken met HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="471b2-142">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

6. <span data-ttu-id="471b2-143">Gebruik de volgende opdracht om bestanden te kopiëren van het gekoppelde opslagaccount naar het nieuwe standaardaccount voor opslag van de SSH-sessie.</span><span class="sxs-lookup"><span data-stu-id="471b2-143">From the SSH session, use the following command to copy files from the linked storage account to the new default storage account.</span></span> <span data-ttu-id="471b2-144">CONTAINER vervangen door de container-informatie geretourneerd door PowerShell.</span><span class="sxs-lookup"><span data-stu-id="471b2-144">Replace CONTAINER with the container information returned by PowerShell.</span></span> <span data-ttu-id="471b2-145">Vervang __ACCOUNT__ met de accountnaam.</span><span class="sxs-lookup"><span data-stu-id="471b2-145">Replace __ACCOUNT__ with the account name.</span></span> <span data-ttu-id="471b2-146">Het pad naar gegevens vervangen door het pad naar een bestand.</span><span class="sxs-lookup"><span data-stu-id="471b2-146">Replace the path to data with the path to a data file.</span></span>

    ```bash
    hdfs dfs -cp wasb://CONTAINER@ACCOUNT.blob.core.windows.net/path/to/old/data /path/to/new/location
    ```

    > [!NOTE]
    > <span data-ttu-id="471b2-147">Als u de mapstructuur die de gegevens bevat, is niet aanwezig op de testomgeving, kunt u met behulp van de volgende opdracht:</span><span class="sxs-lookup"><span data-stu-id="471b2-147">If the directory structure that contains the data does not exist on the test environment, you can create it using the following command:</span></span>

    ```bash
    hdfs dfs -mkdir -p /new/path/to/create
    ```

    <span data-ttu-id="471b2-148">De `-p` schakelt u het maken van alle mappen in het pad.</span><span class="sxs-lookup"><span data-stu-id="471b2-148">The `-p` switch enables the creation of all directories in  the path.</span></span>

#### <a name="direct-copy-between-blobs-in-azure-storage"></a><span data-ttu-id="471b2-149">Directe kopiëren tussen blobs in Azure Storage</span><span class="sxs-lookup"><span data-stu-id="471b2-149">Direct copy between blobs in Azure Storage</span></span>

<span data-ttu-id="471b2-150">U kunt ook gebruik van de `Start-AzureStorageBlobCopy` Azure PowerShell-cmdlet voor het kopiëren van BLOB's tussen opslagaccounts buiten HDInsight.</span><span class="sxs-lookup"><span data-stu-id="471b2-150">Alternatively, you may want to use the `Start-AzureStorageBlobCopy` Azure PowerShell cmdlet to copy blobs between storage accounts outside of HDInsight.</span></span> <span data-ttu-id="471b2-151">Zie voor meer informatie de sectie Azure Blobs van Azure PowerShell gebruiken met Azure Storage beheren.</span><span class="sxs-lookup"><span data-stu-id="471b2-151">For more information, see the How to manage Azure Blobs section of Using Azure PowerShell with Azure Storage.</span></span>

## <a name="client-side-technologies"></a><span data-ttu-id="471b2-152">Client-side '-technologieën</span><span class="sxs-lookup"><span data-stu-id="471b2-152">Client-side technologies</span></span>

<span data-ttu-id="471b2-153">Client-side '-technologieën zoals [Azure PowerShell-cmdlets](/powershell/azureps-cmdlets-docs), [Azure CLI](../cli-install-nodejs.md), of de [.NET SDK voor Hadoop](https://hadoopsdk.codeplex.com/) blijven werken op basis van Linux-clusters.</span><span class="sxs-lookup"><span data-stu-id="471b2-153">Client-side technologies such as [Azure PowerShell cmdlets](/powershell/azureps-cmdlets-docs), [Azure CLI](../cli-install-nodejs.md), or the [.NET SDK for Hadoop](https://hadoopsdk.codeplex.com/) continue to work Linux-based clusters.</span></span> <span data-ttu-id="471b2-154">Deze technologieën zijn afhankelijk van REST-API's die hetzelfde voor beide clustertypen OS zijn.</span><span class="sxs-lookup"><span data-stu-id="471b2-154">These technologies rely on REST APIs that are the same across both cluster OS types.</span></span>

## <a name="server-side-technologies"></a><span data-ttu-id="471b2-155">Server-side technologieën</span><span class="sxs-lookup"><span data-stu-id="471b2-155">Server-side technologies</span></span>

<span data-ttu-id="471b2-156">De volgende tabel biedt richtlijnen voor migratie specifiek voor Windows zijn server-side-onderdelen.</span><span class="sxs-lookup"><span data-stu-id="471b2-156">The following table provides guidance on migrating server-side components that are Windows-specific.</span></span>

| <span data-ttu-id="471b2-157">Als u van deze technologie gebruikmaakt...</span><span class="sxs-lookup"><span data-stu-id="471b2-157">If you are using this technology...</span></span> | <span data-ttu-id="471b2-158">Deze actie duren...</span><span class="sxs-lookup"><span data-stu-id="471b2-158">Take this action...</span></span> |
| --- | --- |
| <span data-ttu-id="471b2-159">**PowerShell** (serverzijde scripts, met inbegrip van scriptacties gebruikt tijdens het maken van het cluster)</span><span class="sxs-lookup"><span data-stu-id="471b2-159">**PowerShell** (server-side scripts, including Script Actions used during cluster creation)</span></span> |<span data-ttu-id="471b2-160">Herschrijf als Bash-scripts.</span><span class="sxs-lookup"><span data-stu-id="471b2-160">Rewrite as Bash scripts.</span></span> <span data-ttu-id="471b2-161">Zie voor scriptacties, [HDInsight op basis van Linux aanpassen met scriptacties](hdinsight-hadoop-customize-cluster-linux.md) en [Scriptactieontwikkeling voor HDInsight op basis van Linux](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-161">For Script Actions, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span> |
| <span data-ttu-id="471b2-162">**Azure CLI** (serverzijde scripts)</span><span class="sxs-lookup"><span data-stu-id="471b2-162">**Azure CLI** (server-side scripts)</span></span> |<span data-ttu-id="471b2-163">De Azure CLI is beschikbaar op Linux, is niet afkomstig vooraf worden geïnstalleerd op de hoofdknooppunten van het HDInsight-cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-163">While the Azure CLI is available on Linux, it does not come pre-installed on the HDInsight cluster head nodes.</span></span> <span data-ttu-id="471b2-164">Zie voor meer informatie over het installeren van de Azure CLI [aan de slag met Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli).</span><span class="sxs-lookup"><span data-stu-id="471b2-164">For more information on installing the Azure CLI, see [Get started with Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli).</span></span> |
| <span data-ttu-id="471b2-165">**.NET-onderdelen**</span><span class="sxs-lookup"><span data-stu-id="471b2-165">**.NET components**</span></span> |<span data-ttu-id="471b2-166">.NET wordt ondersteund op Linux gebaseerde HDInsight via [Mono](https://mono-project.com).</span><span class="sxs-lookup"><span data-stu-id="471b2-166">.NET is supported on Linux-based HDInsight through [Mono](https://mono-project.com).</span></span> <span data-ttu-id="471b2-167">Zie voor meer informatie [migreren .NET-oplossingen voor Linux gebaseerde HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-167">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span> |
| <span data-ttu-id="471b2-168">**Win32-onderdelen of andere alleen Windows technologie**</span><span class="sxs-lookup"><span data-stu-id="471b2-168">**Win32 components or other Windows-only technology**</span></span> |<span data-ttu-id="471b2-169">Richtlijnen, is afhankelijk van het onderdeel of technologie.</span><span class="sxs-lookup"><span data-stu-id="471b2-169">Guidance depends on the component or technology.</span></span> <span data-ttu-id="471b2-170">U kunt mogelijk een versie die compatibel is met Linux of moet u mogelijk een alternatieve oplossing vinden of dit onderdeel herschrijven.</span><span class="sxs-lookup"><span data-stu-id="471b2-170">You may be able to find a version that is compatible with Linux, or you may need to find an alternate solution or rewrite this component.</span></span> |

> [!IMPORTANT]
> <span data-ttu-id="471b2-171">Het beheer van HDInsight SDK is niet volledig compatibel is met Mono.</span><span class="sxs-lookup"><span data-stu-id="471b2-171">The HDInsight management SDK is not fully compatible with Mono.</span></span> <span data-ttu-id="471b2-172">Deze mag niet worden gebruikt als onderdeel van oplossingen die zijn geïmplementeerd op het HDInsight-cluster op dit moment.</span><span class="sxs-lookup"><span data-stu-id="471b2-172">It should not be used as part of solutions deployed to the HDInsight cluster at this time.</span></span>

## <a name="cluster-creation"></a><span data-ttu-id="471b2-173">Maken van het cluster</span><span class="sxs-lookup"><span data-stu-id="471b2-173">Cluster creation</span></span>

<span data-ttu-id="471b2-174">Deze sectie bevat informatie over de verschillen in het maken van het cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-174">This section provides information on differences in cluster creation.</span></span>

### <a name="ssh-user"></a><span data-ttu-id="471b2-175">SSH gebruiker</span><span class="sxs-lookup"><span data-stu-id="471b2-175">SSH User</span></span>

<span data-ttu-id="471b2-176">Linux gebaseerde HDInsight-clusters gebruiken de **Secure Shell (SSH)** protocol voor externe toegang tot de clusterknooppunten.</span><span class="sxs-lookup"><span data-stu-id="471b2-176">Linux-based HDInsight clusters use the **Secure Shell (SSH)** protocol to provide remote access to the cluster nodes.</span></span> <span data-ttu-id="471b2-177">In tegenstelling tot extern bureaublad voor Windows gebaseerde clusters bieden meeste SSH-clients geen een grafische gebruikersinterface.</span><span class="sxs-lookup"><span data-stu-id="471b2-177">Unlike Remote Desktop for Windows-based clusters, most SSH clients do not provide a graphical user experience.</span></span> <span data-ttu-id="471b2-178">SSH-clients bieden in plaats daarvan een opdrachtregel waarmee u opdrachten uit te voeren op het cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-178">Instead, SSH clients provide a command line that allows you to run commands on the cluster.</span></span> <span data-ttu-id="471b2-179">Sommige clients (zoals [MobaXterm](http://mobaxterm.mobatek.net/)) bieden een grafische bestand system browser naast een extern vanaf de opdrachtregel.</span><span class="sxs-lookup"><span data-stu-id="471b2-179">Some clients (such as [MobaXterm](http://mobaxterm.mobatek.net/)) provide a graphical file system browser in addition to a remote command line.</span></span>

<span data-ttu-id="471b2-180">Tijdens het maken, moet u een SSH-gebruiker en een opgeven een **wachtwoord** of **openbare-sleutelcertificaat** voor verificatie.</span><span class="sxs-lookup"><span data-stu-id="471b2-180">During cluster creation, you must provide an SSH user and either a **password** or **public key certificate** for authentication.</span></span>

<span data-ttu-id="471b2-181">Wordt u aangeraden openbare-sleutelcertificaat, omdat het is veiliger dan een wachtwoord te gebruiken.</span><span class="sxs-lookup"><span data-stu-id="471b2-181">We recommend using Public key certificate, as it is more secure than using a password.</span></span> <span data-ttu-id="471b2-182">Verificatie via certificaat werkt door een ondertekende openbaar/persoonlijk sleutelpaar genereren en vervolgens de openbare sleutel bieden bij het maken van het cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-182">Certificate authentication works by generating a signed public/private key pair, then providing the public key when creating the cluster.</span></span> <span data-ttu-id="471b2-183">Wanneer u verbinding maakt met de server via SSH, biedt de persoonlijke sleutel op de client verificatie voor de verbinding.</span><span class="sxs-lookup"><span data-stu-id="471b2-183">When connecting to the server using SSH, the private key on the client provides authentication for the connection.</span></span>

<span data-ttu-id="471b2-184">Zie [SSH gebruiken met HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="471b2-184">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

### <a name="cluster-customization"></a><span data-ttu-id="471b2-185">Aanpassing van het cluster</span><span class="sxs-lookup"><span data-stu-id="471b2-185">Cluster customization</span></span>

<span data-ttu-id="471b2-186">**Acties script** gebruikt met clusters op basis van Linux in Bash-scripts moeten worden geschreven.</span><span class="sxs-lookup"><span data-stu-id="471b2-186">**Script Actions** used with Linux-based clusters must be written in Bash script.</span></span> <span data-ttu-id="471b2-187">Terwijl scriptacties kunnen worden gebruikt tijdens het maken van het cluster, voor op basis van Linux-clusters kunnen ze ook worden gebruikt voor aanpassing uitvoeren nadat u een cluster actief is en wordt uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="471b2-187">While Script Actions can be used during cluster creation, for Linux-based clusters they can also be used to perform customization after a cluster is up and running.</span></span> <span data-ttu-id="471b2-188">Zie voor meer informatie [HDInsight op basis van Linux aanpassen met scriptacties](hdinsight-hadoop-customize-cluster-linux.md) en [Scriptactieontwikkeling voor HDInsight op basis van Linux](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-188">For more information, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span>

<span data-ttu-id="471b2-189">Een andere aanpassing-functie is **bootstrap**.</span><span class="sxs-lookup"><span data-stu-id="471b2-189">Another customization feature is **bootstrap**.</span></span> <span data-ttu-id="471b2-190">Voor Windows-clusters kunt deze functie u de locatie van aanvullende bibliotheken voor gebruik met Hive opgeven.</span><span class="sxs-lookup"><span data-stu-id="471b2-190">For Windows clusters, this feature allows you to specify the location of additional libraries for use with Hive.</span></span> <span data-ttu-id="471b2-191">Na het maken van het cluster deze bibliotheken zijn automatisch beschikbaar voor gebruik met Hive-query's zonder te hoeven gebruiken `ADD JAR`.</span><span class="sxs-lookup"><span data-stu-id="471b2-191">After cluster creation, these libraries are automatically available for use with Hive queries without the need to use `ADD JAR`.</span></span>

<span data-ttu-id="471b2-192">De Bootstrap-functie voor op basis van Linux-clusters biedt deze functionaliteit niet.</span><span class="sxs-lookup"><span data-stu-id="471b2-192">The Bootstrap feature for Linux-based clusters does not provide this functionality.</span></span> <span data-ttu-id="471b2-193">Gebruik in plaats daarvan scriptactie gedocumenteerd in [toevoegen Hive-bibliotheken tijdens het maken van het cluster](hdinsight-hadoop-add-hive-libraries.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-193">Instead, use script action documented in [Add Hive libraries during cluster creation](hdinsight-hadoop-add-hive-libraries.md).</span></span>

### <a name="virtual-networks"></a><span data-ttu-id="471b2-194">Virtuele netwerken</span><span class="sxs-lookup"><span data-stu-id="471b2-194">Virtual Networks</span></span>

<span data-ttu-id="471b2-195">HDInsight op basis van Windows-clusters alleen werken met klassieke virtuele netwerken, terwijl Linux gebaseerde HDInsight-clusters Resource Manager virtuele netwerken vereisen.</span><span class="sxs-lookup"><span data-stu-id="471b2-195">Windows-based HDInsight clusters only work with Classic Virtual Networks, while Linux-based HDInsight clusters require Resource Manager Virtual Networks.</span></span> <span data-ttu-id="471b2-196">Als u een klassiek virtueel netwerk dat het Linux-HDInsight-cluster verbinding met maken moet resources hebt, raadpleegt u [een klassiek virtueel netwerk verbinden met een Resource Manager virtuele netwerk](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-196">If you have resources in a Classic Virtual Network that the Linux-HDInsight cluster must connect to, see [Connecting a Classic Virtual Network to a Resource Manager Virtual Network](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span></span>

<span data-ttu-id="471b2-197">Zie voor meer informatie over de configuratievereisten voor het gebruik van Azure Virtual Networks met HDInsight, [mogelijkheden uitbreiden HDInsight met behulp van een virtueel netwerk](hdinsight-extend-hadoop-virtual-network.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-197">For more information on configuration requirements for using Azure Virtual Networks with HDInsight, see [Extend HDInsight capabilities by using a Virtual Network](hdinsight-extend-hadoop-virtual-network.md).</span></span>

## <a name="management-and-monitoring"></a><span data-ttu-id="471b2-198">Beheer en controle</span><span class="sxs-lookup"><span data-stu-id="471b2-198">Management and monitoring</span></span>

<span data-ttu-id="471b2-199">Veel van de web-UI dat u in combinatie met HDInsight op basis van Windows zoals Taakgeschiedenis of de gebruikersinterface van Yarn gebruikt zijn beschikbaar via Ambari.</span><span class="sxs-lookup"><span data-stu-id="471b2-199">Many of the web UIs you may have used with Windows-based HDInsight, such as Job History or Yarn UI, are available through Ambari.</span></span> <span data-ttu-id="471b2-200">Daarnaast biedt de Ambari Hive-weergave Hive-query's via uw webbrowser uitvoert.</span><span class="sxs-lookup"><span data-stu-id="471b2-200">In addition, the Ambari Hive View provides a way to run Hive queries using your web browser.</span></span> <span data-ttu-id="471b2-201">De Ambari-Webgebruikersinterface is beschikbaar op Linux gebaseerde clusters op https://CLUSTERNAME.azurehdinsight.net.</span><span class="sxs-lookup"><span data-stu-id="471b2-201">The Ambari Web UI is available on Linux-based clusters at https://CLUSTERNAME.azurehdinsight.net.</span></span>

<span data-ttu-id="471b2-202">Zie de volgende documenten voor meer informatie over het werken met Ambari:</span><span class="sxs-lookup"><span data-stu-id="471b2-202">For more information on working with Ambari, see the following documents:</span></span>

* [<span data-ttu-id="471b2-203">Ambari Web</span><span class="sxs-lookup"><span data-stu-id="471b2-203">Ambari Web</span></span>](hdinsight-hadoop-manage-ambari.md)
* [<span data-ttu-id="471b2-204">Ambari REST-API</span><span class="sxs-lookup"><span data-stu-id="471b2-204">Ambari REST API</span></span>](hdinsight-hadoop-manage-ambari-rest-api.md)

### <a name="ambari-alerts"></a><span data-ttu-id="471b2-205">Ambari-waarschuwingen</span><span class="sxs-lookup"><span data-stu-id="471b2-205">Ambari Alerts</span></span>

<span data-ttu-id="471b2-206">Ambari is een waarschuwing systeem waarmee u mogelijke problemen met het cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-206">Ambari has an alert system that can tell you of potential problems with the cluster.</span></span> <span data-ttu-id="471b2-207">Waarschuwingen worden weergegeven als rood of geel vermeldingen in de Ambari-Webgebruikersinterface, maar u ze ook via de REST-API ophalen kunt.</span><span class="sxs-lookup"><span data-stu-id="471b2-207">Alerts appear as red or yellow entries in the Ambari Web UI, however you can also retrieve them through the REST API.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="471b2-208">Ambari waarschuwingen geven aan dat er *mogelijk* is er een probleem niet dat er *is* een probleem.</span><span class="sxs-lookup"><span data-stu-id="471b2-208">Ambari alerts indicate that there *may* be a problem, not that there *is* a problem.</span></span> <span data-ttu-id="471b2-209">Bijvoorbeeld, verschijnt een waarschuwing dat HiveServer2 kan niet worden geopend, zelfs als u toegang hebt tot het normaal.</span><span class="sxs-lookup"><span data-stu-id="471b2-209">For example, you may receive an alert that HiveServer2 cannot be accessed, even though you can access it normally.</span></span>
>
> <span data-ttu-id="471b2-210">Veel waarschuwingen worden geïmplementeerd als op interval gebaseerde query uitgevoerd naar een service en een reactie binnen een specifiek tijdsbestek verwachten.</span><span class="sxs-lookup"><span data-stu-id="471b2-210">Many alerts are implemented as interval-based queries against a service, and expect a response within a specific time frame.</span></span> <span data-ttu-id="471b2-211">Zodat de waarschuwing niet noodzakelijkerwijs dat de service niet actief is, resultaten maar het niet binnen het verwachte tijdsbestek.</span><span class="sxs-lookup"><span data-stu-id="471b2-211">So the alert doesn't necessarily mean that the service is down, just that it didn't return results within the expected time frame.</span></span>

<span data-ttu-id="471b2-212">U moet evalueren of een waarschuwing heeft gedurende lange tijd is optreedt of problemen van gebruikers die zijn gerapporteerd weerspiegelt voordat deze actie te ondernemen.</span><span class="sxs-lookup"><span data-stu-id="471b2-212">You should evaluate whether an alert has been occurring for an extended period, or mirrors user problems that have been reported before taking action on it.</span></span>

## <a name="file-system-locations"></a><span data-ttu-id="471b2-213">De locaties van systeem</span><span class="sxs-lookup"><span data-stu-id="471b2-213">File system locations</span></span>

<span data-ttu-id="471b2-214">Het bestandssysteem van de Linux-cluster worden anders dan Windows gebaseerde HDInsight-clusters verspreid.</span><span class="sxs-lookup"><span data-stu-id="471b2-214">The Linux cluster file system is laid out differently than Windows-based HDInsight clusters.</span></span> <span data-ttu-id="471b2-215">Gebruik de volgende tabel om te zoeken naar gebruikte bestanden.</span><span class="sxs-lookup"><span data-stu-id="471b2-215">Use the following table to find commonly used files.</span></span>

| <span data-ttu-id="471b2-216">Ik wil...</span><span class="sxs-lookup"><span data-stu-id="471b2-216">I need to find...</span></span> | <span data-ttu-id="471b2-217">Deze bevindt zich...</span><span class="sxs-lookup"><span data-stu-id="471b2-217">It is located...</span></span> |
| --- | --- |
| <span data-ttu-id="471b2-218">Configuratie</span><span class="sxs-lookup"><span data-stu-id="471b2-218">Configuration</span></span> |<span data-ttu-id="471b2-219">`/etc`.</span><span class="sxs-lookup"><span data-stu-id="471b2-219">`/etc`.</span></span> <span data-ttu-id="471b2-220">Bijvoorbeeld: `/etc/hadoop/conf/core-site.xml`</span><span class="sxs-lookup"><span data-stu-id="471b2-220">For example, `/etc/hadoop/conf/core-site.xml`</span></span> |
| <span data-ttu-id="471b2-221">Logboekbestanden</span><span class="sxs-lookup"><span data-stu-id="471b2-221">Log files</span></span> |`/var/logs` |
| <span data-ttu-id="471b2-222">Hortonworks Data Platform HDP)</span><span class="sxs-lookup"><span data-stu-id="471b2-222">Hortonworks Data Platform (HDP)</span></span> |<span data-ttu-id="471b2-223">`/usr/hdp`. Er zijn twee directory's die u hier, die de huidige versie van de HDP en `current`.</span><span class="sxs-lookup"><span data-stu-id="471b2-223">`/usr/hdp`.There are two directories located here, one that is the current HDP version and `current`.</span></span> <span data-ttu-id="471b2-224">De `current` directory bevat symbolische koppelingen naar bestanden en mappen die zich in de map van versie-nummer.</span><span class="sxs-lookup"><span data-stu-id="471b2-224">The `current` directory contains symbolic links to files and directories located in the version number directory.</span></span> <span data-ttu-id="471b2-225">De `current` directory is opgegeven als een handige manier toegang krijgen tot HDP bestanden sinds verandert het versienummer als het HDP versie is bijgewerkt.</span><span class="sxs-lookup"><span data-stu-id="471b2-225">The `current` directory is provided as a convenient way of accessing HDP files since the version number changes as the HDP version is updated.</span></span> |
| <span data-ttu-id="471b2-226">hadoop-streaming.jar</span><span class="sxs-lookup"><span data-stu-id="471b2-226">hadoop-streaming.jar</span></span> |`/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar` |

<span data-ttu-id="471b2-227">In het algemeen als u de naam van het bestand, kunt u de volgende opdracht vanaf een SSH-sessie het bestandspad vinden:</span><span class="sxs-lookup"><span data-stu-id="471b2-227">In general, if you know the name of the file, you can use the following command from an SSH session to find the file path:</span></span>

    find / -name FILENAME 2>/dev/null

<span data-ttu-id="471b2-228">U kunt ook jokertekens gebruiken met de bestandsnaam.</span><span class="sxs-lookup"><span data-stu-id="471b2-228">You can also use wildcards with the file name.</span></span> <span data-ttu-id="471b2-229">Bijvoorbeeld: `find / -name *streaming*.jar 2>/dev/null` resulteert in het pad naar het jar-bestanden die het woord streaming als onderdeel van de bestandsnaam bevatten.</span><span class="sxs-lookup"><span data-stu-id="471b2-229">For example, `find / -name *streaming*.jar 2>/dev/null` returns the path to any jar files that contain the word 'streaming' as part of the file name.</span></span>

## <a name="hive-pig-and-mapreduce"></a><span data-ttu-id="471b2-230">Hive, Pig en MapReduce</span><span class="sxs-lookup"><span data-stu-id="471b2-230">Hive, Pig, and MapReduce</span></span>

<span data-ttu-id="471b2-231">Pig en MapReduce-belastingen lijken op Linux gebaseerde clusters.</span><span class="sxs-lookup"><span data-stu-id="471b2-231">Pig and MapReduce workloads are similar on Linux-based clusters.</span></span> <span data-ttu-id="471b2-232">Linux gebaseerde HDInsight-clusters kunnen echter worden gemaakt met een nieuwere versie van Hadoop Hive en Pig.</span><span class="sxs-lookup"><span data-stu-id="471b2-232">However, Linux-based HDInsight clusters can be created using newer versions of Hadoop, Hive, and Pig.</span></span> <span data-ttu-id="471b2-233">Deze verschillen tussen versies kunnen leiden tot wijzigingen in hoe uw bestaande oplossingen-functie.</span><span class="sxs-lookup"><span data-stu-id="471b2-233">These version differences may introduce changes in how your existing solutions function.</span></span> <span data-ttu-id="471b2-234">Zie voor meer informatie over de versies van onderdelen in HDInsight [versiebeheer van HDInsight-onderdeel](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-234">For more information on the versions of components included with HDInsight, see [HDInsight component versioning](hdinsight-component-versioning.md).</span></span>

<span data-ttu-id="471b2-235">Linux gebaseerde HDInsight biedt geen functionaliteit voor extern bureaublad.</span><span class="sxs-lookup"><span data-stu-id="471b2-235">Linux-based HDInsight does not provide remote desktop functionality.</span></span> <span data-ttu-id="471b2-236">U kunt in plaats daarvan SSH gebruiken voor externe verbinding met de hoofdknooppunten van het cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-236">Instead, you can use SSH to remotely connect to the cluster head nodes.</span></span> <span data-ttu-id="471b2-237">Zie de volgende documenten voor meer informatie:</span><span class="sxs-lookup"><span data-stu-id="471b2-237">For more information, see the following documents:</span></span>

* [<span data-ttu-id="471b2-238">Hive gebruiken met SSH</span><span class="sxs-lookup"><span data-stu-id="471b2-238">Use Hive with SSH</span></span>](hdinsight-hadoop-use-hive-ssh.md)
* [<span data-ttu-id="471b2-239">Pig gebruiken met SSH</span><span class="sxs-lookup"><span data-stu-id="471b2-239">Use Pig with SSH</span></span>](hdinsight-hadoop-use-pig-ssh.md)
* [<span data-ttu-id="471b2-240">U MapReduce gebruikt met SSH</span><span class="sxs-lookup"><span data-stu-id="471b2-240">Use MapReduce with SSH</span></span>](hdinsight-hadoop-use-mapreduce-ssh.md)

### <a name="hive"></a><span data-ttu-id="471b2-241">Hive</span><span class="sxs-lookup"><span data-stu-id="471b2-241">Hive</span></span>

> [!IMPORTANT]
> <span data-ttu-id="471b2-242">Als u een externe Hive-metastore gebruikt, moet u back-up de metastore voordat u deze gebruikt met HDInsight op basis van Linux.</span><span class="sxs-lookup"><span data-stu-id="471b2-242">If you use an external Hive metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="471b2-243">HDInsight op basis van Linux is beschikbaar met nieuwere versies van Hive, die mogelijk incompatibel met metastores gemaakt met eerdere versies.</span><span class="sxs-lookup"><span data-stu-id="471b2-243">Linux-based HDInsight is available with newer versions of Hive, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="471b2-244">De volgende tabel biedt richtlijnen voor het migreren van uw Hive-werkbelastingen.</span><span class="sxs-lookup"><span data-stu-id="471b2-244">The following chart provides guidance on migrating your Hive workloads.</span></span>

| <span data-ttu-id="471b2-245">Op Windows gebaseerde ik gebruik...</span><span class="sxs-lookup"><span data-stu-id="471b2-245">On Windows-based, I use...</span></span> | <span data-ttu-id="471b2-246">Op Linux gebaseerde...</span><span class="sxs-lookup"><span data-stu-id="471b2-246">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="471b2-247">**Hive-Editor**</span><span class="sxs-lookup"><span data-stu-id="471b2-247">**Hive Editor**</span></span> |[<span data-ttu-id="471b2-248">Weergave in de Ambari hive</span><span class="sxs-lookup"><span data-stu-id="471b2-248">Hive View in Ambari</span></span>](hdinsight-hadoop-use-hive-ambari-view.md) |
| <span data-ttu-id="471b2-249">`set hive.execution.engine=tez;`inschakelen van Tez</span><span class="sxs-lookup"><span data-stu-id="471b2-249">`set hive.execution.engine=tez;` to enable Tez</span></span> |<span data-ttu-id="471b2-250">Tez is de engine voor het uitvoeren van standaard voor op basis van Linux-clusters, zodat de set-instructie niet langer nodig is.</span><span class="sxs-lookup"><span data-stu-id="471b2-250">Tez is the default execution engine for Linux-based clusters, so the set statement is no longer needed.</span></span> |
| <span data-ttu-id="471b2-251">C# gebruiker gedefinieerde functies</span><span class="sxs-lookup"><span data-stu-id="471b2-251">C# user-defined functions</span></span> | <span data-ttu-id="471b2-252">Zie voor informatie over het valideren van C#-onderdelen met HDInsight op basis van Linux, [migreren .NET-oplossingen voor HDInsight op basis van Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="471b2-252">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="471b2-253">CMD-bestanden of scripts op de server die als onderdeel van een Hive-taak wordt aangeroepen</span><span class="sxs-lookup"><span data-stu-id="471b2-253">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="471b2-254">Bash-scripts gebruiken</span><span class="sxs-lookup"><span data-stu-id="471b2-254">use Bash scripts</span></span> |
| <span data-ttu-id="471b2-255">`hive`de opdracht van een extern bureaublad</span><span class="sxs-lookup"><span data-stu-id="471b2-255">`hive` command from remote desktop</span></span> |<span data-ttu-id="471b2-256">Gebruik [Beeline](hdinsight-hadoop-use-hive-beeline.md) of [Hive van een SSH-sessie](hdinsight-hadoop-use-hive-ssh.md)</span><span class="sxs-lookup"><span data-stu-id="471b2-256">Use [Beeline](hdinsight-hadoop-use-hive-beeline.md) or [Hive from an SSH session](hdinsight-hadoop-use-hive-ssh.md)</span></span> |

### <a name="pig"></a><span data-ttu-id="471b2-257">Pig</span><span class="sxs-lookup"><span data-stu-id="471b2-257">Pig</span></span>

| <span data-ttu-id="471b2-258">Op Windows gebaseerde ik gebruik...</span><span class="sxs-lookup"><span data-stu-id="471b2-258">On Windows-based, I use...</span></span> | <span data-ttu-id="471b2-259">Op Linux gebaseerde...</span><span class="sxs-lookup"><span data-stu-id="471b2-259">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="471b2-260">C# gebruiker gedefinieerde functies</span><span class="sxs-lookup"><span data-stu-id="471b2-260">C# user-defined functions</span></span> | <span data-ttu-id="471b2-261">Zie voor informatie over het valideren van C#-onderdelen met HDInsight op basis van Linux, [migreren .NET-oplossingen voor HDInsight op basis van Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="471b2-261">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="471b2-262">CMD-bestanden of scripts op de server die als onderdeel van een Pig-taak wordt aangeroepen</span><span class="sxs-lookup"><span data-stu-id="471b2-262">CMD files or scripts on the server invoked as part of a Pig job</span></span> |<span data-ttu-id="471b2-263">Bash-scripts gebruiken</span><span class="sxs-lookup"><span data-stu-id="471b2-263">use Bash scripts</span></span> |

### <a name="mapreduce"></a><span data-ttu-id="471b2-264">MapReduce</span><span class="sxs-lookup"><span data-stu-id="471b2-264">MapReduce</span></span>

| <span data-ttu-id="471b2-265">Op Windows gebaseerde ik gebruik...</span><span class="sxs-lookup"><span data-stu-id="471b2-265">On Windows-based, I use...</span></span> | <span data-ttu-id="471b2-266">Op Linux gebaseerde...</span><span class="sxs-lookup"><span data-stu-id="471b2-266">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="471b2-267">C# toewijzen en reducer-onderdelen</span><span class="sxs-lookup"><span data-stu-id="471b2-267">C# mapper and reducer components</span></span> | <span data-ttu-id="471b2-268">Zie voor informatie over het valideren van C#-onderdelen met HDInsight op basis van Linux, [migreren .NET-oplossingen voor HDInsight op basis van Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="471b2-268">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="471b2-269">CMD-bestanden of scripts op de server die als onderdeel van een Hive-taak wordt aangeroepen</span><span class="sxs-lookup"><span data-stu-id="471b2-269">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="471b2-270">Bash-scripts gebruiken</span><span class="sxs-lookup"><span data-stu-id="471b2-270">use Bash scripts</span></span> |

## <a name="oozie"></a><span data-ttu-id="471b2-271">Oozie</span><span class="sxs-lookup"><span data-stu-id="471b2-271">Oozie</span></span>

> [!IMPORTANT]
> <span data-ttu-id="471b2-272">Als u een externe Oozie-metastore gebruikt, moet u back-up de metastore voordat u deze gebruikt met HDInsight op basis van Linux.</span><span class="sxs-lookup"><span data-stu-id="471b2-272">If you use an external Oozie metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="471b2-273">HDInsight op basis van Linux is beschikbaar met nieuwere versies van Oozie, die mogelijk incompatibel met metastores gemaakt met eerdere versies.</span><span class="sxs-lookup"><span data-stu-id="471b2-273">Linux-based HDInsight is available with newer versions of Oozie, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="471b2-274">Oozie werkstromen shell acties voor toestaan.</span><span class="sxs-lookup"><span data-stu-id="471b2-274">Oozie workflows allow shell actions.</span></span> <span data-ttu-id="471b2-275">Acties Shell gebruiken de standaardshell voor het besturingssysteem vanaf de opdrachtregel opdrachten uit te voeren.</span><span class="sxs-lookup"><span data-stu-id="471b2-275">Shell actions use the default shell for the operating system to run command-line commands.</span></span> <span data-ttu-id="471b2-276">Als u Oozie-werkstromen die afhankelijk van de Windows-shell zijn hebt, moet u de werkstromen voor het vertrouwen op de Linux-shell-omgeving (Bash) herschrijven.</span><span class="sxs-lookup"><span data-stu-id="471b2-276">If you have Oozie workflows that rely on the Windows shell, you must rewrite the workflows to rely on the Linux shell environment (Bash).</span></span> <span data-ttu-id="471b2-277">Zie voor meer informatie over het gebruik van de shell-acties met Oozie [Oozie actie shelluitbreiding](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html).</span><span class="sxs-lookup"><span data-stu-id="471b2-277">For more information on using shell actions with Oozie, see [Oozie shell action extension](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html).</span></span>

<span data-ttu-id="471b2-278">Als u Oozie-werkstromen die afhankelijk van C#-toepassingen die wordt opgeroepen via de shell acties zijn hebt, moet u deze toepassingen in een omgeving met Linux valideren.</span><span class="sxs-lookup"><span data-stu-id="471b2-278">If you have Oozie workflows that rely on C# applications invoked through shell actions, you must validate these applications in a Linux environment.</span></span> <span data-ttu-id="471b2-279">Zie voor meer informatie [migreren .NET-oplossingen voor Linux gebaseerde HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-279">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span>

## <a name="storm"></a><span data-ttu-id="471b2-280">Storm</span><span class="sxs-lookup"><span data-stu-id="471b2-280">Storm</span></span>

| <span data-ttu-id="471b2-281">Op Windows gebaseerde ik gebruik...</span><span class="sxs-lookup"><span data-stu-id="471b2-281">On Windows-based, I use...</span></span> | <span data-ttu-id="471b2-282">Op Linux gebaseerde...</span><span class="sxs-lookup"><span data-stu-id="471b2-282">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="471b2-283">Storm-Dashboard</span><span class="sxs-lookup"><span data-stu-id="471b2-283">Storm Dashboard</span></span> |<span data-ttu-id="471b2-284">Het Storm-Dashboard is niet beschikbaar.</span><span class="sxs-lookup"><span data-stu-id="471b2-284">The Storm Dashboard is not available.</span></span> <span data-ttu-id="471b2-285">Zie [implementeren en beheren van Storm-topologieën op Linux gebaseerde HDInsight](hdinsight-storm-deploy-monitor-topology-linux.md) voor manieren om in te dienen topologieën</span><span class="sxs-lookup"><span data-stu-id="471b2-285">See [Deploy and Manage Storm topologies on Linux-based HDInsight](hdinsight-storm-deploy-monitor-topology-linux.md) for ways to submit topologies</span></span> |
| <span data-ttu-id="471b2-286">Storm-gebruikersinterface</span><span class="sxs-lookup"><span data-stu-id="471b2-286">Storm UI</span></span> |<span data-ttu-id="471b2-287">De Storm-gebruikersinterface is beschikbaar op https://CLUSTERNAME.azurehdinsight.NET/stormui</span><span class="sxs-lookup"><span data-stu-id="471b2-287">The Storm UI is available at https://CLUSTERNAME.azurehdinsight.net/stormui</span></span> |
| <span data-ttu-id="471b2-288">Visual Studio maken, implementeren en beheren van C# of hybride topologieën</span><span class="sxs-lookup"><span data-stu-id="471b2-288">Visual Studio to create, deploy, and manage C# or hybrid topologies</span></span> |<span data-ttu-id="471b2-289">Visual Studio kan worden gebruikt voor het maken, implementeren en beheren van C# (SCP.NET) of hybride topologieën op Linux gebaseerde Storm op HDInsight-clusters die zijn gemaakt na 28-10-2016.</span><span class="sxs-lookup"><span data-stu-id="471b2-289">Visual Studio can be used to create, deploy, and manage C# (SCP.NET) or hybrid topologies on Linux-based Storm on HDInsight clusters created after 10/28/2016.</span></span> |

## <a name="hbase"></a><span data-ttu-id="471b2-290">HBase</span><span class="sxs-lookup"><span data-stu-id="471b2-290">HBase</span></span>

<span data-ttu-id="471b2-291">Op Linux gebaseerde clusters, de bovenliggende znode voor HBase is `/hbase-unsecure`.</span><span class="sxs-lookup"><span data-stu-id="471b2-291">On Linux-based clusters, the znode parent for HBase is `/hbase-unsecure`.</span></span> <span data-ttu-id="471b2-292">Stel deze waarde in de configuratie voor elke client Java-toepassingen die gebruikmaken van systeemeigen HBase Java API.</span><span class="sxs-lookup"><span data-stu-id="471b2-292">Set this value in the configuration for any Java client applications that use native HBase Java API.</span></span>

<span data-ttu-id="471b2-293">Zie [een HBase op basis van Java-toepassing bouwt](hdinsight-hbase-build-java-maven.md) voor een voorbeeld van de client die deze waarde wordt ingesteld.</span><span class="sxs-lookup"><span data-stu-id="471b2-293">See [Build a Java-based HBase application](hdinsight-hbase-build-java-maven.md) for an example client that sets this value.</span></span>

## <a name="spark"></a><span data-ttu-id="471b2-294">Spark</span><span class="sxs-lookup"><span data-stu-id="471b2-294">Spark</span></span>

<span data-ttu-id="471b2-295">Spark-clusters zijn beschikbaar op Windows-clusters tijdens de preview.</span><span class="sxs-lookup"><span data-stu-id="471b2-295">Spark clusters were available on Windows-clusters during preview.</span></span> <span data-ttu-id="471b2-296">Spark GA is alleen beschikbaar bij op basis van Linux-clusters.</span><span class="sxs-lookup"><span data-stu-id="471b2-296">Spark GA is only available with Linux-based clusters.</span></span> <span data-ttu-id="471b2-297">Er is geen migratiepad van een preview Spark op basis van Windows cluster naar een release op basis van Linux Spark-cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-297">There is no migration path from a Windows-based Spark preview cluster to a release Linux-based Spark cluster.</span></span>

## <a name="known-issues"></a><span data-ttu-id="471b2-298">Bekende problemen</span><span class="sxs-lookup"><span data-stu-id="471b2-298">Known issues</span></span>

### <a name="azure-data-factory-custom-net-activities"></a><span data-ttu-id="471b2-299">Azure Data Factory aangepaste .NET-activiteiten</span><span class="sxs-lookup"><span data-stu-id="471b2-299">Azure Data Factory custom .NET activities</span></span>

<span data-ttu-id="471b2-300">Azure Data Factory aangepaste .NET-activiteiten worden momenteel niet ondersteund op Linux gebaseerde HDInsight-clusters.</span><span class="sxs-lookup"><span data-stu-id="471b2-300">Azure Data Factory custom .NET activities are not currently supported on Linux-based HDInsight clusters.</span></span> <span data-ttu-id="471b2-301">In plaats daarvan moet u een van de volgende methoden gebruiken voor het implementeren van aangepaste activiteiten als onderdeel van uw ADF-pijplijn.</span><span class="sxs-lookup"><span data-stu-id="471b2-301">Instead, you should use one of the following methods to implement custom activities as part of your ADF pipeline.</span></span>

* <span data-ttu-id="471b2-302">.NET-activiteiten niet uitvoeren op Azure Batch-pool.</span><span class="sxs-lookup"><span data-stu-id="471b2-302">Execute .NET activities on Azure Batch pool.</span></span> <span data-ttu-id="471b2-303">Zie de gebruik Azure Batch service-sectie van gekoppelde [aangepaste activiteiten gebruiken in een Azure Data Factory-pijplijn](../data-factory/data-factory-use-custom-activities.md)</span><span class="sxs-lookup"><span data-stu-id="471b2-303">See the Use Azure Batch linked service section of [Use custom activities in an Azure Data Factory pipeline](../data-factory/data-factory-use-custom-activities.md)</span></span>
* <span data-ttu-id="471b2-304">De activiteit als een MapReduce-activiteit worden geïmplementeerd.</span><span class="sxs-lookup"><span data-stu-id="471b2-304">Implement the activity as a MapReduce activity.</span></span> <span data-ttu-id="471b2-305">Zie voor meer informatie [MapReduce-programma's uit Data Factory aanroepen](../data-factory/data-factory-map-reduce.md).</span><span class="sxs-lookup"><span data-stu-id="471b2-305">For more information, see [Invoke MapReduce Programs from Data Factory](../data-factory/data-factory-map-reduce.md).</span></span>

### <a name="line-endings"></a><span data-ttu-id="471b2-306">Regeleinden</span><span class="sxs-lookup"><span data-stu-id="471b2-306">Line endings</span></span>

<span data-ttu-id="471b2-307">In het algemeen gebruik regeleinden op Windows-systemen bij van CRLF, op basis van Linux-systemen LF gebruiken.</span><span class="sxs-lookup"><span data-stu-id="471b2-307">In general, line endings on Windows-based systems use CRLF, while Linux-based systems use LF.</span></span> <span data-ttu-id="471b2-308">Als u produceren, of van plan, gegevens met regeleinden CRLF bent, moet u wellicht de producenten of consumenten werken met het einde van de regel LF wijzigen.</span><span class="sxs-lookup"><span data-stu-id="471b2-308">If you produce, or expect, data with CRLF line endings, you may need to modify the producers or consumers to work with the LF line ending.</span></span>

<span data-ttu-id="471b2-309">Bijvoorbeeld, retourneert met behulp van Azure PowerShell query HDInsight op een cluster met Windows-gegevens met CRLF.</span><span class="sxs-lookup"><span data-stu-id="471b2-309">For example, using Azure PowerShell to query HDInsight on a Windows-based cluster returns data with CRLF.</span></span> <span data-ttu-id="471b2-310">Dezelfde query met een cluster op basis van Linux retourneert LF.</span><span class="sxs-lookup"><span data-stu-id="471b2-310">The same query with a Linux-based cluster returns LF.</span></span> <span data-ttu-id="471b2-311">U moet testen om te zien als het einde van regel zorgt ervoor een probleem met uw solutuion dat voordat u migreert naar een cluster op basis van Linux.</span><span class="sxs-lookup"><span data-stu-id="471b2-311">You should test to see if the line ending causes a problem with your solutuion before migrating to a Linux-based cluster.</span></span>

<span data-ttu-id="471b2-312">Als u scripts die rechtstreeks op de Linux-clusterknooppunten worden uitgevoerd hebt, moet u altijd LF gebruiken als het beëindigen van de regel.</span><span class="sxs-lookup"><span data-stu-id="471b2-312">If you have scripts that are executed directly on the Linux-cluster nodes, you should always use LF as the line ending.</span></span> <span data-ttu-id="471b2-313">Als u CRLF gebruikt, kunt u misschien fouten ziet wanneer de scripts uitgevoerd op een cluster op basis van Linux.</span><span class="sxs-lookup"><span data-stu-id="471b2-313">If you use CRLF, you may see errors when running the scripts on a Linux-based cluster.</span></span>

<span data-ttu-id="471b2-314">Als u de scripts bevatten geen tekenreeksen met ingesloten CR tekens, kunt u wijzigen bulksgewijs de regeleinden met behulp van een van de volgende methoden:</span><span class="sxs-lookup"><span data-stu-id="471b2-314">If you know that the scripts do not contain strings with embedded CR characters, you can bulk change the line endings using one of the following methods:</span></span>

* <span data-ttu-id="471b2-315">**Voordat u uploadt naar het cluster**: Gebruik de volgende PowerShell-instructies om de regeleinden van CRLF te LF wijzigen voordat u het script uploadt naar het cluster.</span><span class="sxs-lookup"><span data-stu-id="471b2-315">**Before uploading to the cluster**: Use the following PowerShell statements to change the line endings from CRLF to LF before uploading the script to the cluster.</span></span>

    ```powershell
    $original_file ='c:\path\to\script.py'
    $text = [IO.File]::ReadAllText($original_file) -replace "`r`n", "`n"
    [IO.File]::WriteAllText($original_file, $text)
    ```

* <span data-ttu-id="471b2-316">**Na het uploaden van het cluster**: Gebruik de volgende opdracht vanaf een SSH-sessie met het cluster op basis van Linux te wijzigen van het script.</span><span class="sxs-lookup"><span data-stu-id="471b2-316">**After uploading to the cluster**: Use the following command from an SSH session to the Linux-based cluster to modify the script.</span></span>

    ```bash
    hdfs dfs -get wasb:///path/to/script.py oldscript.py
    tr -d '\r' < oldscript.py > script.py
    hdfs dfs -put -f script.py wasb:///path/to/script.py
    ```

## <a name="next-steps"></a><span data-ttu-id="471b2-317">Volgende stappen</span><span class="sxs-lookup"><span data-stu-id="471b2-317">Next Steps</span></span>

* [<span data-ttu-id="471b2-318">Informatie over het maken van Linux gebaseerde HDInsight-clusters</span><span class="sxs-lookup"><span data-stu-id="471b2-318">Learn how to create Linux-based HDInsight clusters</span></span>](hdinsight-hadoop-provision-linux-clusters.md)
* [<span data-ttu-id="471b2-319">SSH gebruiken met HDInsight</span><span class="sxs-lookup"><span data-stu-id="471b2-319">Use SSH to connect to HDInsight</span></span>](hdinsight-hadoop-linux-use-ssh-unix.md)
* [<span data-ttu-id="471b2-320">Beheer op basis van Linux clusters met Ambari</span><span class="sxs-lookup"><span data-stu-id="471b2-320">Manage a Linux-based cluster using Ambari</span></span>](hdinsight-hadoop-manage-ambari.md)
