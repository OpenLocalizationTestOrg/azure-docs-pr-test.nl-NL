---
title: aaaManage resources voor Apache Spark in Azure HDInsight-cluster | Microsoft Docs
description: Meer informatie over hoe toouse resources beheren voor Spark-clusters in Azure HDInsight voor betere prestaties.
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: e18682a24f77494db884105f9db03c0a350ddad6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 10/06/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="a6dc1-103">Resources beheren voor Apache Spark-cluster in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="a6dc1-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="a6dc1-104">In dit artikel leert u hoe tooaccess Hallo interfaces zoals Ambari UI, gebruikersinterface van YARN en Hallo Spark geschiedenis Server die is gekoppeld aan uw Spark-cluster.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-104">In this article you will learn how tooaccess hello interfaces like Ambari UI, YARN UI, and hello Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="a6dc1-105">U wordt ook meer informatie over hoe tootune Hallo clusterconfiguratie voor optimale prestaties.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-105">You will also learn about how tootune hello cluster configuration for optimal performance.</span></span>

<span data-ttu-id="a6dc1-106">**Vereisten:**</span><span class="sxs-lookup"><span data-stu-id="a6dc1-106">**Prerequisites:**</span></span>

<span data-ttu-id="a6dc1-107">U moet Hallo volgende hebben:</span><span class="sxs-lookup"><span data-stu-id="a6dc1-107">You must have hello following:</span></span>

* <span data-ttu-id="a6dc1-108">Een Azure-abonnement.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-108">An Azure subscription.</span></span> <span data-ttu-id="a6dc1-109">Zie [Gratis proefversie van Azure ophalen](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="a6dc1-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="a6dc1-110">Een Apache Spark-cluster in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="a6dc1-111">Zie voor instructies [maken Apache Spark-clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="a6dc1-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-hello-ambari-web-ui"></a><span data-ttu-id="a6dc1-112">Hoe ik Hallo Ambari-Webgebruikersinterface starten?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-112">How do I launch hello Ambari Web UI?</span></span>
1. <span data-ttu-id="a6dc1-113">Van Hallo [Azure Portal](https://portal.azure.com/), vanaf Hallo startboard, klikt u op Hallo tegel voor uw Spark-cluster (als u toohello startboard vastgemaakt).</span><span class="sxs-lookup"><span data-stu-id="a6dc1-113">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span> <span data-ttu-id="a6dc1-114">U kunt ook tooyour cluster onder navigeren **door alles bladeren** > **HDInsight-Clusters**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-114">You can also navigate tooyour cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="a6dc1-115">Klik op Hallo blade Spark-cluster **Dashboard**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-115">From hello Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="a6dc1-116">Wanneer u wordt gevraagd, voert u Hallo beheerdersreferenties voor Hallo Spark-cluster.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-116">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

    <span data-ttu-id="a6dc1-117">![Ambari starten](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span><span class="sxs-lookup"><span data-stu-id="a6dc1-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="a6dc1-118">Dit moet Hallo Ambari-Webgebruikersinterface, starten, zoals hieronder wordt weergegeven.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-118">This should launch hello Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="a6dc1-119">![Ambari-webgebruikersinterface](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari-webgebruikersinterface")</span><span class="sxs-lookup"><span data-stu-id="a6dc1-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-hello-spark-history-server"></a><span data-ttu-id="a6dc1-120">Hoe ik Hallo Spark geschiedenis Server starten?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-120">How do I launch hello Spark History Server?</span></span>
1. <span data-ttu-id="a6dc1-121">Van Hallo [Azure Portal](https://portal.azure.com/), vanaf Hallo startboard, klikt u op Hallo tegel voor uw Spark-cluster (als u toohello startboard vastgemaakt).</span><span class="sxs-lookup"><span data-stu-id="a6dc1-121">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span>
2. <span data-ttu-id="a6dc1-122">Bij Hallo cluster blade onder **snelkoppelingen**, klikt u op **Cluster-Dashboard**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-122">From hello cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="a6dc1-123">In Hallo **Cluster-Dashboard** blade, klikt u op **Spark geschiedenis Server**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-123">In hello **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="a6dc1-124">![Spark geschiedenis Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark geschiedenis van Server")</span><span class="sxs-lookup"><span data-stu-id="a6dc1-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="a6dc1-125">Wanneer u wordt gevraagd, voert u Hallo beheerdersreferenties voor Hallo Spark-cluster.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-125">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

## <a name="how-do-i-launch-hello-yarn-ui"></a><span data-ttu-id="a6dc1-126">Hoe ik Hallo gebruikersinterface van Yarn starten?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-126">How do I launch hello Yarn UI?</span></span>
<span data-ttu-id="a6dc1-127">U kunt Hallo gebruikersinterface van YARN toomonitor toepassingen die momenteel worden uitgevoerd op Hallo Spark-cluster gebruiken.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-127">You can use hello YARN UI toomonitor applications that are currently running on hello Spark cluster.</span></span>

1. <span data-ttu-id="a6dc1-128">Cluster-blade hello, klikt u op **Cluster-Dashboard**, en klik vervolgens op **YARN**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-128">From hello cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Gebruikersinterface van YARN starten](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="a6dc1-130">U kunt ook kunt u ook Hallo gebruikersinterface van YARN van Hallo Ambari UI starten.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-130">Alternatively, you can also launch hello YARN UI from hello Ambari UI.</span></span> <span data-ttu-id="a6dc1-131">toolaunch hello Ambari UI, cluster-blade hello, klikt u op **Cluster-Dashboard**, en klik vervolgens op **HDInsight-Cluster-Dashboard**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-131">toolaunch hello Ambari UI, from hello cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="a6dc1-132">Hallo Ambari UI, klik op **YARN**, klikt u op **snelkoppelingen**op Hallo active resourcemanager en klik vervolgens op **ResourceManager UI**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-132">From hello Ambari UI, click **YARN**, click **Quick Links**, click hello active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-hello-optimum-cluster-configuration-toorun-spark-applications"></a><span data-ttu-id="a6dc1-133">Wat is Hallo optimale configuratie toorun Spark clustertoepassingen?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-133">What is hello optimum cluster configuration toorun Spark applications?</span></span>
<span data-ttu-id="a6dc1-134">Hallo drie belangrijke parameters die kunnen worden gebruikt voor de configuratie van Spark, afhankelijk van de toepassingsvereisten zijn `spark.executor.instances`, `spark.executor.cores`, en `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-134">hello three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="a6dc1-135">Een Executor is een proces gestart voor een Spark-toepassing.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="a6dc1-136">Het wordt uitgevoerd op hello werkrolknooppunt en is verantwoordelijk toocarry Hallo taken voor de toepassing hello uit.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-136">It runs on hello worker node and is responsible toocarry out hello tasks for hello application.</span></span> <span data-ttu-id="a6dc1-137">Hallo standaardaantal Executor en Hallo executor grootten voor elk cluster wordt berekend op basis van Hallo aantal worker-knooppunten en Hallo worker knooppuntgrootte.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-137">hello default number of executors and hello executor sizes for each cluster is calculated based on hello number of worker nodes and hello worker node size.</span></span> <span data-ttu-id="a6dc1-138">Deze worden opgeslagen in `spark-defaults.conf` op Hallo van head clusterknooppunten.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-138">These are stored in `spark-defaults.conf` on hello cluster head nodes.</span></span>

<span data-ttu-id="a6dc1-139">Hallo drie configuratieparameters kunnen worden geconfigureerd op clusterniveau hello (voor alle toepassingen die worden uitgevoerd op Hallo cluster) of voor elke afzonderlijke toepassing ook kunnen worden opgegeven.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-139">hello three configuration parameters can be configured at hello cluster level (for all applications that run on hello cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-hello-parameters-using-ambari-ui"></a><span data-ttu-id="a6dc1-140">Hallo-parameters met Ambari UI wijzigen</span><span class="sxs-lookup"><span data-stu-id="a6dc1-140">Change hello parameters using Ambari UI</span></span>
1. <span data-ttu-id="a6dc1-141">Hallo Ambari UI Klik **Spark**, klikt u op **Configs**, en vouw vervolgens **aangepaste spark-standaardwaarden**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-141">From hello Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Parameters instellen met Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="a6dc1-143">Hallo standaardwaarden zijn goede toohave 4 Spark scala-toepassingen op Hallo cluster gelijktijdig worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-143">hello default values are good toohave 4 Spark applications run concurrently on hello cluster.</span></span> <span data-ttu-id="a6dc1-144">U kunt wijzigingen deze waarden via de gebruikersinterface hello, zoals hieronder wordt weergegeven.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-144">You can changes these values from hello user interface, as shown below.</span></span>

    ![Parameters instellen met Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="a6dc1-146">Klik op **opslaan** toosave Hallo configuratiewijzigingen.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-146">Click **Save** toosave hello configuration changes.</span></span> <span data-ttu-id="a6dc1-147">Bovenaan Hallo Hallo pagina, wordt u gevraagd alle Hallo toorestart betrokken services.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-147">At hello top of hello page, you will be prompted toorestart all hello affected services.</span></span> <span data-ttu-id="a6dc1-148">Klik op **opnieuw**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-148">Click **Restart**.</span></span>

    ![Services opnieuw starten](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-hello-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="a6dc1-150">Hallo-parameters voor een toepassing die wordt uitgevoerd in Jupyter-notebook wijzigen</span><span class="sxs-lookup"><span data-stu-id="a6dc1-150">Change hello parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="a6dc1-151">Voor toepassingen die worden uitgevoerd in de Jupyter-notebook hello, kunt u Hallo `%%configure` magic toomake Hallo configuratiewijzigingen.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-151">For applications running in hello Jupyter notebook, you can use hello `%%configure` magic toomake hello configuration changes.</span></span> <span data-ttu-id="a6dc1-152">In het ideale geval moet u deze wijzigingen aanbrengen aan Hallo begin van de toepassing hello, voordat u uw eerste codecel uitvoert.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-152">Ideally, you must make such changes at hello beginning of hello application, before you run your first code cell.</span></span> <span data-ttu-id="a6dc1-153">Dit zorgt ervoor dat configuration Hallo toegepaste toohello Livy-sessie wanneer deze wordt gemaakt.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-153">This ensures that hello configuration is applied toohello Livy session, when it gets created.</span></span> <span data-ttu-id="a6dc1-154">Als u wilt dat toochange Hallo configuratie op een later stadium in de toepassing hello, moet u Hallo `-f` parameter.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-154">If you want toochange hello configuration at a later stage in hello application, you must use hello `-f` parameter.</span></span> <span data-ttu-id="a6dc1-155">Hierdoor alle voortgang in Hallo wordt toepassing wel verloren.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-155">However, by doing so all progress in hello application will be lost.</span></span>

<span data-ttu-id="a6dc1-156">Hallo codefragment hieronder ziet u hoe toochange configuratie voor een toepassing die wordt uitgevoerd in Jupyter Hallo.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-156">hello snippet below shows how toochange hello configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="a6dc1-157">Parameters voor de configuratie moeten worden doorgegeven als een JSON-tekenreeks en moeten op de volgende regel Hallo na het Hallo-magic, zoals weergegeven in Hallo voorbeeldkolom.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-157">Configuration parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span>

### <a name="change-hello-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="a6dc1-158">Wijziging Hallo parameters voor een toepassing die wordt verzonden met verzenden spark</span><span class="sxs-lookup"><span data-stu-id="a6dc1-158">Change hello parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="a6dc1-159">Na de opdracht is een voorbeeld van hoe toochange configuratieparameters voor een batch-toepassing die wordt verzonden met behulp van Hallo `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-159">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <hello application class tooexecute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-hello-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="a6dc1-160">Hallo-parameters voor een toepassing die wordt verzonden met cURL wijzigen</span><span class="sxs-lookup"><span data-stu-id="a6dc1-160">Change hello parameters for an application submitted using cURL</span></span>
<span data-ttu-id="a6dc1-161">Na de opdracht is een voorbeeld van hoe toochange configuratieparameters voor een batch-toepassing die wordt verzonden met behulp van cURL Hallo.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-161">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<hello application class tooexecute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="a6dc1-162">Hoe kan ik deze parameters op een Spark Thrift-Server wijzigen?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="a6dc1-163">Spark Thrift-Server JDBC/ODBC toegang tooa Spark-cluster en gebruikte tooservice Spark SQL-query's is.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-163">Spark Thrift Server provides JDBC/ODBC access tooa Spark cluster and is used tooservice Spark SQL queries.</span></span> <span data-ttu-id="a6dc1-164">Hulpprogramma's zoals Power BI, Tableau enzovoort.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="a6dc1-165">ODBC-protocol toocommunicate met Spark Thrift-Server tooexecute Spark SQL-query's gebruiken als een Spark-toepassing.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-165">use ODBC protocol toocommunicate with Spark Thrift Server tooexecute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="a6dc1-166">Wanneer een Spark-cluster is gemaakt, twee exemplaren van Hallo Spark Thrift-Server zijn gestart, één op elke hoofdknooppunt.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-166">When a Spark cluster is created, two instances of hello Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="a6dc1-167">Elke Spark Thrift-Server wordt weergegeven als een Spark-toepassing in de gebruikersinterface van YARN Hallo.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-167">Each Spark Thrift Server is visible as a Spark application in hello YARN UI.</span></span>

<span data-ttu-id="a6dc1-168">Spark Thrift-Server gebruikt dynamische executor toewijzing Spark en daarom Hallo `spark.executor.instances` wordt niet gebruikt.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-168">Spark Thrift Server uses Spark dynamic executor allocation and hence hello `spark.executor.instances` is not used.</span></span> <span data-ttu-id="a6dc1-169">In plaats daarvan Spark Thrift-Server gebruikt `spark.dynamicAllocation.minExecutors` en `spark.dynamicAllocation.maxExecutors` toospecify Hallo executor count.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` toospecify hello executor count.</span></span> <span data-ttu-id="a6dc1-170">Hallo configuratieparameters `spark.executor.cores` en `spark.executor.memory` is toomodify Hallo executor grootte gebruikt.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-170">hello configuration parameters `spark.executor.cores` and `spark.executor.memory` is used toomodify hello executor size.</span></span> <span data-ttu-id="a6dc1-171">U kunt deze parameters kunt wijzigen, zoals hieronder wordt weergegeven.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="a6dc1-172">Vouw Hallo **geavanceerde spark-thrift-sparkconf** categorie tooupdate Hallo parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, en `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-172">Expand hello **Advanced spark-thrift-sparkconf** category tooupdate hello parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Spark thrift-server configureren](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="a6dc1-174">Vouw Hallo **aangepaste spark thrift sparkconf** categorie tooupdate Hallo parameter `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-174">Expand hello **Custom spark-thrift-sparkconf** category tooupdate hello parameter `spark.executor.cores`.</span></span>

    ![Spark thrift-server configureren](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-hello-driver-memory-of-hello-spark-thrift-server"></a><span data-ttu-id="a6dc1-176">Hoe wijzig ik Hallo stuurprogramma geheugen Hallo Spark Thrift-Server?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-176">How do I change hello driver memory of hello Spark Thrift Server?</span></span>
<span data-ttu-id="a6dc1-177">Spark Thrift-Server stuurprogramma geheugen is % van de geconfigureerde too25 met een grootte voor het hoofdknooppunt RAM-geheugen van Hallo opgegeven Hallo totale RAM-geheugen van het hoofdknooppunt Hallo groter dan 14GB is.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-177">Spark Thrift Server driver memory is configured too25% of hello head node RAM size, provided hello total RAM size of hello head node is greater than 14GB.</span></span> <span data-ttu-id="a6dc1-178">U kunt Hallo Ambari UI toochange Hallo stuurprogramma geheugenconfiguratie, zoals hieronder wordt weergegeven.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-178">You can use hello Ambari UI toochange hello driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="a6dc1-179">Hallo Ambari UI Klik **Spark**, klikt u op **Configs**, vouw **spark env geavanceerde**, en geef vervolgens de waarde voor Hallo **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-179">From hello Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide hello value for **spark_thrift_cmd_opts**.</span></span>

    ![RAM-geheugen voor Spark thrift-server configureren](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-hello-resources-back"></a><span data-ttu-id="a6dc1-181">Ik gebruik geen BI met Spark-cluster.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="a6dc1-182">Hoe ik Hallo resources terug uitvoeren?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-182">How do I take hello resources back?</span></span>
<span data-ttu-id="a6dc1-183">Aangezien we de dynamische toewijzing Spark gebruiken, zijn hello alleen de resources die worden verbruikt door thrift-server Hallo bronnen voor Hallo twee toepassing modellen.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-183">Since we use Spark dynamic allocation, hello only resources that are consumed by thrift server are hello resources for hello two application masters.</span></span> <span data-ttu-id="a6dc1-184">tooreclaim deze resources die moet u stoppen Hallo services Thrift-Server op Hallo-cluster.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-184">tooreclaim these resources you must stop hello Thrift Server services running on hello cluster.</span></span>

1. <span data-ttu-id="a6dc1-185">Hallo Ambari UI, in het linkerdeelvenster hello, klik op **Spark**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-185">From hello Ambari UI, from hello left pane, click **Spark**.</span></span>
2. <span data-ttu-id="a6dc1-186">Klik in de volgende pagina Hallo op **Spark Thrift Servers**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-186">In hello next page, click **Spark Thrift Servers**.</span></span>

    ![Thrift-server opnieuw opstarten](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="a6dc1-188">Hier ziet u twee Hallo-headnodes welke Hallo Spark Thrift-Server wordt uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-188">You should see hello two headnodes on which hello Spark Thrift Server is running.</span></span> <span data-ttu-id="a6dc1-189">Klik op een Hallo headnodes.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-189">Click one of hello headnodes.</span></span>

    ![Thrift-server opnieuw opstarten](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="a6dc1-191">de volgende pagina Hallo geeft een lijst van alle Hallo services worden uitgevoerd op die headnode.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-191">hello next page lists all hello services running on that headnode.</span></span> <span data-ttu-id="a6dc1-192">In de lijst Hallo Hallo vervolgkeuzeknop volgende tooSpark Thrift-Server op en klik op **stoppen**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-192">From hello list click hello drop-down button next tooSpark Thrift Server, and then click **Stop**.</span></span>

    ![Thrift-server opnieuw opstarten](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="a6dc1-194">Herhaal deze stappen op Hallo ook andere headnode.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-194">Repeat these steps on hello other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-hello-service"></a><span data-ttu-id="a6dc1-195">Mijn Jupyter-notebooks niet worden uitgevoerd zoals verwacht.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="a6dc1-196">Hoe kan ik Hallo-service opnieuw starten?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-196">How can I restart hello service?</span></span>
<span data-ttu-id="a6dc1-197">Start Hallo Ambari-Webgebruikersinterface zoals hierboven.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-197">Launch hello Ambari Web UI as shown above.</span></span> <span data-ttu-id="a6dc1-198">Hallo navigatiedeelvenster links, klik op **Jupyter**, klikt u op **serviceacties**, en klik vervolgens op **start opnieuw alle**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-198">From hello left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="a6dc1-199">Hiermee start u Hallo Jupyter-service op alle Hallo headnodes.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-199">This will start hello Jupyter service on all hello headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="a6dc1-200">Hoe weet ik of mijn onvoldoende resources werkt systeem?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="a6dc1-201">Start de gebruikersinterface van Yarn Hallo zoals hierboven.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-201">Launch hello Yarn UI as shown above.</span></span> <span data-ttu-id="a6dc1-202">In de tabel van de Cluster metrische gegevens boven op het welkomstscherm, controleert u de waarden van **geheugen gebruikt** en **Totaal geheugen** kolommen.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-202">In Cluster Metrics table on top of hello screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="a6dc1-203">Als de waarden Hallo 2 bijna, er mogelijk niet voldoende bronnen toostart Hallo volgende toepassing.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-203">If hello 2 values are very close, there might not be enough resources toostart hello next application.</span></span> <span data-ttu-id="a6dc1-204">Hallo geldt toohello **VCores gebruikt** en **VCores totaal** kolommen.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-204">hello same applies toohello **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="a6dc1-205">Ook in de hoofdweergave hello, als er een toepassing gebleven **GEACCEPTEERDE** status en niet in een overgang **met** noch **mislukt** staat, dit kan ook wel een indicatie deze is niet voldoende bronnen toostart ophalen.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-205">Also, in hello main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources toostart.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-toofree-up-resource"></a><span data-ttu-id="a6dc1-206">Hoe kill een actieve toepassing toofree bron?</span><span class="sxs-lookup"><span data-stu-id="a6dc1-206">How do I kill a running application toofree up resource?</span></span>
1. <span data-ttu-id="a6dc1-207">Klik in de gebruikersinterface van Yarn Hallo van het linkerpaneel Hallo, op **met**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-207">In hello Yarn UI, from hello left panel, click **Running**.</span></span> <span data-ttu-id="a6dc1-208">Bepalen in lijst van actieve toepassingen Hallo Hallo toepassing toobe afgesloten en klik op Hallo **ID**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-208">From hello list of running applications, determine hello application toobe killed and click on hello **ID**.</span></span>

    <span data-ttu-id="a6dc1-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "App1 afsluiten")</span><span class="sxs-lookup"><span data-stu-id="a6dc1-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="a6dc1-210">Klik op **toepassing Kill** op Hallo rechterbovenhoek, klik vervolgens op **OK**.</span><span class="sxs-lookup"><span data-stu-id="a6dc1-210">Click **Kill Application** on hello top right corner, then click **OK**.</span></span>

    <span data-ttu-id="a6dc1-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "App2 afsluiten")</span><span class="sxs-lookup"><span data-stu-id="a6dc1-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="a6dc1-212">Zie ook</span><span class="sxs-lookup"><span data-stu-id="a6dc1-212">See also</span></span>
* [<span data-ttu-id="a6dc1-213">Taken die worden uitgevoerd in een Apache Spark-cluster in HDInsight, traceren en er fouten in oplossen</span><span class="sxs-lookup"><span data-stu-id="a6dc1-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="a6dc1-214">Voor gegevensanalisten</span><span class="sxs-lookup"><span data-stu-id="a6dc1-214">For data analysts</span></span>

* [<span data-ttu-id="a6dc1-215">Spark met Machine Learning: Spark in HDInsight gebruiken voor het analyseren van de gebouwtemperatuur met behulp van HVAC-gegevens</span><span class="sxs-lookup"><span data-stu-id="a6dc1-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="a6dc1-216">Spark met Machine Learning: Spark in HDInsight toopredict voedselinspectieresultaten gebruiken</span><span class="sxs-lookup"><span data-stu-id="a6dc1-216">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="a6dc1-217">Websitelogboekanalyse met Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="a6dc1-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="a6dc1-218">Analyse van Application Insights-telemetriegegevens met behulp van Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="a6dc1-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="a6dc1-219">Gebruik Caffe op Azure HDInsight Spark voor gedistribueerde grondige learning</span><span class="sxs-lookup"><span data-stu-id="a6dc1-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="a6dc1-220">Voor Spark-ontwikkelaars</span><span class="sxs-lookup"><span data-stu-id="a6dc1-220">For Spark developers</span></span>

* [<span data-ttu-id="a6dc1-221">Een zelfstandige toepassing maken met behulp van Scala</span><span class="sxs-lookup"><span data-stu-id="a6dc1-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="a6dc1-222">Taken op afstand uitvoeren in een Spark-cluster met behulp van Livy</span><span class="sxs-lookup"><span data-stu-id="a6dc1-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="a6dc1-223">De invoegtoepassing HDInsight Tools voor IntelliJ IDEA toocreate en verzenden van Spark Scala-toepassingen</span><span class="sxs-lookup"><span data-stu-id="a6dc1-223">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="a6dc1-224">Spark-streaming: Spark in HDInsight gebruiken voor het bouwen van realtime streamingtoepassingen</span><span class="sxs-lookup"><span data-stu-id="a6dc1-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="a6dc1-225">De invoegtoepassing HDInsight Tools for IntelliJ IDEA toodebug Spark applications op afstand gebruiken</span><span class="sxs-lookup"><span data-stu-id="a6dc1-225">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="a6dc1-226">Zeppelin-notebooks gebruiken met een Spark-cluster in HDInsight</span><span class="sxs-lookup"><span data-stu-id="a6dc1-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="a6dc1-227">Beschikbare kernels voor Jupyter-notebook in Spark-cluster voor HDInsight</span><span class="sxs-lookup"><span data-stu-id="a6dc1-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="a6dc1-228">Externe pakketten gebruiken met Jupyter-notebooks</span><span class="sxs-lookup"><span data-stu-id="a6dc1-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="a6dc1-229">Jupyter op uw computer installeren en verbinding maken met tooan HDInsight Spark-cluster</span><span class="sxs-lookup"><span data-stu-id="a6dc1-229">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
