---
title: Evalueren van de prestaties van het model in Machine Learning | Microsoft Docs
description: Legt uit hoe evalueren model prestaties in Azure Machine Learning.
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
ms.assetid: 5dc5348a-4488-4536-99eb-ff105be9b160
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/20/2017
ms.author: bradsev;garye
ms.openlocfilehash: d9576e0059f2e77a684e518389182e713f0a4f09
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 07/11/2017
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning"></a><span data-ttu-id="431ca-103">Modelprestaties evalueren in Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="431ca-103">How to evaluate model performance in Azure Machine Learning</span></span>
<span data-ttu-id="431ca-104">Dit artikel laat zien hoe u de prestaties van een model in Azure Machine Learning Studio evalueren en bevat een korte uitleg van de beschikbare metrische gegevens voor deze taak.</span><span class="sxs-lookup"><span data-stu-id="431ca-104">This article demonstrates how to evaluate the performance of a model in Azure Machine Learning Studio and provides a brief explanation of the metrics available for this task.</span></span> <span data-ttu-id="431ca-105">Drie gangbare scenario's met leren met supervisie worden weergegeven:</span><span class="sxs-lookup"><span data-stu-id="431ca-105">Three common supervised learning scenarios are presented:</span></span> 

* <span data-ttu-id="431ca-106">Regressie</span><span class="sxs-lookup"><span data-stu-id="431ca-106">regression</span></span>
* <span data-ttu-id="431ca-107">binaire classificatie</span><span class="sxs-lookup"><span data-stu-id="431ca-107">binary classification</span></span> 
* <span data-ttu-id="431ca-108">multiklassen classificatie</span><span class="sxs-lookup"><span data-stu-id="431ca-108">multiclass classification</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="431ca-109">Evalueren van de prestaties van een model is een van de core fasen in het proces van de wetenschappelijke gegevens.</span><span class="sxs-lookup"><span data-stu-id="431ca-109">Evaluating the performance of a model is one of the core stages in the data science process.</span></span> <span data-ttu-id="431ca-110">Hiermee wordt aangegeven hoe geslaagde de score (voorspellingen) van een dataset is door een getraind model.</span><span class="sxs-lookup"><span data-stu-id="431ca-110">It indicates how successful the scoring (predictions) of a dataset has been by a trained model.</span></span> 

<span data-ttu-id="431ca-111">Azure Machine Learning ondersteunt model evaluatie via twee van de belangrijkste machine learning-modules: [Evaluate Model] [ evaluate-model] en [gekruist te valideren Model][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="431ca-111">Azure Machine Learning supports model evaluation through two of its main machine learning modules: [Evaluate Model][evaluate-model] and [Cross-Validate Model][cross-validate-model].</span></span> <span data-ttu-id="431ca-112">Deze modules kunnen u zien hoe uw model uitvoert in termen van een aantal metrische gegevens die vaak worden gebruikt in machine learning en statistieken.</span><span class="sxs-lookup"><span data-stu-id="431ca-112">These modules allow you to see how your model performs in terms of a number of metrics that are commonly used in machine learning and statistics.</span></span>

## <a name="evaluation-vs-cross-validation"></a><span data-ttu-id="431ca-113">Vs evaluatie. Cross-validatie</span><span class="sxs-lookup"><span data-stu-id="431ca-113">Evaluation vs. Cross Validation</span></span>
<span data-ttu-id="431ca-114">Evaluatie en cross validatie zijn standaard manieren om de prestaties van uw model te meten.</span><span class="sxs-lookup"><span data-stu-id="431ca-114">Evaluation and cross validation are standard ways to measure the performance of your model.</span></span> <span data-ttu-id="431ca-115">Beide evaluatie metrische gegevens die u kunt controleren of vergelijken met die van andere modellen genereren.</span><span class="sxs-lookup"><span data-stu-id="431ca-115">They both generate evaluation metrics that you can inspect or compare against those of other models.</span></span>

<span data-ttu-id="431ca-116">[Model evalueren] [ evaluate-model] een scored gegevensset verwacht als invoer (of 2 in het geval dat u wilt vergelijken de prestaties van 2 verschillende modellen).</span><span class="sxs-lookup"><span data-stu-id="431ca-116">[Evaluate Model][evaluate-model] expects a scored dataset as input (or 2 in case you would like to compare the performance of 2 different models).</span></span> <span data-ttu-id="431ca-117">Dit betekent dat u moet voor het trainen van uw model met de [Model trainen] [ train-model] module en maak voorspellingen op bepaalde gegevensset met behulp van de [Score Model] [ score-model] -module, voordat u de resultaten kunt evalueren.</span><span class="sxs-lookup"><span data-stu-id="431ca-117">This means that you need to train your model using the [Train Model][train-model] module and make predictions on some dataset using the [Score Model][score-model] module, before you can evaluate the results.</span></span> <span data-ttu-id="431ca-118">De evaluatie is gebaseerd op de scored labels/waarschijnlijkheid samen met de waarde true labels, die allemaal worden uitgevoerd door de [Score Model] [ score-model] module.</span><span class="sxs-lookup"><span data-stu-id="431ca-118">The evaluation is based on the scored labels/probabilities along with the true labels, all of which are output by the [Score Model][score-model] module.</span></span>

<span data-ttu-id="431ca-119">U kunt ook kunt u cross-validatie uit te voeren een aantal bewerkingen train score evalueren (10 vouwen) automatisch op verschillende subsets van de invoergegevens.</span><span class="sxs-lookup"><span data-stu-id="431ca-119">Alternatively, you can use cross validation to perform a number of train-score-evaluate operations (10 folds) automatically on different subsets of the input data.</span></span> <span data-ttu-id="431ca-120">De invoergegevens opgesplitst 10 delen, waarbij een is gereserveerd voor het testen, en de andere 9 voor training.</span><span class="sxs-lookup"><span data-stu-id="431ca-120">The input data is split into 10 parts, where one is reserved for testing, and the other 9 for training.</span></span> <span data-ttu-id="431ca-121">Dit proces wordt herhaald 10 keer en het gemiddelde genomen van de evaluatie van metrische gegevens.</span><span class="sxs-lookup"><span data-stu-id="431ca-121">This process is repeated 10 times and the evaluation metrics are averaged.</span></span> <span data-ttu-id="431ca-122">Dit helpt bij het bepalen hoe goed een model zou generalize naar nieuwe gegevenssets.</span><span class="sxs-lookup"><span data-stu-id="431ca-122">This helps in determining how well a model would generalize to new datasets.</span></span> <span data-ttu-id="431ca-123">De [gekruist te valideren Model] [ cross-validate-model] module neemt in een ongetrainde model en sommige gelabelde gegevensset en worden de evaluatieresultaten van elk van de 10 vouwen dat, naast de gemiddelde resultaten.</span><span class="sxs-lookup"><span data-stu-id="431ca-123">The [Cross-Validate Model][cross-validate-model] module takes in an untrained model and some labeled dataset and outputs the evaluation results of each of the 10 folds, in addition to the averaged results.</span></span>

<span data-ttu-id="431ca-124">In de volgende secties we eenvoudige regressie en classificatie modellen bouwt en evalueren van de prestaties, met zowel de [Evaluate Model] [ evaluate-model] en de [gekruist te valideren Model] [ cross-validate-model] modules.</span><span class="sxs-lookup"><span data-stu-id="431ca-124">In the following sections, we will build simple regression and classification models and evaluate their performance, using both the [Evaluate Model][evaluate-model] and the [Cross-Validate Model][cross-validate-model] modules.</span></span>

## <a name="evaluating-a-regression-model"></a><span data-ttu-id="431ca-125">Een regressiemodel evalueren</span><span class="sxs-lookup"><span data-stu-id="431ca-125">Evaluating a Regression Model</span></span>
<span data-ttu-id="431ca-126">Stel dat we willen voorspellen van een auto prijs met bepaalde functies zoals dimensies, paardenkracht en engine-specificaties.</span><span class="sxs-lookup"><span data-stu-id="431ca-126">Assume we want to predict a car’s price using some features such as dimensions, horsepower, engine specs, and so on.</span></span> <span data-ttu-id="431ca-127">Dit is een probleem typische regressie waar de doelvariabele (*prijs*) is een continue numerieke waarde.</span><span class="sxs-lookup"><span data-stu-id="431ca-127">This is a typical regression problem, where the target variable (*price*) is a continuous numeric value.</span></span> <span data-ttu-id="431ca-128">We past een eenvoudige lineair regressiemodel waarmee basis van de waarden van de functie van een bepaalde auto kan de prijs van die auto's voorspellen.</span><span class="sxs-lookup"><span data-stu-id="431ca-128">We can fit a simple linear regression model that, given the feature values of a certain car, can predict the price of that car.</span></span> <span data-ttu-id="431ca-129">Deze regressiemodel kan worden gebruikt voor de beoordeling van dezelfde gegevensset die we getraind op.</span><span class="sxs-lookup"><span data-stu-id="431ca-129">This regression model can be used to score the same dataset we trained on.</span></span> <span data-ttu-id="431ca-130">Nadat we de voorspelde prijzen voor alle van de auto's hebben, kunnen we de prestaties van het model evalueren door te kijken naar de voorspellingen hoeveel van de werkelijke prijzen gemiddeld afwijken.</span><span class="sxs-lookup"><span data-stu-id="431ca-130">Once we have the predicted prices for all of the cars, we can evaluate the performance of the model by looking at how much the predictions deviate from the actual prices on average.</span></span> <span data-ttu-id="431ca-131">Een voorbeeld gebruiken we de *Automobile price data (Raw) gegevensset* beschikbaar in de **gegevenssets opgeslagen** sectie in Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="431ca-131">To illustrate this, we use the *Automobile price data (Raw) dataset* available in the **Saved Datasets** section in Azure Machine Learning Studio.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="431ca-132">Het Experiment maken</span><span class="sxs-lookup"><span data-stu-id="431ca-132">Creating the Experiment</span></span>
<span data-ttu-id="431ca-133">De volgende modules toevoegen aan uw werkruimte in Azure Machine Learning Studio:</span><span class="sxs-lookup"><span data-stu-id="431ca-133">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="431ca-134">Auto price data (Raw)</span><span class="sxs-lookup"><span data-stu-id="431ca-134">Automobile price data (Raw)</span></span>
* <span data-ttu-id="431ca-135">[Lineaire regressie][linear-regression]</span><span class="sxs-lookup"><span data-stu-id="431ca-135">[Linear Regression][linear-regression]</span></span>
* <span data-ttu-id="431ca-136">[Train Model][train-model]</span><span class="sxs-lookup"><span data-stu-id="431ca-136">[Train Model][train-model]</span></span>
* <span data-ttu-id="431ca-137">[Score-Model][score-model]</span><span class="sxs-lookup"><span data-stu-id="431ca-137">[Score Model][score-model]</span></span>
* <span data-ttu-id="431ca-138">[Model evalueren][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="431ca-138">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="431ca-139">Verbinding maken met de poorten, zoals hieronder wordt weergegeven in afbeelding 1 en stelt de Label-kolom van de [Train Model] [ train-model] module *prijs*.</span><span class="sxs-lookup"><span data-stu-id="431ca-139">Connect the ports as shown below in Figure 1 and set the Label column of the [Train Model][train-model] module to *price*.</span></span>

![Een regressiemodel evalueren](media/machine-learning-evaluate-model-performance/1.png)

<span data-ttu-id="431ca-141">Afbeelding 1.</span><span class="sxs-lookup"><span data-stu-id="431ca-141">Figure 1.</span></span> <span data-ttu-id="431ca-142">Evalueren van een regressiemodel.</span><span class="sxs-lookup"><span data-stu-id="431ca-142">Evaluating a Regression Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="431ca-143">De resultaten van de evaluatie te bekijken</span><span class="sxs-lookup"><span data-stu-id="431ca-143">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="431ca-144">Nadat het experiment is uitgevoerd, kunt u klikken op de uitvoerpoort van de [Evaluate Model] [ evaluate-model] module en selecteer *Visualize* om te zien van de evaluatieresultaten.</span><span class="sxs-lookup"><span data-stu-id="431ca-144">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results.</span></span> <span data-ttu-id="431ca-145">De evaluatie van metrische gegevens beschikbaar voor regressie modellen zijn: *Absolute Error betekenen*, *hoofdmap betekenen Absolute Error*, *Relative Absolute Error*, *Relative Squared Error*, en de *determinatiecoëfficiënt*.</span><span class="sxs-lookup"><span data-stu-id="431ca-145">The evaluation metrics available for regression models are: *Mean Absolute Error*, *Root Mean Absolute Error*, *Relative Absolute Error*, *Relative Squared Error*, and the *Coefficient of Determination*.</span></span>

<span data-ttu-id="431ca-146">De term "error" Hier geeft het verschil tussen de voorspelde waarde en de waarde ' True '.</span><span class="sxs-lookup"><span data-stu-id="431ca-146">The term "error" here represents the difference between the predicted value and the true value.</span></span> <span data-ttu-id="431ca-147">De absolute waarde of het kwadraat van dit verschil zijn meestal berekend voor het vastleggen van de totale omvang van de fout in alle exemplaren, zoals het verschil tussen de voorspelde en waar de waarde kan niet negatief zijn in sommige gevallen.</span><span class="sxs-lookup"><span data-stu-id="431ca-147">The absolute value or the square of this difference are usually computed to capture the total magnitude of error across all instances, as the difference between the predicted and true value could be negative in some cases.</span></span> <span data-ttu-id="431ca-148">De fout metrische gegevens meten de voorspellende prestaties van een regressiemodel in termen van de gemiddelde afwijking van de voorspellingen van de waarden true.</span><span class="sxs-lookup"><span data-stu-id="431ca-148">The error metrics measure the predictive performance of a regression model in terms of the mean deviation of its predictions from the true values.</span></span> <span data-ttu-id="431ca-149">Lagere foutwaarden betekent dat het model nauwkeurigere bij het maken van voorspellingen is.</span><span class="sxs-lookup"><span data-stu-id="431ca-149">Lower error values mean the model is more accurate in making predictions.</span></span> <span data-ttu-id="431ca-150">Een algemene fout metriek 0 betekent dat het model past bij de gegevens perfect.</span><span class="sxs-lookup"><span data-stu-id="431ca-150">An overall error metric of 0 means that the model fits the data perfectly.</span></span>

<span data-ttu-id="431ca-151">De determinatiecoëfficiënt, wat ook wel bekend als R kwadraat, is ook een standaardmanier meten hoe goed het model geschikt is voor de gegevens.</span><span class="sxs-lookup"><span data-stu-id="431ca-151">The coefficient of determination, which is also known as R squared, is also a standard way of measuring how well the model fits the data.</span></span> <span data-ttu-id="431ca-152">Het kan worden geïnterpreteerd als het aandeel van de variatie worden verklaard in het model.</span><span class="sxs-lookup"><span data-stu-id="431ca-152">It can be interpreted as the proportion of variation explained by the model.</span></span> <span data-ttu-id="431ca-153">Een hogere verhouding is beter in dit geval waarbij 1 geeft aan een past.</span><span class="sxs-lookup"><span data-stu-id="431ca-153">A higher proportion is better in this case, where 1 indicates a perfect fit.</span></span>

![Lineaire regressie evaluatie metrische gegevens](media/machine-learning-evaluate-model-performance/2.png)

<span data-ttu-id="431ca-155">Afbeelding 2.</span><span class="sxs-lookup"><span data-stu-id="431ca-155">Figure 2.</span></span> <span data-ttu-id="431ca-156">Lineaire regressie evaluatie metrische gegevens.</span><span class="sxs-lookup"><span data-stu-id="431ca-156">Linear Regression Evaluation Metrics.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="431ca-157">Met behulp van Cross-validatie</span><span class="sxs-lookup"><span data-stu-id="431ca-157">Using Cross Validation</span></span>
<span data-ttu-id="431ca-158">Zoals eerder gezegd, kunt u uitvoeren herhaalde training, scores en evaluaties automatisch met de [gekruist te valideren Model] [ cross-validate-model] module.</span><span class="sxs-lookup"><span data-stu-id="431ca-158">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="431ca-159">In dit geval hoeft u een gegevensset, een ongetrainde model en een [gekruist te valideren Model] [ cross-validate-model] module (Zie afbeelding hieronder).</span><span class="sxs-lookup"><span data-stu-id="431ca-159">All you need in this case is a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="431ca-160">Houd er rekening mee dat u de labelkolom ingesteld moet op *prijs* in de [gekruist te valideren Model] [ cross-validate-model] eigenschappen van de module.</span><span class="sxs-lookup"><span data-stu-id="431ca-160">Note that you need to set the label column to *price* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span>

![Een regressiemodel cross valideren](media/machine-learning-evaluate-model-performance/3.png)

<span data-ttu-id="431ca-162">Afbeelding 3.</span><span class="sxs-lookup"><span data-stu-id="431ca-162">Figure 3.</span></span> <span data-ttu-id="431ca-163">Cross-valideren van een regressiemodel.</span><span class="sxs-lookup"><span data-stu-id="431ca-163">Cross-Validating a Regression Model.</span></span>

<span data-ttu-id="431ca-164">Nadat het experiment is uitgevoerd, kunt u de resultaten van evaluatie van controleren door te klikken op de juiste uitvoerpoort van de [gekruist te valideren Model] [ cross-validate-model] module.</span><span class="sxs-lookup"><span data-stu-id="431ca-164">After running the experiment, you can inspect the evaluation results by clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="431ca-165">Dit biedt een gedetailleerde weergave van de metrische gegevens voor elke herhaling (vouwen) en de gemiddelde resultaten van elk van de metrische gegevens (afbeelding 4).</span><span class="sxs-lookup"><span data-stu-id="431ca-165">This will provide a detailed view of the metrics for each iteration (fold), and the averaged results of each of the metrics (Figure 4).</span></span>

![Kruisvalidatie resultaten van een regressiemodel](media/machine-learning-evaluate-model-performance/4.png)

<span data-ttu-id="431ca-167">Afbeelding 4.</span><span class="sxs-lookup"><span data-stu-id="431ca-167">Figure 4.</span></span> <span data-ttu-id="431ca-168">Kruisvalidatie resultaten van een regressiemodel.</span><span class="sxs-lookup"><span data-stu-id="431ca-168">Cross-Validation Results of a Regression Model.</span></span>

## <a name="evaluating-a-binary-classification-model"></a><span data-ttu-id="431ca-169">Een binaire indeling Model evalueren</span><span class="sxs-lookup"><span data-stu-id="431ca-169">Evaluating a Binary Classification Model</span></span>
<span data-ttu-id="431ca-170">In een binaire classificatie-scenario is de doelvariabele slechts twee mogelijke resultaten, bijvoorbeeld: {0, 1} of {false, true}, {negatief, positieve}.</span><span class="sxs-lookup"><span data-stu-id="431ca-170">In a binary classification scenario, the target variable has only two possible outcomes, for example: {0, 1} or {false, true}, {negative, positive}.</span></span> <span data-ttu-id="431ca-171">Wordt ervan uitgegaan dat u krijgt u een gegevensset volwassenen werknemers met enkele demografische gegevens en arbeid variabelen en u wordt gevraagd om te voorspellen van het niveau van inkomsten, een binaire variabele met de waarden {"< = 50K ', ' > 50K '}.</span><span class="sxs-lookup"><span data-stu-id="431ca-171">Assume you are given a dataset of adult employees with some demographic and employment variables, and that you are asked to predict the income level, a binary variable with the values {“<=50K”, “>50K”}.</span></span> <span data-ttu-id="431ca-172">Met andere woorden, de negatieve klasse vertegenwoordigt de werknemers die kleiner dan of gelijk zijn aan 50 kB per jaar en de positieve klasse geeft alle andere werknemers.</span><span class="sxs-lookup"><span data-stu-id="431ca-172">In other words, the negative class represents the employees who make less than or equal to 50K per year, and the positive class represents all other employees.</span></span> <span data-ttu-id="431ca-173">Net zoals in het scenario regressie zou we een model te trainen, bepaalde gegevens te beoordelen en evalueren van de resultaten.</span><span class="sxs-lookup"><span data-stu-id="431ca-173">As in the regression scenario, we would train a model, score some data, and evaluate the results.</span></span> <span data-ttu-id="431ca-174">Het belangrijkste verschil is hier is de keuze van metrische gegevens die Azure Machine Learning wordt berekend en uitvoer.</span><span class="sxs-lookup"><span data-stu-id="431ca-174">The main difference here is the choice of metrics Azure Machine Learning computes and outputs.</span></span> <span data-ttu-id="431ca-175">Ter illustratie van het niveau voorspelling inkomsten scenario, gebruiken we de [volwassenen](http://archive.ics.uci.edu/ml/datasets/Adult) gegevensset voor het maken van een Azure Machine Learning-experiment en evalueren van de prestaties van een tweeklasse logistic regressiemodel, een veelgebruikte binaire classificatie.</span><span class="sxs-lookup"><span data-stu-id="431ca-175">To illustrate the income level prediction scenario, we will use the [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) dataset to create an Azure Machine Learning experiment and evaluate the performance of a two-class logistic regression model, a commonly used binary classifier.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="431ca-176">Het Experiment maken</span><span class="sxs-lookup"><span data-stu-id="431ca-176">Creating the Experiment</span></span>
<span data-ttu-id="431ca-177">De volgende modules toevoegen aan uw werkruimte in Azure Machine Learning Studio:</span><span class="sxs-lookup"><span data-stu-id="431ca-177">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="431ca-178">Volwassenen inventarisering Income binaire classificatie gegevensset</span><span class="sxs-lookup"><span data-stu-id="431ca-178">Adult Census Income Binary Classification dataset</span></span>
* <span data-ttu-id="431ca-179">[Two-Class Logistic Regression][two-class-logistic-regression]</span><span class="sxs-lookup"><span data-stu-id="431ca-179">[Two-Class Logistic Regression][two-class-logistic-regression]</span></span>
* <span data-ttu-id="431ca-180">[Train Model][train-model]</span><span class="sxs-lookup"><span data-stu-id="431ca-180">[Train Model][train-model]</span></span>
* <span data-ttu-id="431ca-181">[Score-Model][score-model]</span><span class="sxs-lookup"><span data-stu-id="431ca-181">[Score Model][score-model]</span></span>
* <span data-ttu-id="431ca-182">[Model evalueren][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="431ca-182">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="431ca-183">Verbinding maken met de poorten, zoals hieronder wordt weergegeven in afbeelding 5 en stelt de Label-kolom van de [Train Model] [ train-model] module *inkomsten*.</span><span class="sxs-lookup"><span data-stu-id="431ca-183">Connect the ports as shown below in Figure 5 and set the Label column of the [Train Model][train-model] module to *income*.</span></span>

![Een binaire indeling Model evalueren](media/machine-learning-evaluate-model-performance/5.png)

<span data-ttu-id="431ca-185">Afbeelding 5.</span><span class="sxs-lookup"><span data-stu-id="431ca-185">Figure 5.</span></span> <span data-ttu-id="431ca-186">Een binaire indeling Model evalueren.</span><span class="sxs-lookup"><span data-stu-id="431ca-186">Evaluating a Binary Classification Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="431ca-187">De resultaten van de evaluatie te bekijken</span><span class="sxs-lookup"><span data-stu-id="431ca-187">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="431ca-188">Nadat het experiment is uitgevoerd, kunt u klikken op de uitvoerpoort van de [Evaluate Model] [ evaluate-model] module en selecteer *Visualize* om te zien van de evaluatieresultaten (afbeelding 7).</span><span class="sxs-lookup"><span data-stu-id="431ca-188">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results (Figure 7).</span></span> <span data-ttu-id="431ca-189">De evaluatie van metrische gegevens beschikbaar voor binaire classificatie modellen zijn: *nauwkeurigheid*, *precisie*, *intrekken*, *F1 Score*, en *AUC*.</span><span class="sxs-lookup"><span data-stu-id="431ca-189">The evaluation metrics available for binary classification models are: *Accuracy*, *Precision*, *Recall*, *F1 Score*, and *AUC*.</span></span> <span data-ttu-id="431ca-190">Bovendien de module een verwarring matrix met het aantal positieven true, false negatieve valse positieven en waar negatieve levert, evenals *ROC*, *precisie/intrekken*, en *til* curven.</span><span class="sxs-lookup"><span data-stu-id="431ca-190">In addition, the module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as *ROC*, *Precision/Recall*, and *Lift* curves.</span></span>

<span data-ttu-id="431ca-191">Nauwkeurigheid is het aantal exemplaren correct ingedeeld.</span><span class="sxs-lookup"><span data-stu-id="431ca-191">Accuracy is simply the proportion of correctly classified instances.</span></span> <span data-ttu-id="431ca-192">Meestal is dit de eerste metrische gegevens die u bekijkt bij het evalueren van een classificatie.</span><span class="sxs-lookup"><span data-stu-id="431ca-192">It is usually the first metric you look at when evaluating a classifier.</span></span> <span data-ttu-id="431ca-193">Wanneer de testgegevens is echter niet in balans (waar de meeste van de exemplaren behoren tot een van de klassen) of als u meer geïnteresseerd in de prestaties op een van de klassen, nauwkeurigheid echt de effectiviteit van een classificatie niet vastleggen.</span><span class="sxs-lookup"><span data-stu-id="431ca-193">However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn’t really capture the effectiveness of a classifier.</span></span> <span data-ttu-id="431ca-194">In het scenario inkomsten niveau classificatie wordt ervan uitgegaan dat u wilt testen op bepaalde gegevens waar 99% exemplaren van mensen die kleiner dan of gelijk zijn aan 50 kB per jaar verdienen vertegenwoordigen.</span><span class="sxs-lookup"><span data-stu-id="431ca-194">In the income level classification scenario, assume you are testing on some data where 99% of the instances represent people who earn less than or equal to 50K per year.</span></span> <span data-ttu-id="431ca-195">Het is mogelijk een 0.99 nauwkeurigheid bereiken door het voorspellen van de klasse ' < = 50K ' voor alle exemplaren.</span><span class="sxs-lookup"><span data-stu-id="431ca-195">It is possible to achieve a 0.99 accuracy by predicting the class “<=50K” for all instances.</span></span> <span data-ttu-id="431ca-196">De classificatie in dit geval wordt weergegeven in algemene goed werk, maar in werkelijkheid is mislukt voor het classificeren van een van de hoog inkomen personen (1%) correct.</span><span class="sxs-lookup"><span data-stu-id="431ca-196">The classifier in this case appears to be doing a good job overall, but in reality, it fails to classify any of the high-income individuals (the 1%) correctly.</span></span>

<span data-ttu-id="431ca-197">Daarom is het handig zijn voor het berekenen van aanvullende gegevens die meer specifieke aspecten van de evaluatie vastlegt.</span><span class="sxs-lookup"><span data-stu-id="431ca-197">For that reason, it is helpful to compute additional metrics that capture more specific aspects of the evaluation.</span></span> <span data-ttu-id="431ca-198">Voordat u doorgaat naar de details van deze metrische gegevens, is het belangrijk om te begrijpen van de matrix verwarring van de evaluatie van een binaire indeling.</span><span class="sxs-lookup"><span data-stu-id="431ca-198">Before going into the details of such metrics, it is important to understand the confusion matrix of a binary classification evaluation.</span></span> <span data-ttu-id="431ca-199">De klasse labels in de trainingset kunnen alleen 2 mogelijke waarden die we meestal naar verwijzen overnemen als positief of negatief.</span><span class="sxs-lookup"><span data-stu-id="431ca-199">The class labels in the training set can take on only 2 possible values, which we usually refer to as positive or negative.</span></span> <span data-ttu-id="431ca-200">Het positieve en negatieve instanties die een classificatie correct voorspelt worden genoemd waar positieven (TP) en waar negatieve (TN), respectievelijk.</span><span class="sxs-lookup"><span data-stu-id="431ca-200">The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively.</span></span> <span data-ttu-id="431ca-201">Op deze manier worden de onjuist ingedeelde exemplaren valse positieven (EP) en fout-negatieve resultaten (FN) genoemd.</span><span class="sxs-lookup"><span data-stu-id="431ca-201">Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</span></span> <span data-ttu-id="431ca-202">De matrix verwarring is gewoon een tabel met het nummer van exemplaren die bij elk van deze 4 categorieën vallen.</span><span class="sxs-lookup"><span data-stu-id="431ca-202">The confusion matrix is simply a table showing the number of instances that fall under each of these 4 categories.</span></span> <span data-ttu-id="431ca-203">Azure Machine Learning besluit automatisch welke van de twee klassen in de gegevensset is positief klasse.</span><span class="sxs-lookup"><span data-stu-id="431ca-203">Azure Machine Learning automatically decides which of the two classes in the dataset is the positive class.</span></span> <span data-ttu-id="431ca-204">Als de klasse-labels Boolean of gehele getallen zijn zijn, zijn de positieve klasse toegewezen door de gelabelde exemplaren 'true' of '1'.</span><span class="sxs-lookup"><span data-stu-id="431ca-204">If the class labels are Boolean or integers, then the ‘true’ or ‘1’ labeled instances are assigned the positive class.</span></span> <span data-ttu-id="431ca-205">Als de labels tekenreeksen zijn, in het geval van de gegevensset inkomsten, de labels alfabetische volgorde worden gesorteerd en het eerste niveau is gekozen als de negatieve klasse terwijl het tweede niveau positief klasse is.</span><span class="sxs-lookup"><span data-stu-id="431ca-205">If the labels are strings, as in the case of the income dataset, the labels are sorted alphabetically and the first level is chosen to be the negative class while the second level is the positive class.</span></span>

![Binaire classificatie verwarring Matrix](media/machine-learning-evaluate-model-performance/6a.png)

<span data-ttu-id="431ca-207">Afbeelding 6.</span><span class="sxs-lookup"><span data-stu-id="431ca-207">Figure 6.</span></span> <span data-ttu-id="431ca-208">Binaire classificatie verwarring Matrix.</span><span class="sxs-lookup"><span data-stu-id="431ca-208">Binary Classification Confusion Matrix.</span></span>

<span data-ttu-id="431ca-209">Ga terug naar de klassificatieprobleem inkomsten, zou willen we vragen verschillende evaluatievragen die help ons inzicht in de prestaties van de classificatie die wordt gebruikt.</span><span class="sxs-lookup"><span data-stu-id="431ca-209">Going back to the income classification problem, we would want to ask several evaluation questions that help us understand the performance of the classifier used.</span></span> <span data-ttu-id="431ca-210">Een logisch vraag is: ' buiten de personen die het model met het verdienen worden voorspeld > 50 K (TP + FrontPage), hoeveel zijn correct geclassificeerd (TP)?'</span><span class="sxs-lookup"><span data-stu-id="431ca-210">A very natural question is: ‘Out of the individuals whom the model predicted to be earning >50K (TP+FP), how many were classified correctly (TP)?’</span></span> <span data-ttu-id="431ca-211">Kan deze vraag worden beantwoord door te kijken naar de **precisie** van het model, is het aandeel van positieven die correct zijn geclassificeerd: TP/(TP+FP).</span><span class="sxs-lookup"><span data-stu-id="431ca-211">This question can be answered by looking at the **Precision** of the model, which is the proportion of positives that are classified correctly: TP/(TP+FP).</span></span> <span data-ttu-id="431ca-212">Vraag is ' buiten de hoge verdienen werknemers met inkomsten > 50 k (TP + FN), hoeveel de classificatie classificeren correct (TP) '.</span><span class="sxs-lookup"><span data-stu-id="431ca-212">Another common question is “Out of all the high earning employees with income >50k (TP+FN), how many did the classifier classify correctly (TP)”.</span></span> <span data-ttu-id="431ca-213">Dit is in werkelijkheid de **intrekken**, of de waarde true positief snelheid: TP/(TP+FN) van de classificatie.</span><span class="sxs-lookup"><span data-stu-id="431ca-213">This is actually the **Recall**, or the true positive rate: TP/(TP+FN) of the classifier.</span></span> <span data-ttu-id="431ca-214">Er is een duidelijke compromis tussen precision en intrekken, zult u merken.</span><span class="sxs-lookup"><span data-stu-id="431ca-214">You might notice that there is an obvious trade-off between precision and recall.</span></span> <span data-ttu-id="431ca-215">Bijvoorbeeld, een relatief taakverdeling gegevensset wordt opgegeven, heeft een classificatie die voornamelijk positief exemplaren voorspelt een hoge intrekken, maar een relatief laag precisie zo veel mogelijk negatieve exemplaren van zou worden verkeerd geclassificeerd wat resulteert in een groot aantal fout-positieven.</span><span class="sxs-lookup"><span data-stu-id="431ca-215">For example, given a relatively balanced dataset, a classifier that predicts mostly positive instances, would have a high recall, but a rather low precision as many of the negative instances would be misclassified resulting in a large number of false positives.</span></span> <span data-ttu-id="431ca-216">Overzicht van hoe deze twee metrische gegevens variëren tekent, kunt u op de curve precisie/INTREKKEN in de pagina evaluatie resultaat uitvoer (boven links deel uit van de afbeelding 7).</span><span class="sxs-lookup"><span data-stu-id="431ca-216">To see a plot of how these two metrics vary, you can click on the ‘PRECISION/RECALL’ curve in the evaluation result output page (top left part of Figure 7).</span></span>

![Resultaten van evaluatie van binaire classificatie](media/machine-learning-evaluate-model-performance/7.png)

<span data-ttu-id="431ca-218">Afbeelding 7.</span><span class="sxs-lookup"><span data-stu-id="431ca-218">Figure 7.</span></span> <span data-ttu-id="431ca-219">Resultaten van evaluatie van binaire classificatie.</span><span class="sxs-lookup"><span data-stu-id="431ca-219">Binary Classification Evaluation Results.</span></span>

<span data-ttu-id="431ca-220">Een andere gerelateerde metriek die vaak wordt gebruikt is het **F1 Score**, wat zowel precision en terughalen in aanmerking duurt.</span><span class="sxs-lookup"><span data-stu-id="431ca-220">Another related metric that is often used is the **F1 Score**, which takes both precision and recall into consideration.</span></span> <span data-ttu-id="431ca-221">Dit is het gemiddelde harmonische van deze 2 metrische gegevens en als zodanig wordt berekend: F1 = 2 (precisie x intrekken) / (precisie + intrekken).</span><span class="sxs-lookup"><span data-stu-id="431ca-221">It is the harmonic mean of these 2 metrics and is computed as such: F1 = 2 (precision x recall) / (precision + recall).</span></span> <span data-ttu-id="431ca-222">De score F1 is een uitstekende manier om samen te vatten de evaluatie van een enkel getal, maar het is altijd een goede gewoonte om te kijken naar zowel precision en terughalen samen om beter te begrijpen hoe een classificatie zich gedraagt.</span><span class="sxs-lookup"><span data-stu-id="431ca-222">The F1 score is a good way to summarize the evaluation in a single number, but it’s always a good practice to look at both precision and recall together to better understand how a classifier behaves.</span></span>

<span data-ttu-id="431ca-223">Bovendien een de waarde true positief snelheid versus de false positief frequentie in kunt inspecteren de **ontvanger besturingssysteem kenmerk (ROC)** curve en de bijbehorende **gebied onder de Curve (AUC)** waarde.</span><span class="sxs-lookup"><span data-stu-id="431ca-223">In addition, one can inspect the true positive rate vs. the false positive rate in the **Receiver Operating Characteristic (ROC)** curve and the corresponding **Area Under the Curve (AUC)** value.</span></span> <span data-ttu-id="431ca-224">Hoe dichter deze curve is in de linkerbovenhoek, hoe beter de classificatie prestaties (die is het optimaliseren van de waarde true positief snelheid terwijl het minimaliseert de false positief snelheid).</span><span class="sxs-lookup"><span data-stu-id="431ca-224">The closer this curve is to the upper left corner, the better the classifier’s performance is (that is maximizing the true positive rate while minimizing the false positive rate).</span></span> <span data-ttu-id="431ca-225">Curven die zich dicht bij de diagonaal van de grafiek, het resultaat van de classificaties die doorgaans de voorspellingen die zich dicht bij willekeurige raden.</span><span class="sxs-lookup"><span data-stu-id="431ca-225">Curves that are close to the diagonal of the plot, result from classifiers that tend to make predictions that are close to random guessing.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="431ca-226">Met behulp van Cross-validatie</span><span class="sxs-lookup"><span data-stu-id="431ca-226">Using Cross Validation</span></span>
<span data-ttu-id="431ca-227">Zoals in het voorbeeld regressie kunnen we cross validatie herhaaldelijk trainen, scores en andere subsets van de gegevens automatisch evalueren als u wilt uitvoeren.</span><span class="sxs-lookup"><span data-stu-id="431ca-227">As in the regression example, we can perform cross validation to repeatedly train, score and evaluate different subsets of the data automatically.</span></span> <span data-ttu-id="431ca-228">Op deze manier kunnen we gebruiken de [gekruist te valideren Model] [ cross-validate-model] module, een ongetrainde logistic regressiemodel en een dataset.</span><span class="sxs-lookup"><span data-stu-id="431ca-228">Similarly, we can use the [Cross-Validate Model][cross-validate-model] module, an untrained logistic regression model, and a dataset.</span></span> <span data-ttu-id="431ca-229">De labelkolom moet worden ingesteld op *inkomsten* in de [gekruist te valideren Model] [ cross-validate-model] eigenschappen van de module.</span><span class="sxs-lookup"><span data-stu-id="431ca-229">The label column must be set to *income* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span> <span data-ttu-id="431ca-230">Nadat het experiment uitvoeren en te klikken op de juiste van uitvoerpoort de [gekruist te valideren Model] [ cross-validate-model] -module, ziet u de binaire classificatie metrische waarden voor elke vouwen bovendien voor de gemiddelde en de standaarddeviatie van elke.</span><span class="sxs-lookup"><span data-stu-id="431ca-230">After running the experiment and clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module, we can see the binary classification metric values for each fold, in addition to the mean and standard deviation of each.</span></span> 

![Een binaire indeling Model cross valideren](media/machine-learning-evaluate-model-performance/8.png)

<span data-ttu-id="431ca-232">Afbeelding 8.</span><span class="sxs-lookup"><span data-stu-id="431ca-232">Figure 8.</span></span> <span data-ttu-id="431ca-233">Een binaire indeling Model cross valideren.</span><span class="sxs-lookup"><span data-stu-id="431ca-233">Cross-Validating a Binary Classification Model.</span></span>

![Kruisvalidatie resultaten van een binaire classificatie](media/machine-learning-evaluate-model-performance/9.png)

<span data-ttu-id="431ca-235">Afbeelding 9.</span><span class="sxs-lookup"><span data-stu-id="431ca-235">Figure 9.</span></span> <span data-ttu-id="431ca-236">Kruisvalidatie resultaten van een binaire classificatie.</span><span class="sxs-lookup"><span data-stu-id="431ca-236">Cross-Validation Results of a Binary Classifier.</span></span>

## <a name="evaluating-a-multiclass-classification-model"></a><span data-ttu-id="431ca-237">Evaluatie van een Model Multiklassen classificatie</span><span class="sxs-lookup"><span data-stu-id="431ca-237">Evaluating a Multiclass Classification Model</span></span>
<span data-ttu-id="431ca-238">In dit experiment gebruiken we de populaire [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") dataset die exemplaren van 3 soorten (klassen) het bedrijf iris bevat.</span><span class="sxs-lookup"><span data-stu-id="431ca-238">In this experiment we will use the popular [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") dataset which contains instances of 3 different types (classes) of the iris plant.</span></span> <span data-ttu-id="431ca-239">Er zijn 4 functie waarden (sepal lengte/breedte en lengte Bloemblad/breedte) voor elk exemplaar.</span><span class="sxs-lookup"><span data-stu-id="431ca-239">There are 4 feature values (sepal length/width and petal length/width) for each instance.</span></span> <span data-ttu-id="431ca-240">In de vorige experimenten we getraind en de modellen met behulp van de dezelfde gegevenssets getest.</span><span class="sxs-lookup"><span data-stu-id="431ca-240">In the previous experiments we trained and tested the models using the same datasets.</span></span> <span data-ttu-id="431ca-241">Hier gebruiken we de [Split Data] [ split] module 2 subsets van de gegevens maken, op de eerste trainen en beoordelen en evalueren in het tweede.</span><span class="sxs-lookup"><span data-stu-id="431ca-241">Here, we will use the [Split Data][split] module to create 2 subsets of the data, train on the first, and score and evaluate on the second.</span></span> <span data-ttu-id="431ca-242">De gegevensset Iris openbaar beschikbaar is op de [UCI Machine Learning-opslagplaats](http://archive.ics.uci.edu/ml/index.html), en kan worden gedownload met behulp van een [importgegevens] [ import-data] module.</span><span class="sxs-lookup"><span data-stu-id="431ca-242">The Iris dataset is publicly available on the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html), and can be downloaded using an [Import Data][import-data] module.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="431ca-243">Het Experiment maken</span><span class="sxs-lookup"><span data-stu-id="431ca-243">Creating the Experiment</span></span>
<span data-ttu-id="431ca-244">De volgende modules toevoegen aan uw werkruimte in Azure Machine Learning Studio:</span><span class="sxs-lookup"><span data-stu-id="431ca-244">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="431ca-245">[Gegevens importeren][import-data]</span><span class="sxs-lookup"><span data-stu-id="431ca-245">[Import Data][import-data]</span></span>
* <span data-ttu-id="431ca-246">[Multiklasse besluit Forest][multiclass-decision-forest]</span><span class="sxs-lookup"><span data-stu-id="431ca-246">[Multiclass Decision Forest][multiclass-decision-forest]</span></span>
* <span data-ttu-id="431ca-247">[Gegevens splitsen][split]</span><span class="sxs-lookup"><span data-stu-id="431ca-247">[Split Data][split]</span></span>
* <span data-ttu-id="431ca-248">[Train Model][train-model]</span><span class="sxs-lookup"><span data-stu-id="431ca-248">[Train Model][train-model]</span></span>
* <span data-ttu-id="431ca-249">[Score-Model][score-model]</span><span class="sxs-lookup"><span data-stu-id="431ca-249">[Score Model][score-model]</span></span>
* <span data-ttu-id="431ca-250">[Model evalueren][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="431ca-250">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="431ca-251">Verbinding maken met de poorten zoals hieronder wordt weergegeven in afbeelding 10.</span><span class="sxs-lookup"><span data-stu-id="431ca-251">Connect the ports as shown below in Figure 10.</span></span>

<span data-ttu-id="431ca-252">Stel de kolomindex Label van de [Train Model] [ train-model] module tot 5.</span><span class="sxs-lookup"><span data-stu-id="431ca-252">Set the Label column index of the [Train Model][train-model] module to 5.</span></span> <span data-ttu-id="431ca-253">De gegevensset heeft geen veldnamenrij, maar we weten dat de klasse-labels in de vijfde kolom zijn.</span><span class="sxs-lookup"><span data-stu-id="431ca-253">The dataset has no header row but we know that the class labels are in the fifth column.</span></span>

<span data-ttu-id="431ca-254">Klik op de [gegevens importeren] [ import-data] module en stel de *gegevensbron* eigenschap *via HTTP-URL voor webinhoud*, en de *URL* naar http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span><span class="sxs-lookup"><span data-stu-id="431ca-254">Click on the [Import Data][import-data] module and set the *Data source* property to *Web URL via HTTP*, and the *URL* to http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span></span>

<span data-ttu-id="431ca-255">Stel de fractie van exemplaren moet worden gebruikt voor training in de [Split Data] [ split] module (0,7 bijvoorbeeld).</span><span class="sxs-lookup"><span data-stu-id="431ca-255">Set the fraction of instances to be used for training in the [Split Data][split] module (0.7 for example).</span></span>

![Evaluatie van een Multiklassen classificatie](media/machine-learning-evaluate-model-performance/10.png)

<span data-ttu-id="431ca-257">Afbeelding 10.</span><span class="sxs-lookup"><span data-stu-id="431ca-257">Figure 10.</span></span> <span data-ttu-id="431ca-258">Evaluatie van een Multiklassen classificatie</span><span class="sxs-lookup"><span data-stu-id="431ca-258">Evaluating a Multiclass Classifier</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="431ca-259">De resultaten van de evaluatie te bekijken</span><span class="sxs-lookup"><span data-stu-id="431ca-259">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="431ca-260">Voer het experiment uit en klik op de uitvoerpoort van [Evaluate Model][evaluate-model].</span><span class="sxs-lookup"><span data-stu-id="431ca-260">Run the experiment and click on the output port of [Evaluate Model][evaluate-model].</span></span> <span data-ttu-id="431ca-261">De evaluatieresultaten worden weergegeven in de vorm van een matrix verwarring in dit geval.</span><span class="sxs-lookup"><span data-stu-id="431ca-261">The evaluation results are presented in the form of a confusion matrix, in this case.</span></span> <span data-ttu-id="431ca-262">De matrix geeft de werkelijke waarden versus voorspelde exemplaren voor alle 3 klassen.</span><span class="sxs-lookup"><span data-stu-id="431ca-262">The matrix shows the actual vs. predicted instances for all 3 classes.</span></span>

![Resultaten van evaluatie van multiklassen classificatie](media/machine-learning-evaluate-model-performance/11.png)

<span data-ttu-id="431ca-264">Afbeelding 11.</span><span class="sxs-lookup"><span data-stu-id="431ca-264">Figure 11.</span></span> <span data-ttu-id="431ca-265">Resultaten van evaluatie van multiklassen classificatie.</span><span class="sxs-lookup"><span data-stu-id="431ca-265">Multiclass Classification Evaluation Results.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="431ca-266">Met behulp van Cross-validatie</span><span class="sxs-lookup"><span data-stu-id="431ca-266">Using Cross Validation</span></span>
<span data-ttu-id="431ca-267">Zoals eerder gezegd, kunt u uitvoeren herhaalde training, scores en evaluaties automatisch met de [gekruist te valideren Model] [ cross-validate-model] module.</span><span class="sxs-lookup"><span data-stu-id="431ca-267">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="431ca-268">U moet een gegevensset, een ongetrainde model en een [gekruist te valideren Model] [ cross-validate-model] module (Zie afbeelding hieronder).</span><span class="sxs-lookup"><span data-stu-id="431ca-268">You would need a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="431ca-269">U moet opnieuw instellen van de labelkolom van de [gekruist te valideren Model] [ cross-validate-model] module (kolomindex 5 in dit geval).</span><span class="sxs-lookup"><span data-stu-id="431ca-269">Again you need to set the label column of the [Cross-Validate Model][cross-validate-model] module (column index 5 in this case).</span></span> <span data-ttu-id="431ca-270">Nadat het experiment uitgevoerd en het recht te klikken op de uitvoerpoort van de [gekruist te valideren Model][cross-validate-model], kunt u de metrische waarden voor elke vouwen, evenals de afwijking van gemiddelde en standard controleren.</span><span class="sxs-lookup"><span data-stu-id="431ca-270">After running the experiment and clicking the right output port of the [Cross-Validate Model][cross-validate-model], you can inspect the metric values for each fold as well as the mean and standard deviation.</span></span> <span data-ttu-id="431ca-271">De metrische gegevens hier weergegeven zijn de vergelijkbaar met die in het geval van de binaire indeling besproken.</span><span class="sxs-lookup"><span data-stu-id="431ca-271">The metrics displayed here are the similar to the ones discussed in the binary classification case.</span></span> <span data-ttu-id="431ca-272">Let echter op dat in multiklassen classificatie computing de waar positieven/negatieve en fout-positieven/negatieve resultaten wordt gerealiseerd door tellen op basis van per-klasse als er geen klasse algemene positief of negatief is.</span><span class="sxs-lookup"><span data-stu-id="431ca-272">However, note that in multiclass classification, computing the true positives/negatives and false positives/negatives is done by counting on a per-class basis, as there is no overall positive or negative class.</span></span> <span data-ttu-id="431ca-273">Bijvoorbeeld bij het berekenen van de precisie of intrekken van de klasse 'Iris setosa', wordt ervan uitgegaan dat dit de positieve klasse en alle andere negatief is.</span><span class="sxs-lookup"><span data-stu-id="431ca-273">For example, when computing the precision or recall of the ‘Iris-setosa’ class, it is assumed that this is the positive class and all others as negative.</span></span>

![Een Model Multiklassen classificatie cross valideren](media/machine-learning-evaluate-model-performance/12.png)

<span data-ttu-id="431ca-275">Afbeelding 12.</span><span class="sxs-lookup"><span data-stu-id="431ca-275">Figure 12.</span></span> <span data-ttu-id="431ca-276">Een Model Multiklassen classificatie cross valideren.</span><span class="sxs-lookup"><span data-stu-id="431ca-276">Cross-Validating a Multiclass Classification Model.</span></span>

![Kruisvalidatieresultaten van een Model Multiklassen classificatie](media/machine-learning-evaluate-model-performance/13.png)

<span data-ttu-id="431ca-278">Afbeelding 13.</span><span class="sxs-lookup"><span data-stu-id="431ca-278">Figure 13.</span></span> <span data-ttu-id="431ca-279">De Kruisvalidatieresultaten van een Model Multiklassen classificatie.</span><span class="sxs-lookup"><span data-stu-id="431ca-279">Cross-Validation Results of a Multiclass Classification Model.</span></span>

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/

