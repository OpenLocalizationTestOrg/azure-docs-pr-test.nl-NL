---
title: aaaFeature selectie in Hallo Team gegevens wetenschap proces | Microsoft Docs
description: Hallo-doel van functieselectie worden en voorbeelden gegeven van hun rol in de procedure voor de verbetering van Hallo gegevens van machine learning.
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 878541f5-1df8-4368-889a-ced6852aba47
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/24/2017
ms.author: zhangya;bradsev
ms.openlocfilehash: 54af93c83e4cc6a3670b3ad62490e0f74082b4ee
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 10/06/2017
---
# <a name="feature-selection-in-hello-team-data-science-process-tdsp"></a><span data-ttu-id="b68b4-103">Functieselectie in Hallo Team gegevens wetenschap proces (TDSP)</span><span class="sxs-lookup"><span data-stu-id="b68b4-103">Feature selection in hello Team Data Science Process (TDSP)</span></span>
<span data-ttu-id="b68b4-104">In dit artikel wordt uitgelegd Hallo doeleinden van functieselectie en vindt u voorbeelden van de rol in de procedure voor de verbetering van Hallo gegevens van machine learning.</span><span class="sxs-lookup"><span data-stu-id="b68b4-104">This article explains hello purposes of feature selection and provides examples of its role in hello data enhancement process of machine learning.</span></span> <span data-ttu-id="b68b4-105">Deze voorbeelden zijn afkomstig van Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="b68b4-105">These examples are drawn from Azure Machine Learning Studio.</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="b68b4-106">Hallo engineering en selectie van functies is een onderdeel van Hallo Team gegevens wetenschap proces (TDSP) die worden beschreven in [wat is er Hallo Team gegevens wetenschap proces?](data-science-process-overview.md).</span><span class="sxs-lookup"><span data-stu-id="b68b4-106">hello engineering and selection of features is one part of hello Team Data Science Process (TDSP) outlined in [What is hello Team Data Science Process?](data-science-process-overview.md).</span></span> <span data-ttu-id="b68b4-107">Selectie van functie-engineering en zijn onderdelen van Hallo **functies ontwikkelen** stap Hallo TDSP.</span><span class="sxs-lookup"><span data-stu-id="b68b4-107">Feature engineering and selection are parts of hello **Develop features** step of hello TDSP.</span></span>

* <span data-ttu-id="b68b4-108">**functie-engineering**: dit proces probeert toocreate extra relevante functies van bestaande onbewerkte functies Hallo Hallo gegevens en tooincrease predictive vermogen toohello learning-algoritme.</span><span class="sxs-lookup"><span data-stu-id="b68b4-108">**feature engineering**: This process attempts toocreate additional relevant features from hello existing raw features in hello data, and tooincrease predictive power toohello learning algorithm.</span></span>
* <span data-ttu-id="b68b4-109">**functie selectie**: dit proces Hallo sleutel subset van functies van de oorspronkelijke gegevens in een poging tooreduce Hallo dimensionaliteit van Hallo training probleem selecteren.</span><span class="sxs-lookup"><span data-stu-id="b68b4-109">**feature selection**: This process selects hello key subset of original data features in an attempt tooreduce hello dimensionality of hello training problem.</span></span>

<span data-ttu-id="b68b4-110">Normaal gesproken **functie-engineering** is toegepaste eerste toogenerate extra functies en Hallo **functie selectie** stap is uitgevoerd tooeliminate irrelevante, redundante of maximaal gecorreleerde functies.</span><span class="sxs-lookup"><span data-stu-id="b68b4-110">Normally **feature engineering** is applied first toogenerate additional features, and then hello **feature selection** step is performed tooeliminate irrelevant, redundant, or highly correlated features.</span></span>

## <a name="filtering-features-from-your-data---feature-selection"></a><span data-ttu-id="b68b4-111">Filteren van de functies van uw gegevens - Functieselectie</span><span class="sxs-lookup"><span data-stu-id="b68b4-111">Filtering Features from Your Data - Feature Selection</span></span>
<span data-ttu-id="b68b4-112">Functieselectie is een proces dat vaak voor Hallo constructie van training gegevenssets voor voorspellende modelleertaken zoals classificatie- of regressiemodel taken wordt toegepast.</span><span class="sxs-lookup"><span data-stu-id="b68b4-112">Feature selection is a process that is commonly applied for hello construction of training datasets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="b68b4-113">Hallo-doel is een subset van Hallo-functies uit de oorspronkelijke gegevensset Hallo die de afmetingen verminderen met behulp van een minimale set functies toorepresent Hallo maximale hoeveelheid variantie in Hallo gegevens tooselect.</span><span class="sxs-lookup"><span data-stu-id="b68b4-113">hello goal is tooselect a subset of hello features from hello original dataset that reduce its dimensions by using a minimal set of features toorepresent hello maximum amount of variance in hello data.</span></span> <span data-ttu-id="b68b4-114">Deze subset van functies worden vervolgens Hallo alleen functies toobe tootrain Hallo model opgenomen.</span><span class="sxs-lookup"><span data-stu-id="b68b4-114">This subset of features are, then, hello only features toobe included tootrain hello model.</span></span> <span data-ttu-id="b68b4-115">Functieselectie fungeert twee hoofddoelen.</span><span class="sxs-lookup"><span data-stu-id="b68b4-115">Feature selection serves two main purposes.</span></span>

* <span data-ttu-id="b68b4-116">Eerst Functieselectie vaak verhoogt de nauwkeurigheid van de classificatie doordat irrelevante, redundante of maximaal gecorreleerde functies.</span><span class="sxs-lookup"><span data-stu-id="b68b4-116">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="b68b4-117">Ten tweede neemt Hallo aantal functies waardoor model trainingsproces efficiënter af.</span><span class="sxs-lookup"><span data-stu-id="b68b4-117">Second, it decreases hello number of features which makes model training process more efficient.</span></span> <span data-ttu-id="b68b4-118">Dit is vooral belangrijk voor overbrengen die dure tootrain zoals ondersteuning vector machines zijn.</span><span class="sxs-lookup"><span data-stu-id="b68b4-118">This is particularly important for learners that are expensive tootrain such as support vector machines.</span></span>

<span data-ttu-id="b68b4-119">Hoewel Functieselectie tooreduce Hallo aantal functies in Hallo gegevensset gebruikt tootrain Hallo model zoeken, is het niet meestal waarnaar wordt verwezen tooby Hallo term 'dimensionaliteit vermindering'.</span><span class="sxs-lookup"><span data-stu-id="b68b4-119">Although feature selection does seek tooreduce hello number of features in hello dataset used tootrain hello model, it is not usually referred tooby hello term "dimensionality reduction".</span></span> <span data-ttu-id="b68b4-120">Functie selectiemethodes extraheren een subset van de oorspronkelijke functies in Hallo gegevens niet wijzigen.</span><span class="sxs-lookup"><span data-stu-id="b68b4-120">Feature selection methods extract a subset of original features in hello data without changing them.</span></span>  <span data-ttu-id="b68b4-121">Dimensionaliteit vermindering methoden gebruiken engineering functies die u kunnen de oorspronkelijke functies Hallo transformeren en ze zo te wijzigen.</span><span class="sxs-lookup"><span data-stu-id="b68b4-121">Dimensionality reduction methods employ engineered features that can transform hello original features and thus modify them.</span></span> <span data-ttu-id="b68b4-122">Voorbeelden van dimensionaliteit vermindering methoden zijn Principal onderdeel analyse, canonieke correlatieanalyse en enkelvoud waarde afbreken.</span><span class="sxs-lookup"><span data-stu-id="b68b4-122">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</span></span>

<span data-ttu-id="b68b4-123">Onder andere wordt één breed worden toegepast categorie van functie selectiemethoden in een context die onder supervisie 'filteren op basis van functieselectie' genoemd.</span><span class="sxs-lookup"><span data-stu-id="b68b4-123">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</span></span> <span data-ttu-id="b68b4-124">Deze methoden toepassen door te evalueren Hallo correlatie tussen elke functie en Hallo target-kenmerk, een statistische meting tooassign een score tooeach-functie.</span><span class="sxs-lookup"><span data-stu-id="b68b4-124">By evaluating hello correlation between each feature and hello target attribute, these methods apply a statistical measure tooassign a score tooeach feature.</span></span> <span data-ttu-id="b68b4-125">Hallo-functies zijn vervolgens gerangschikt op Hallo score, die mogelijk gebruikte toohelp ingestelde Hallo drempelwaarde voor behouden of een specifieke functie geëlimineerd.</span><span class="sxs-lookup"><span data-stu-id="b68b4-125">hello features are then ranked by hello score, which may be used toohelp set hello threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="b68b4-126">Voorbeelden van Hallo statistische metingen die worden gebruikt in deze methoden zijn persoon correlatie, wederzijdse informatie en test Hallo Chi-kwadraat.</span><span class="sxs-lookup"><span data-stu-id="b68b4-126">Examples of hello statistical measures used in these methods include Person correlation, mutual information, and hello Chi squared test.</span></span>

<span data-ttu-id="b68b4-127">In Azure Machine Learning Studio zijn er modules die zijn opgegeven voor de Functieselectie van de.</span><span class="sxs-lookup"><span data-stu-id="b68b4-127">In Azure Machine Learning Studio, there are modules provided for feature selection.</span></span> <span data-ttu-id="b68b4-128">Zoals u in de volgende afbeelding Hallo, deze modules bevatten [Functieselectie op basis van het Filter] [ filter-based-feature-selection] en [Fisher lineaire Discriminant analyse] [ fisher-linear-discriminant-analysis].</span><span class="sxs-lookup"><span data-stu-id="b68b4-128">As shown in hello following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![Voorbeeld van de functie-selectie](./media/machine-learning-data-science-select-features/feature-Selection.png)

<span data-ttu-id="b68b4-130">U kunt bijvoorbeeld Hallo Hallo [Functieselectie op basis van het Filter] [ filter-based-feature-selection] module.</span><span class="sxs-lookup"><span data-stu-id="b68b4-130">Consider, for example, hello use of hello [Filter-Based Feature Selection][filter-based-feature-selection] module.</span></span> <span data-ttu-id="b68b4-131">Hallo doel gemak gaan we toouse Hallo analysemodel tekstvoorbeeld die hierboven worden beschreven.</span><span class="sxs-lookup"><span data-stu-id="b68b4-131">For hello purpose of convenience, we continue toouse hello text mining example outlined above.</span></span> <span data-ttu-id="b68b4-132">Wordt ervan uitgegaan dat willen we een regressiemodel nadat een set van 256 functies worden gemaakt via Hallo toobuild [hash-functie] [ feature-hashing] module en die Hallo antwoord variabele Hallo 'Col1' en een boek vertegenwoordigt bekijken beoordelingen variëren van 1 too5.</span><span class="sxs-lookup"><span data-stu-id="b68b4-132">Assume that we want toobuild a regression model after a set of 256 features are created through hello [Feature Hashing][feature-hashing] module, and that hello response variable is hello "Col1" and represents a book review ratings ranging from 1 too5.</span></span> <span data-ttu-id="b68b4-133">Hiervoor 'Functie score berekenen methode' toobe 'Pearson correlatie' Hallo 'Doelkolom' toobe 'Col1' en Hallo 'Het aantal gewenste functies' too50.</span><span class="sxs-lookup"><span data-stu-id="b68b4-133">By setting "Feature scoring method" toobe "Pearson Correlation", hello "Target column" toobe "Col1", and hello "Number of desired features" too50.</span></span> <span data-ttu-id="b68b4-134">Vervolgens Hallo module [Functieselectie op basis van het Filter] [ filter-based-feature-selection] waarmee een gegevensset met 50 functies samen met het doelkenmerk Hallo 'Col1' wordt geproduceerd.</span><span class="sxs-lookup"><span data-stu-id="b68b4-134">Then hello module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with hello target attribute "Col1".</span></span> <span data-ttu-id="b68b4-135">Hallo volgende afbeelding toont Hallo stroom van dit experiment en Hallo invoerparameters die hierboven wordt beschreven.</span><span class="sxs-lookup"><span data-stu-id="b68b4-135">hello following figure shows hello flow of this experiment and hello input parameters we just described.</span></span>

![Voorbeeld van de functie-selectie](./media/machine-learning-data-science-select-features/feature-Selection1.png)

<span data-ttu-id="b68b4-137">Hallo toont volgende afbeelding Hallo resulterende gegevenssets.</span><span class="sxs-lookup"><span data-stu-id="b68b4-137">hello following figure shows hello resulting datasets.</span></span> <span data-ttu-id="b68b4-138">Elke functie wordt berekend op basis van Hallo Pearson correlatie tussen zichzelf en target-kenmerk 'Col1' Hallo.</span><span class="sxs-lookup"><span data-stu-id="b68b4-138">Each feature is scored based on hello Pearson Correlation between itself and hello target attribute "Col1".</span></span> <span data-ttu-id="b68b4-139">Hallo-functies met de hoogste scores worden bewaard.</span><span class="sxs-lookup"><span data-stu-id="b68b4-139">hello features with top scores are kept.</span></span>

![Voorbeeld van de functie-selectie](./media/machine-learning-data-science-select-features/feature-Selection2.png)

<span data-ttu-id="b68b4-141">Hallo bijbehorende scores van functies Hallo geselecteerd worden weergegeven in Hallo volgende afbeelding.</span><span class="sxs-lookup"><span data-stu-id="b68b4-141">hello corresponding scores of hello selected features are shown in hello following figure.</span></span>

![Voorbeeld van de functie-selectie](./media/machine-learning-data-science-select-features/feature-Selection3.png)

<span data-ttu-id="b68b4-143">Door het toepassen van dit [Functieselectie op basis van het Filter] [ filter-based-feature-selection] 50 van 256 functies worden geselecteerd omdat ze hebben meest gecorreleerde functies met doelvariabele Hallo 'Col1' Hallo-module op basis van het Hallo score berekenen methode 'Pearson correlatie'.</span><span class="sxs-lookup"><span data-stu-id="b68b4-143">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have hello most correlated features with hello target variable "Col1", based on hello scoring method "Pearson Correlation".</span></span>

## <a name="conclusion"></a><span data-ttu-id="b68b4-144">Conclusie</span><span class="sxs-lookup"><span data-stu-id="b68b4-144">Conclusion</span></span>
<span data-ttu-id="b68b4-145">Functie-engineering en Functieselectie zijn twee meestal ontworpen en geselecteerde onderdelen efficiënter Hallo Hallo dat tooextract Hallo belangrijke informatie in Hallo gegevens probeert te trainen.</span><span class="sxs-lookup"><span data-stu-id="b68b4-145">Feature engineering and feature selection are two commonly Engineered and selected features increase hello efficiency of hello training process which attempts tooextract hello key information contained in hello data.</span></span> <span data-ttu-id="b68b4-146">Bovendien de Hallo kracht van deze modellen tooclassify Hallo ingevoerde gegevens correct en toopredict resultaten van belang meer krachtig.</span><span class="sxs-lookup"><span data-stu-id="b68b4-146">They also improve hello power of these models tooclassify hello input data accurately and toopredict outcomes of interest more robustly.</span></span> <span data-ttu-id="b68b4-147">Selectie van functie-engineering en kunnen u ook toomake Hallo learning meer rekenkundig tractable combineren.</span><span class="sxs-lookup"><span data-stu-id="b68b4-147">Feature engineering and selection can also combine toomake hello learning more computationally tractable.</span></span> <span data-ttu-id="b68b4-148">Dit gebeurt met verbeteren en vervolgens terug te brengen Hallo aantal functies nodig toocalibrate of trein een model.</span><span class="sxs-lookup"><span data-stu-id="b68b4-148">It does so by enhancing and then reducing hello number of features needed toocalibrate or train a model.</span></span> <span data-ttu-id="b68b4-149">Wiskundig spreken Hallo functies geselecteerde tootrain Hallo model zijn een minimale set van onafhankelijke variabelen die Hallo patronen in Hallo gegevens leggen en vervolgens de resultaten met succes voorspellen.</span><span class="sxs-lookup"><span data-stu-id="b68b4-149">Mathematically speaking, hello features selected tootrain hello model are a minimal set of independent variables that explain hello patterns in hello data and then predict outcomes successfully.</span></span>

<span data-ttu-id="b68b4-150">Houd er rekening mee dat het is niet altijd noodzakelijkerwijs tooperform techniek of functie Functieselectie.</span><span class="sxs-lookup"><span data-stu-id="b68b4-150">Note that it is not always necessarily tooperform feature engineering or feature selection.</span></span> <span data-ttu-id="b68b4-151">Hiermee wordt aangegeven of het nodig is of niet, is afhankelijk van Hallo gegevens we hebben of verzamelen, Hallo algoritme die we kiest, en Hallo doelstelling van Hallo experiment.</span><span class="sxs-lookup"><span data-stu-id="b68b4-151">Whether it is needed or not depends on hello data we have or collect, hello algorithm we pick, and hello objective of hello experiment.</span></span>

<!-- Module References -->
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/

