---
title: 'Handleiding voor de per saldo # Neural Networks specificatietaal | Microsoft Docs'
description: 'De syntaxis voor de per saldo # neural networks specificatietaal, samen met enkele voorbeelden van een aangepaste neurale netwerk wordt getraind model maken in Microsoft Azure ML met Net #'
services: machine-learning
documentationcenter: 
author: jeannt
manager: jhubbard
editor: cgronlun
ms.assetid: cfd1454b-47df-4745-b064-ce5f9b3be303
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/31/2017
ms.author: jeannt
ms.openlocfilehash: 965c60ffde55041cc3864d06d81f5590c7ea1c11
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 07/11/2017
---
# <a name="guide-to-net-neural-network-specification-language-for-azure-machine-learning"></a><span data-ttu-id="2e71e-103">Handleiding voor de taal Net #-neural network-specificatie voor Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="2e71e-103">Guide to Net# neural network specification language for Azure Machine Learning</span></span>
## <a name="overview"></a><span data-ttu-id="2e71e-104">Overzicht</span><span class="sxs-lookup"><span data-stu-id="2e71e-104">Overview</span></span>
<span data-ttu-id="2e71e-105">NET # is een taal die is ontwikkeld door Microsoft die wordt gebruikt voor het definiëren van neural network-architecturen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-105">Net# is a language developed by Microsoft that is used to define neural network architectures.</span></span> <span data-ttu-id="2e71e-106">U kunt Net # in neural network-modules in Microsoft Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="2e71e-106">You can use Net# in neural network modules in Microsoft Azure Machine Learning.</span></span>

<!-- This function doesn't currentlyappear in the MicrosoftML documentation. If it is added in a future update, we can uncomment this text.

, or in the `rxNeuralNetwork()` function in [MicrosoftML](https://msdn.microsoft.com/microsoft-r/microsoftml/microsoftml). 

-->

<span data-ttu-id="2e71e-107">In dit artikel leert u basisconcepten die nodig zijn voor het ontwikkelen van een aangepaste neurale netwerk:</span><span class="sxs-lookup"><span data-stu-id="2e71e-107">In this article, you will learn basic concepts needed to develop a custom neural network:</span></span> 

* <span data-ttu-id="2e71e-108">Neural netwerkvereisten en het definiëren van de primaire onderdelen</span><span class="sxs-lookup"><span data-stu-id="2e71e-108">Neural network requirements and how to define the primary components</span></span>
* <span data-ttu-id="2e71e-109">De syntaxis en trefwoorden van de taal Net #-specificatie</span><span class="sxs-lookup"><span data-stu-id="2e71e-109">The syntax and keywords of the Net# specification language</span></span>
* <span data-ttu-id="2e71e-110">Voorbeelden van aangepaste neural netwerken die zijn gemaakt met Net #</span><span class="sxs-lookup"><span data-stu-id="2e71e-110">Examples of custom neural networks created using Net#</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

## <a name="neural-network-basics"></a><span data-ttu-id="2e71e-111">Basisprincipes van neurale netwerk</span><span class="sxs-lookup"><span data-stu-id="2e71e-111">Neural network basics</span></span>
<span data-ttu-id="2e71e-112">Een structuur neurale netwerk bestaat uit ***knooppunten*** die zijn ingedeeld in ***lagen***, en de gewogen ***verbindingen*** (of ***randen***) tussen de knooppunten.</span><span class="sxs-lookup"><span data-stu-id="2e71e-112">A neural network structure consists of ***nodes*** that are organized in ***layers***, and weighted ***connections*** (or ***edges***) between the nodes.</span></span> <span data-ttu-id="2e71e-113">De verbindingen zijn gericht en elke verbinding heeft een ***bron*** knooppunt en een ***bestemming*** knooppunt.</span><span class="sxs-lookup"><span data-stu-id="2e71e-113">The connections are directional, and each connection has a ***source*** node and a ***destination*** node.</span></span>  

<span data-ttu-id="2e71e-114">Elke ***trainable laag*** (een verborgen of een laag uitvoer) heeft een of meer ***verbinding bundels***.</span><span class="sxs-lookup"><span data-stu-id="2e71e-114">Each ***trainable layer*** (a hidden or an output layer) has one or more ***connection bundles***.</span></span> <span data-ttu-id="2e71e-115">Een bundel verbinding bestaat uit een bronlaag en een specificatie voor de verbindingen van die bronlaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-115">A connection bundle consists of a source layer and a specification of the connections from that source layer.</span></span> <span data-ttu-id="2e71e-116">De verbindingen in een bepaalde bundel delen dezelfde ***bronlaag*** en dezelfde ***bestemming laag***.</span><span class="sxs-lookup"><span data-stu-id="2e71e-116">All the connections in a given bundle share the same ***source layer*** and the same ***destination layer***.</span></span> <span data-ttu-id="2e71e-117">In Net #, wordt beschouwd als een bundel verbinding als onderdeel van de bundel bestemming laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-117">In Net#, a connection bundle is considered as belonging to the bundle's destination layer.</span></span>  

<span data-ttu-id="2e71e-118">NET # ondersteunt verschillende soorten verbinding pakketten, kunt u de invoer manier aanpassen zijn toegewezen aan verborgen lagen en toegewezen aan de uitvoer.</span><span class="sxs-lookup"><span data-stu-id="2e71e-118">Net# supports various kinds of connection bundles, which lets you customize the way inputs are mapped to hidden layers and mapped to the outputs.</span></span>   

<span data-ttu-id="2e71e-119">De standaard- of standard-bundel is een **volledige bundel**, in die op elk knooppunt in de bronlaag is verbonden met elk knooppunt in de doellaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-119">The default or standard bundle is a **full bundle**, in which each node in the source layer is connected to every node in the destination layer.</span></span>  

<span data-ttu-id="2e71e-120">Daarnaast ondersteunt Net # de volgende vier typen bundels geavanceerde verbinding:</span><span class="sxs-lookup"><span data-stu-id="2e71e-120">Additionally, Net# supports the following four kinds of advanced connection bundles:</span></span>  

* <span data-ttu-id="2e71e-121">**Gefilterd bundels**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-121">**Filtered bundles**.</span></span> <span data-ttu-id="2e71e-122">De gebruiker kan een predikaat definiëren met behulp van de locaties van het bronknooppunt laag en het doelknooppunt voor de laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-122">The user can define a predicate by using the locations of the source layer node and the destination layer node.</span></span> <span data-ttu-id="2e71e-123">Knooppunten zijn verbonden wanneer het predikaat waar is.</span><span class="sxs-lookup"><span data-stu-id="2e71e-123">Nodes are connected whenever the predicate is True.</span></span>
* <span data-ttu-id="2e71e-124">**Convolutional bundels**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-124">**Convolutional bundles**.</span></span> <span data-ttu-id="2e71e-125">De gebruiker kunt kleine groepen van knooppunten definiëren in de bronlaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-125">The user can define small neighborhoods of nodes in the source layer.</span></span> <span data-ttu-id="2e71e-126">Elk knooppunt in de doellaag is verbonden met één groep van knooppunten in de bronlaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-126">Each node in the destination layer is connected to one neighborhood of nodes in the source layer.</span></span>
* <span data-ttu-id="2e71e-127">**Groeperen van bundels** en **antwoord normalisatie bundels**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-127">**Pooling bundles** and **Response normalization bundles**.</span></span> <span data-ttu-id="2e71e-128">Dit zijn vergelijkbaar met convolutional bundels in dat de gebruiker gedefinieerd kleine groepen van knooppunten in de bronlaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-128">These are similar to convolutional bundles in that the user defines small neighborhoods of nodes in the source layer.</span></span> <span data-ttu-id="2e71e-129">Het verschil is dat het gewicht van de randen in deze pakketten niet trainable zijn.</span><span class="sxs-lookup"><span data-stu-id="2e71e-129">The difference is that the weights of the edges in these bundles are not trainable.</span></span> <span data-ttu-id="2e71e-130">In plaats daarvan wordt een vooraf gedefinieerde functie toegepast op de waarden van het knooppunt bron om te bepalen van de waarde van de doel-knooppunt.</span><span class="sxs-lookup"><span data-stu-id="2e71e-130">Instead, a predefined function is applied to the source node values to determine the destination node value.</span></span>  

<span data-ttu-id="2e71e-131">Net # definiëren met de structuur van een neural netwerk, maakt het mogelijk voor het definiëren van complexe structuren zoals diep neural networks of convoluties van willekeurige dimensies, waarvan bekend is dat het leren op gegevens, zoals afbeelding, audio of video verbeteren.</span><span class="sxs-lookup"><span data-stu-id="2e71e-131">Using Net# to define the structure of a neural network makes it possible to define complex structures such as deep neural networks or convolutions of arbitrary dimensions, which are known to improve learning on data such as image, audio, or video.</span></span>  

## <a name="supported-customizations"></a><span data-ttu-id="2e71e-132">Ondersteunde aanpassingen</span><span class="sxs-lookup"><span data-stu-id="2e71e-132">Supported customizations</span></span>
<span data-ttu-id="2e71e-133">De architectuur van neural network-modellen die u in Azure Machine Learning maakt kan grote schaal worden aangepast via Net #.</span><span class="sxs-lookup"><span data-stu-id="2e71e-133">The architecture of neural network models that you create in Azure Machine Learning can be extensively customized by using Net#.</span></span> <span data-ttu-id="2e71e-134">U kunt:</span><span class="sxs-lookup"><span data-stu-id="2e71e-134">You can:</span></span>  

* <span data-ttu-id="2e71e-135">Verborgen lagen maken en beheren van het aantal knooppunten in elke laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-135">Create hidden layers and control the number of nodes in each layer.</span></span>
* <span data-ttu-id="2e71e-136">Opgeven hoe lagen moeten met elkaar worden verbonden.</span><span class="sxs-lookup"><span data-stu-id="2e71e-136">Specify how layers are to be connected to each other.</span></span>
* <span data-ttu-id="2e71e-137">Speciale connectiviteit structuren, zoals convoluties en gewicht delen bundels definiëren.</span><span class="sxs-lookup"><span data-stu-id="2e71e-137">Define special connectivity structures, such as convolutions and weight sharing bundles.</span></span>
* <span data-ttu-id="2e71e-138">Geef de activering van andere functies.</span><span class="sxs-lookup"><span data-stu-id="2e71e-138">Specify different activation functions.</span></span>  

<span data-ttu-id="2e71e-139">Zie voor meer informatie van de syntaxis van de specificatie [structuur specificatie](#Structure-specifications).</span><span class="sxs-lookup"><span data-stu-id="2e71e-139">For details of the specification language syntax, see [Structure Specification](#Structure-specifications).</span></span>  

<span data-ttu-id="2e71e-140">Zie voor voorbeelden van het definiëren van neural networks voor een aantal veelvoorkomende machine learning-taken uit Simplex () naar complexe [voorbeelden](#Examples-of-Net#-usage).</span><span class="sxs-lookup"><span data-stu-id="2e71e-140">For examples of defining neural networks for some common machine learning tasks, from simplex to complex, see [Examples](#Examples-of-Net#-usage).</span></span>  

## <a name="general-requirements"></a><span data-ttu-id="2e71e-141">Algemene vereisten</span><span class="sxs-lookup"><span data-stu-id="2e71e-141">General requirements</span></span>
* <span data-ttu-id="2e71e-142">Moet er precies één uitvoer laag, ten minste één invoer-laag en nul of meer verborgen lagen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-142">There must be exactly one output layer, at least one input layer, and zero or more hidden layers.</span></span> 
* <span data-ttu-id="2e71e-143">Elke laag heeft een vast aantal knooppunten, conceptueel gerangschikt in een rechthoekige matrix met willekeurige dimensies.</span><span class="sxs-lookup"><span data-stu-id="2e71e-143">Each layer has a fixed number of nodes, conceptually arranged in a rectangular array of arbitrary dimensions.</span></span> 
* <span data-ttu-id="2e71e-144">Invoer lagen geen bijbehorende getraind parameters hebben en het punt waar de gegevens van het netwerk krijgt vertegenwoordigen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-144">Input layers have no associated trained parameters and represent the point where instance data enters the network.</span></span> 
* <span data-ttu-id="2e71e-145">Trainable lagen (de lagen verborgen en uitvoer) gekoppelde hebben getraind parameters, gewicht en vooroordelen genoemd.</span><span class="sxs-lookup"><span data-stu-id="2e71e-145">Trainable layers (the hidden and output layers) have associated trained parameters, known as weights and biases.</span></span> 
* <span data-ttu-id="2e71e-146">De bron- en doelserver knooppunten moeten zich in verschillende lagen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-146">The source and destination nodes must be in separate layers.</span></span> 
* <span data-ttu-id="2e71e-147">Verbindingen moet acyclische; Er kan niet met andere woorden, een keten van toonaangevende terug naar het eerste bronknooppunt verbindingen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-147">Connections must be acyclic; in other words, there cannot be a chain of connections leading back to the initial source node.</span></span>
* <span data-ttu-id="2e71e-148">De uitvoer-laag kan niet een bronlaag van een bundel verbinding.</span><span class="sxs-lookup"><span data-stu-id="2e71e-148">The output layer cannot be a source layer of a connection bundle.</span></span>  

## <a name="structure-specifications"></a><span data-ttu-id="2e71e-149">Structuur specificaties</span><span class="sxs-lookup"><span data-stu-id="2e71e-149">Structure specifications</span></span>
<span data-ttu-id="2e71e-150">Een structure-specificatie van het neurale netwerk bestaat uit drie delen: de **constantendeclaratie**, wordt de **laag-declaratie**, wordt de **verbinding declaratie**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-150">A neural network structure specification is composed of three sections: the **constant declaration**, the **layer declaration**, the **connection declaration**.</span></span> <span data-ttu-id="2e71e-151">Er is ook een optionele **delen declaratie** sectie.</span><span class="sxs-lookup"><span data-stu-id="2e71e-151">There is also an optional **share declaration** section.</span></span> <span data-ttu-id="2e71e-152">De secties kunnen in elke volgorde worden opgegeven.</span><span class="sxs-lookup"><span data-stu-id="2e71e-152">The sections can be specified in any order.</span></span>  

## <a name="constant-declaration"></a><span data-ttu-id="2e71e-153">Constantendeclaratie</span><span class="sxs-lookup"><span data-stu-id="2e71e-153">Constant declaration</span></span>
<span data-ttu-id="2e71e-154">Een constantendeclaratie is optioneel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-154">A constant declaration is optional.</span></span> <span data-ttu-id="2e71e-155">Het biedt een manier voor het definiëren van waarden elders in de definitie van het neurale netwerk wordt gebruikt.</span><span class="sxs-lookup"><span data-stu-id="2e71e-155">It provides a means to define values used elsewhere in the neural network definition.</span></span> <span data-ttu-id="2e71e-156">De declaratie-instructie bestaat uit een id die wordt gevolgd door een gelijkteken en een waardenexpressie.</span><span class="sxs-lookup"><span data-stu-id="2e71e-156">The declaration statement consists of an identifier followed by an equal sign and a value expression.</span></span>   

<span data-ttu-id="2e71e-157">De volgende instructie definieert u bijvoorbeeld een constante **x**:</span><span class="sxs-lookup"><span data-stu-id="2e71e-157">For example, the following statement defines a constant **x**:</span></span>  

    Const X = 28;  

<span data-ttu-id="2e71e-158">Als u twee of meer constanten tegelijkertijd definieert, moet u de id-namen en waarden tussen vierkante haakjes en gescheiden door puntkomma's.</span><span class="sxs-lookup"><span data-stu-id="2e71e-158">To define two or more constants simultaneously, enclose the identifier names and values in braces, and separate them by using semicolons.</span></span> <span data-ttu-id="2e71e-159">Bijvoorbeeld:</span><span class="sxs-lookup"><span data-stu-id="2e71e-159">For example:</span></span>  

    Const { X = 28; Y = 4; }  

<span data-ttu-id="2e71e-160">De rechterkant van de toewijzingsexpressie voor elke kan een geheel getal, een reëel getal, een Booleaanse waarde (True of False) of een rekenkundige expressie zijn.</span><span class="sxs-lookup"><span data-stu-id="2e71e-160">The right-hand side of each assignment expression can be an integer, a real number, a Boolean value (True or False), or a mathematical expression.</span></span> <span data-ttu-id="2e71e-161">Bijvoorbeeld:</span><span class="sxs-lookup"><span data-stu-id="2e71e-161">For example:</span></span>  

    Const { X = 17 * 2; Y = true; }  

## <a name="layer-declaration"></a><span data-ttu-id="2e71e-162">Laag-declaratie</span><span class="sxs-lookup"><span data-stu-id="2e71e-162">Layer declaration</span></span>
<span data-ttu-id="2e71e-163">De declaratie laag is vereist.</span><span class="sxs-lookup"><span data-stu-id="2e71e-163">The layer declaration is required.</span></span> <span data-ttu-id="2e71e-164">Het definieert de grootte en de bron van de laag, met inbegrip van de verbinding bundels en kenmerken.</span><span class="sxs-lookup"><span data-stu-id="2e71e-164">It defines the size and source of the layer, including its connection bundles and attributes.</span></span> <span data-ttu-id="2e71e-165">De declaratie-instructie begint met de naam van de laag (invoer, verborgen of uitvoer), gevolgd door de afmetingen van de laag (een tuple van positieve gehele getallen).</span><span class="sxs-lookup"><span data-stu-id="2e71e-165">The declaration statement starts with the name of the layer (input, hidden, or output), followed by the dimensions of the layer (a tuple of positive integers).</span></span> <span data-ttu-id="2e71e-166">Bijvoorbeeld:</span><span class="sxs-lookup"><span data-stu-id="2e71e-166">For example:</span></span>  

    input Data auto;
    hidden Hidden[5,20] from Data all;
    output Result[2] from Hidden all;  

* <span data-ttu-id="2e71e-167">Het product van de dimensies is het aantal knooppunten in de laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-167">The product of the dimensions is the number of nodes in the layer.</span></span> <span data-ttu-id="2e71e-168">In dit voorbeeld zijn er twee dimensies [5,20], wat betekent dat er 100 knooppunten zijn in de laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-168">In this example, there are two dimensions [5,20], which means there are  100 nodes in the layer.</span></span>
* <span data-ttu-id="2e71e-169">De lagen kunnen worden gedeclareerd in willekeurige volgorde, met één uitzondering: de volgorde waarin ze zijn gedeclareerd als meer dan één invoer laag is gedefinieerd, moet overeenkomen met de volgorde van de functies in de invoergegevens.</span><span class="sxs-lookup"><span data-stu-id="2e71e-169">The layers can be declared in any order, with one exception: If more than one input layer is defined, the order in which they are declared must match the order of features in the input data.</span></span>  

<span data-ttu-id="2e71e-170">Als u wilt opgeven dat het aantal knooppunten in een laag automatisch worden vastgesteld, gebruikt u de **automatisch** sleutelwoord.</span><span class="sxs-lookup"><span data-stu-id="2e71e-170">To specify that the number of nodes in a layer be determined automatically, use the **auto** keyword.</span></span> <span data-ttu-id="2e71e-171">De **automatisch** sleutelwoord heeft verschillende effecten, afhankelijk van de laag:</span><span class="sxs-lookup"><span data-stu-id="2e71e-171">The **auto** keyword has different effects, depending on the layer:</span></span>  

* <span data-ttu-id="2e71e-172">In een declaratie invoer laag is het aantal knooppunten in het aantal functies in de invoergegevens.</span><span class="sxs-lookup"><span data-stu-id="2e71e-172">In an input layer declaration, the number of nodes is the number of features in the input data.</span></span>
* <span data-ttu-id="2e71e-173">In de declaratie van een verborgen laag, het aantal knooppunten is het aantal dat is opgegeven door de waarde van parameter voor **aantal knooppunten dat verborgen**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-173">In a hidden layer declaration, the number of nodes is the number that is specified by the parameter value for **Number of hidden nodes**.</span></span> 
* <span data-ttu-id="2e71e-174">Het aantal knooppunten is in de declaratie van een uitvoer-laag 2 voor tweeklasse classificatie, 1 voor regressie en gelijk is aan het aantal uitvoerknooppunten voor multiklassen classificatie.</span><span class="sxs-lookup"><span data-stu-id="2e71e-174">In an output layer declaration, the number of nodes is 2 for two-class classification, 1 for regression, and equal to the number of output nodes for multiclass classification.</span></span>   

<span data-ttu-id="2e71e-175">De volgende netwerkdefinitie kan bijvoorbeeld de grootte van alle lagen automatisch bepaald:</span><span class="sxs-lookup"><span data-stu-id="2e71e-175">For example, the following network definition allows the size of all layers to be automatically determined:</span></span>  

    input Data auto;
    hidden Hidden auto from Data all;
    output Result auto from Hidden all;  


<span data-ttu-id="2e71e-176">De declaratie van een laag voor een trainable laag (de lagen verborgen of uitvoer) kunt u eventueel de uitvoer functie (ook wel een functie voor activering genoemd), die een standaardwaarde opnemen **sigmoid** voor classificatie-modellen en  **lineaire** voor regressie-modellen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-176">A layer declaration for a trainable layer (the hidden or output layers) can optionally include the output function (also called an activation function), which defaults to **sigmoid** for classification models, and **linear** for regression models.</span></span> <span data-ttu-id="2e71e-177">(Zelfs als u de standaard gebruikt, u kunt expliciet aangeven van de functie activeren, indien gewenst voor de duidelijkheid.)</span><span class="sxs-lookup"><span data-stu-id="2e71e-177">(Even if you use the default, you can explicitly state the activation function, if desired for clarity.)</span></span>

<span data-ttu-id="2e71e-178">De volgende uitvoer-functies worden ondersteund:</span><span class="sxs-lookup"><span data-stu-id="2e71e-178">The following output functions are supported:</span></span>  

* <span data-ttu-id="2e71e-179">sigmoid</span><span class="sxs-lookup"><span data-stu-id="2e71e-179">sigmoid</span></span>
* <span data-ttu-id="2e71e-180">Lineair</span><span class="sxs-lookup"><span data-stu-id="2e71e-180">linear</span></span>
* <span data-ttu-id="2e71e-181">softmax</span><span class="sxs-lookup"><span data-stu-id="2e71e-181">softmax</span></span>
* <span data-ttu-id="2e71e-182">rlinear</span><span class="sxs-lookup"><span data-stu-id="2e71e-182">rlinear</span></span>
* <span data-ttu-id="2e71e-183">vierkante</span><span class="sxs-lookup"><span data-stu-id="2e71e-183">square</span></span>
* <span data-ttu-id="2e71e-184">SQRT</span><span class="sxs-lookup"><span data-stu-id="2e71e-184">sqrt</span></span>
* <span data-ttu-id="2e71e-185">srlinear</span><span class="sxs-lookup"><span data-stu-id="2e71e-185">srlinear</span></span>
* <span data-ttu-id="2e71e-186">ABS</span><span class="sxs-lookup"><span data-stu-id="2e71e-186">abs</span></span>
* <span data-ttu-id="2e71e-187">TANH</span><span class="sxs-lookup"><span data-stu-id="2e71e-187">tanh</span></span> 
* <span data-ttu-id="2e71e-188">brlinear</span><span class="sxs-lookup"><span data-stu-id="2e71e-188">brlinear</span></span>  

<span data-ttu-id="2e71e-189">De volgende declaratie gebruikt bijvoorbeeld de **softmax** functie:</span><span class="sxs-lookup"><span data-stu-id="2e71e-189">For example, the following declaration uses the **softmax** function:</span></span>  

    output Result [100] softmax from Hidden all;  

## <a name="connection-declaration"></a><span data-ttu-id="2e71e-190">Verbinding declaratie</span><span class="sxs-lookup"><span data-stu-id="2e71e-190">Connection declaration</span></span>
<span data-ttu-id="2e71e-191">Direct na het definiëren van de trainable laag, moet u de verbindingen tussen de lagen die u hebt gedefinieerd declareren.</span><span class="sxs-lookup"><span data-stu-id="2e71e-191">Immediately after defining the trainable layer, you must declare connections among the layers you have defined.</span></span> <span data-ttu-id="2e71e-192">De declaratie van de bundel verbinding begint met het sleutelwoord **van**, gevolgd door de naam van de bundel bronlaag en de aard van de bundel verbinding te maken.</span><span class="sxs-lookup"><span data-stu-id="2e71e-192">The connection bundle declaration starts with the keyword **from**, followed by the name of the bundle's source layer and the kind of connection bundle to create.</span></span>   

<span data-ttu-id="2e71e-193">Op dit moment worden verbinding bundels vijf typen ondersteund:</span><span class="sxs-lookup"><span data-stu-id="2e71e-193">Currently, five kinds of connection bundles are supported:</span></span>  

* <span data-ttu-id="2e71e-194">**Volledige** bundels, aangegeven door het sleutelwoord **alle**</span><span class="sxs-lookup"><span data-stu-id="2e71e-194">**Full** bundles, indicated by the keyword **all**</span></span>
* <span data-ttu-id="2e71e-195">**Gefilterd** bundels, aangegeven door het sleutelwoord **waar**, gevolgd door een predikaat expressie</span><span class="sxs-lookup"><span data-stu-id="2e71e-195">**Filtered** bundles, indicated by the keyword **where**, followed by a predicate expression</span></span>
* <span data-ttu-id="2e71e-196">**Convolutional** bundels, aangegeven door het sleutelwoord **convolve**, gevolgd door de kenmerken convolutiefilter</span><span class="sxs-lookup"><span data-stu-id="2e71e-196">**Convolutional** bundles, indicated by the keyword **convolve**, followed by the convolution attributes</span></span>
* <span data-ttu-id="2e71e-197">**Groeperen van** bundels, aangegeven door de trefwoorden **maximum aantal toepassingen** of **betekent dat de groep van toepassingen**</span><span class="sxs-lookup"><span data-stu-id="2e71e-197">**Pooling** bundles, indicated by the keywords **max pool** or **mean pool**</span></span>
* <span data-ttu-id="2e71e-198">**Antwoord normalisatie** bundels, aangegeven door het sleutelwoord **antwoord norm**</span><span class="sxs-lookup"><span data-stu-id="2e71e-198">**Response normalization** bundles, indicated by the keyword **response norm**</span></span>      

## <a name="full-bundles"></a><span data-ttu-id="2e71e-199">Volledige bundels</span><span class="sxs-lookup"><span data-stu-id="2e71e-199">Full bundles</span></span>
<span data-ttu-id="2e71e-200">Een volledige verbinding bundel bevat een verbinding van elk knooppunt in de bronlaag voor elk knooppunt in de doellaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-200">A full connection bundle includes a connection from each node in the source layer to each node in the destination layer.</span></span> <span data-ttu-id="2e71e-201">Dit is het type standaard netwerkverbinding.</span><span class="sxs-lookup"><span data-stu-id="2e71e-201">This is the default network connection type.</span></span>  

## <a name="filtered-bundles"></a><span data-ttu-id="2e71e-202">Gefilterde bundels</span><span class="sxs-lookup"><span data-stu-id="2e71e-202">Filtered bundles</span></span>
<span data-ttu-id="2e71e-203">Een gefilterde verbinding bundel specificatie bevat een veel-predicaat, syntaxis, uitgedrukt als een C# lambda-expressie.</span><span class="sxs-lookup"><span data-stu-id="2e71e-203">A filtered connection bundle specification includes a predicate, expressed syntactically, much like a C# lambda expression.</span></span> <span data-ttu-id="2e71e-204">Het volgende voorbeeld definieert twee gefilterde bundels:</span><span class="sxs-lookup"><span data-stu-id="2e71e-204">The following example defines two filtered bundles:</span></span>  

    input Pixels [10, 20];
    hidden ByRow[10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol[5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;  

* <span data-ttu-id="2e71e-205">In het predikaat voor *ByRow*, **s** is een parameter die een index in de rechthoekige matrix van knooppunten van de invoer laag vertegenwoordigt *Pixels*, en **d** is een parameter die een index in de matrix van knooppunten in de verborgen laag vertegenwoordigt *ByRow*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-205">In the predicate for *ByRow*, **s** is a parameter representing an index into the rectangular array of nodes of the input layer, *Pixels*, and **d** is a parameter representing an index into the array of nodes of the hidden layer, *ByRow*.</span></span> <span data-ttu-id="2e71e-206">Het type van beide **s** en **d** is een tuple van gehele getallen van twee lengte.</span><span class="sxs-lookup"><span data-stu-id="2e71e-206">The type of both **s** and **d** is a tuple of integers of length two.</span></span> <span data-ttu-id="2e71e-207">Conceptueel gezien **s** bereiken via alle paren van gehele getallen met *0 < = s [0] < 10* en *0 < = s[1] < 20*, en **d**  bereiken via alle paren van gehele getallen, met *0 < = [0] d < 10* en *0 < = d[1] < 12*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-207">Conceptually, **s** ranges over all pairs of integers with *0 <= s[0] < 10* and *0 <= s[1] < 20*, and **d** ranges over all pairs of integers, with *0 <= d[0] < 10* and *0 <= d[1] < 12*.</span></span> 
* <span data-ttu-id="2e71e-208">Aan de rechterkant van de predikaatexpressie die is is er een voorwaarde.</span><span class="sxs-lookup"><span data-stu-id="2e71e-208">On the right-hand side of the predicate expression, there is a condition.</span></span> <span data-ttu-id="2e71e-209">In dit voorbeeld wordt voor elke waarde van **s** en **d** zodanig dat de voorwaarde waar is, er is een rand van het bronknooppunt laag naar het doelknooppunt voor de laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-209">In this example, for every value of **s** and **d** such that the condition is True, there is an edge from the source layer node to the destination layer node.</span></span> <span data-ttu-id="2e71e-210">Dus deze filterexpressie geeft aan dat de bundel een verbinding van het knooppunt dat is gedefinieerd bevat door **s** naar het knooppunt dat is gedefinieerd door **d** in alle gevallen waarbij s [0] gelijk aan [0] d is.</span><span class="sxs-lookup"><span data-stu-id="2e71e-210">Thus, this filter expression indicates that the bundle includes a connection from the node defined by **s** to the node defined by **d** in all cases where s[0] is equal to d[0].</span></span>  

<span data-ttu-id="2e71e-211">U kunt eventueel opgeven dat een set van gewicht voor een gefilterde bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-211">Optionally, you can specify a set of weights for a filtered bundle.</span></span> <span data-ttu-id="2e71e-212">De waarde voor de **gewichten** kenmerk moet een tuple met drijvende puntwaarden met een lengte die overeenkomt met het aantal verbindingen dat is gedefinieerd door de bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-212">The value for the **Weights** attribute must be a tuple of floating point values with a length that matches the number of connections defined by the bundle.</span></span> <span data-ttu-id="2e71e-213">Standaard worden gewichten willekeurig gegenereerd.</span><span class="sxs-lookup"><span data-stu-id="2e71e-213">By default, weights are randomly generated.</span></span>  

<span data-ttu-id="2e71e-214">Gewichtswaarden zijn gegroepeerd op de index van de doel-knooppunt.</span><span class="sxs-lookup"><span data-stu-id="2e71e-214">Weight values are grouped by the destination node index.</span></span> <span data-ttu-id="2e71e-215">Is als het eerste bestemmingsknooppunt is verbonden met K bron knooppunten, de eerste *K* elementen van de **gewichten** tuple zijn het gewicht voor het eerste doelknooppunt in volgorde van de gegevensbron-index.</span><span class="sxs-lookup"><span data-stu-id="2e71e-215">That is, if the first destination node is connected to K source nodes, the first *K* elements of the **Weights** tuple are the weights for the first destination node, in source index order.</span></span> <span data-ttu-id="2e71e-216">Hetzelfde geldt voor de resterende knooppunten van de bestemming.</span><span class="sxs-lookup"><span data-stu-id="2e71e-216">The same applies for the remaining destination nodes.</span></span>  

<span data-ttu-id="2e71e-217">Het is mogelijk gewichten rechtstreeks als constante waarden opgeven.</span><span class="sxs-lookup"><span data-stu-id="2e71e-217">It's possible to specify weights directly as constant values.</span></span> <span data-ttu-id="2e71e-218">Bijvoorbeeld, als u het gewicht eerder hebt geleerd, kunt u ze als constanten gebruik de volgende syntaxis:</span><span class="sxs-lookup"><span data-stu-id="2e71e-218">For example, if you learned the weights previously, you can specify them as constants using this syntax:</span></span>

    const Weights_1 = [0.0188045055, 0.130500451, ...]


## <a name="convolutional-bundles"></a><span data-ttu-id="2e71e-219">Convolutional bundels</span><span class="sxs-lookup"><span data-stu-id="2e71e-219">Convolutional bundles</span></span>
<span data-ttu-id="2e71e-220">Wanneer de trainingsgegevens een homogene structuur heeft, worden convolutional verbindingen worden vaak gebruikt voor meer informatie over geavanceerde functies van de gegevens.</span><span class="sxs-lookup"><span data-stu-id="2e71e-220">When the training data has a homogeneous structure, convolutional connections are commonly used to learn high-level features of the data.</span></span> <span data-ttu-id="2e71e-221">Gegevens bijvoorbeeld: in afbeelding audio- of videobestanden, ruimtelijke of tijdelijke dimensionaliteit kunnen zijn redelijk uniform.</span><span class="sxs-lookup"><span data-stu-id="2e71e-221">For example, in image, audio, or video data, spatial or temporal dimensionality can be fairly uniform.</span></span>  

<span data-ttu-id="2e71e-222">Convolutional bundels alvast rechthoekige **kernels** die via de dimensies worden geschoven.</span><span class="sxs-lookup"><span data-stu-id="2e71e-222">Convolutional bundles employ rectangular **kernels** that are slid through the dimensions.</span></span> <span data-ttu-id="2e71e-223">In wezen elke kernel definieert een reeks gewichten toegepast in de lokale groepen genoemd **kerneltoepassingen**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-223">Essentially, each kernel defines a set of weights applied in local neighborhoods, referred to as **kernel applications**.</span></span> <span data-ttu-id="2e71e-224">Elke toepassing kernel komt overeen met een knooppunt in de bronlaag, waarnaar wordt verwezen als de **centrale knooppunt**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-224">Each kernel application corresponds to a node in the source layer, which is referred to as the **central node**.</span></span> <span data-ttu-id="2e71e-225">Het gewicht van een kernel worden gedeeld door veel verbindingen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-225">The weights of a kernel are shared among many connections.</span></span> <span data-ttu-id="2e71e-226">In een convolutional bundel elke kernel is rechthoekig en alle kerneltoepassingen zijn dezelfde grootte hebben.</span><span class="sxs-lookup"><span data-stu-id="2e71e-226">In a convolutional bundle, each kernel is rectangular and all kernel applications are the same size.</span></span>  

<span data-ttu-id="2e71e-227">Convolutional bundels ondersteunen de volgende kenmerken:</span><span class="sxs-lookup"><span data-stu-id="2e71e-227">Convolutional bundles support the following attributes:</span></span>

<span data-ttu-id="2e71e-228">**InputShape** definieert de dimensionaliteit van de bronlaag voor de doeleinden van deze convolutional bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-228">**InputShape** defines the dimensionality of the source layer for the purposes of this convolutional bundle.</span></span> <span data-ttu-id="2e71e-229">De waarde moet een tuple van positieve gehele getallen zijn.</span><span class="sxs-lookup"><span data-stu-id="2e71e-229">The value must be a tuple of positive integers.</span></span> <span data-ttu-id="2e71e-230">Het aantal knooppunten in de bronlaag moet gelijk zijn aan het product van de gehele getallen, maar anders hoeft niet overeenkomen met de dimensionaliteit is gedeclareerd voor de bronlaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-230">The product of the integers must equal the number of nodes in the source layer, but otherwise, it does not need to match the dimensionality declared for the source layer.</span></span> <span data-ttu-id="2e71e-231">De lengte van deze tuple wordt de **ariteit** waarde voor de convolutional bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-231">The length of this tuple becomes the **arity** value for the convolutional bundle.</span></span> <span data-ttu-id="2e71e-232">(Meestal ariteit verwijst naar het aantal argumenten of operanden die kan worden uitgevoerd door een functie.)</span><span class="sxs-lookup"><span data-stu-id="2e71e-232">(Typically arity refers to the number of arguments or operands that a function can take.)</span></span>  

<span data-ttu-id="2e71e-233">Gebruik de kenmerken definiëren van de vorm en de locaties van de kernels **KernelShape**, **Stride**, **opvulling**, **LowerPad**, en  **UpperPad**:</span><span class="sxs-lookup"><span data-stu-id="2e71e-233">To define the shape and locations of the kernels, use the attributes **KernelShape**, **Stride**, **Padding**, **LowerPad**, and **UpperPad**:</span></span>   

* <span data-ttu-id="2e71e-234">**KernelShape**: (vereist) definieert de dimensionaliteit van elke kernel voor de convolutional bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-234">**KernelShape**: (required) Defines the dimensionality of each kernel for the convolutional bundle.</span></span> <span data-ttu-id="2e71e-235">De waarde moet een tuple van positieve gehele getallen met een lengte die gelijk is aan de ariteit van de bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-235">The value must be a tuple of positive integers with a length that equals the arity of the bundle.</span></span> <span data-ttu-id="2e71e-236">Elk onderdeel van deze tuple mag niet langer zijn dan het overeenkomstige onderdeel van **InputShape**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-236">Each component of this tuple must be no greater than the corresponding component of **InputShape**.</span></span> 
* <span data-ttu-id="2e71e-237">**Stride**: (optioneel) definieert de verschuivende stap grootte van de convolutiefilter (één stapgrootte voor elke dimensie), die de afstand tussen de centrale knooppunten.</span><span class="sxs-lookup"><span data-stu-id="2e71e-237">**Stride**: (optional) Defines the sliding step sizes of the convolution (one step size for each dimension), that is the distance between the central nodes.</span></span> <span data-ttu-id="2e71e-238">De waarde moet een tuple van positieve gehele getallen met een lengte die de ariteit van de bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-238">The value must be a tuple of positive integers with a length that is the arity of the bundle.</span></span> <span data-ttu-id="2e71e-239">Elk onderdeel van deze tuple mag niet langer zijn dan het overeenkomstige onderdeel van **KernelShape**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-239">Each component of this tuple must be no greater than the corresponding component of **KernelShape**.</span></span> <span data-ttu-id="2e71e-240">De standaardwaarde is een tuple met alle onderdelen die gelijk zijn aan één.</span><span class="sxs-lookup"><span data-stu-id="2e71e-240">The default value is a tuple with all components equal to one.</span></span> 
* <span data-ttu-id="2e71e-241">**Delen**: (optioneel) definieert het gewicht voor elke dimensie van de convolutiefilter delen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-241">**Sharing**: (optional) Defines the weight sharing for each dimension of the convolution.</span></span> <span data-ttu-id="2e71e-242">De waarde kan niet één Booleaanse waarde of een tuple van Booleaanse waarden met een lengte die de ariteit van de bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-242">The value can be a single Boolean value or a tuple of Boolean values with a length that is the arity of the bundle.</span></span> <span data-ttu-id="2e71e-243">Een enkele Booleaanse waarde is uitgebreid om te worden van een tuple van de juiste lengte met alle onderdelen die gelijk is aan de opgegeven waarde.</span><span class="sxs-lookup"><span data-stu-id="2e71e-243">A single Boolean value is extended to be a tuple of the correct length with all components equal to the specified value.</span></span> <span data-ttu-id="2e71e-244">De standaardwaarde is een tuple die uit alle waar waarden bestaat.</span><span class="sxs-lookup"><span data-stu-id="2e71e-244">The default value is a tuple that consists of all True values.</span></span> 
* <span data-ttu-id="2e71e-245">**MapCount**: (optioneel) definieert het aantal van de functie voor de convolutional bundel wordt toegewezen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-245">**MapCount**: (optional) Defines the number of feature maps for the convolutional bundle.</span></span> <span data-ttu-id="2e71e-246">De waarde kan niet een enkel positief geheel getal of een tuple van positieve gehele getallen met een lengte die de ariteit van de bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-246">The value can be a single positive integer or a tuple of positive integers with a length that is the arity of the bundle.</span></span> <span data-ttu-id="2e71e-247">Een enkele geheelgetalwaarde is uitgebreid om te worden van een tuple van de juiste lengte van de eerste onderdelen die gelijk is aan de opgegeven waarde en de resterende onderdelen gelijk is aan één.</span><span class="sxs-lookup"><span data-stu-id="2e71e-247">A single integer value is extended to be a tuple of the correct length with the first components equal to the specified value and all the remaining components equal to one.</span></span> <span data-ttu-id="2e71e-248">De standaardwaarde is een.</span><span class="sxs-lookup"><span data-stu-id="2e71e-248">The default value is one.</span></span> <span data-ttu-id="2e71e-249">Het totale aantal functie maps is het product van de onderdelen van de tuple.</span><span class="sxs-lookup"><span data-stu-id="2e71e-249">The total number of feature maps is the product of the components of the tuple.</span></span> <span data-ttu-id="2e71e-250">Waarbij van dit totale aantal voor de onderdelen bepaalt hoe de waarden van de kaart functie worden gegroepeerd in de doel-knooppunten.</span><span class="sxs-lookup"><span data-stu-id="2e71e-250">The factoring of this total number across the components determines how the feature map values are grouped in the destination nodes.</span></span> 
* <span data-ttu-id="2e71e-251">**Gewicht**: (optioneel) definieert het eerste gewicht voor de bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-251">**Weights**: (optional) Defines the initial weights for the bundle.</span></span> <span data-ttu-id="2e71e-252">De waarde moet een tuple met drijvende puntwaarden met een lengte van het aantal keren kernels het nummer van de gewichten per kernel, zoals verderop in dit artikel is gedefinieerd.</span><span class="sxs-lookup"><span data-stu-id="2e71e-252">The value must be a tuple of floating point values with a length that is the number of kernels times the number of weights per kernel, as defined later in this article.</span></span> <span data-ttu-id="2e71e-253">De standaardgewichten worden willekeurig gegenereerd.</span><span class="sxs-lookup"><span data-stu-id="2e71e-253">The default weights are randomly generated.</span></span>  

<span data-ttu-id="2e71e-254">Er zijn twee sets van eigenschappen die regelen opvulling, de eigenschappen wordt sluiten elkaar wederzijds uit:</span><span class="sxs-lookup"><span data-stu-id="2e71e-254">There are two sets of properties that control padding, the properties being mutually exclusive:</span></span>

* <span data-ttu-id="2e71e-255">**Opvulling**: (optioneel) bepaalt of de invoer moet zijn opgevuld met behulp van een **opvulling standaardschema**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-255">**Padding**: (optional) Determines whether the input should be padded by using a **default padding scheme**.</span></span> <span data-ttu-id="2e71e-256">De waarde kan één Booleaanse waarde, of het kan ook een tuple van Booleaanse waarden met een lengte die de ariteit van de bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-256">The value can be a single Boolean value, or it can be a tuple of Boolean values with a length that is the arity of the bundle.</span></span> <span data-ttu-id="2e71e-257">Een enkele Booleaanse waarde is uitgebreid om te worden van een tuple van de juiste lengte met alle onderdelen die gelijk is aan de opgegeven waarde.</span><span class="sxs-lookup"><span data-stu-id="2e71e-257">A single Boolean value is extended to be a tuple of the correct length with all components equal to the specified value.</span></span> <span data-ttu-id="2e71e-258">Als de waarde voor een dimensie True is, worden de bron logisch opgevuld in die dimensie met de cellen met nul ter ondersteuning van aanvullende kerneltoepassingen, zodat de centrale knooppunten van het eerste en laatste kernels in die dimensie zijn de eerste en laatste knooppunten dat in dimensie in de bronlaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-258">If the value for a dimension is True, the source is logically padded in that dimension with zero-valued cells to support additional kernel applications, such that the central nodes of the first and last kernels in that dimension are the first and last nodes in that dimension in the source layer.</span></span> <span data-ttu-id="2e71e-259">Dus het aantal 'dummy' knooppunten in elke dimensie wordt automatisch bepaald, past precies *(InputShape [d] - 1) / Stride [d] + 1* kernels in de bronlaag gevuld.</span><span class="sxs-lookup"><span data-stu-id="2e71e-259">Thus, the number of "dummy" nodes in each dimension is determined automatically, to fit exactly *(InputShape[d] - 1) / Stride[d] + 1* kernels into the padded source layer.</span></span> <span data-ttu-id="2e71e-260">Als de waarde voor een dimensie False is, worden de kernels gedefinieerd, zodat het aantal knooppunten voor elke zijde die worden weggelaten hetzelfde (maximaal een verschil van 1 wordt).</span><span class="sxs-lookup"><span data-stu-id="2e71e-260">If the value for a dimension is False, the kernels are defined so that the number of nodes on each side that are left out is the same (up to a difference of 1).</span></span> <span data-ttu-id="2e71e-261">De standaardwaarde van dit kenmerk is een tuple met alle onderdelen die gelijk is aan False.</span><span class="sxs-lookup"><span data-stu-id="2e71e-261">The default value of this attribute is a tuple with all components equal to False.</span></span>
* <span data-ttu-id="2e71e-262">**UpperPad** en **LowerPad**: (optioneel) Geef meer controle over de hoeveelheid opvulling te gebruiken.</span><span class="sxs-lookup"><span data-stu-id="2e71e-262">**UpperPad** and **LowerPad**: (optional) Provide greater control over the amount of padding to use.</span></span> <span data-ttu-id="2e71e-263">**Belangrijk:** deze kenmerken kunnen worden gedefinieerd als en alleen als de **opvulling** eigenschap hierboven is ***niet*** gedefinieerd.</span><span class="sxs-lookup"><span data-stu-id="2e71e-263">**Important:** These attributes can be defined if and only if the **Padding** property above is ***not*** defined.</span></span> <span data-ttu-id="2e71e-264">De waarden moet geheel getalwaarde tuples met een lengte die de ariteit van de bundel.</span><span class="sxs-lookup"><span data-stu-id="2e71e-264">The values should be integer-valued tuples with lengths that are the arity of the bundle.</span></span> <span data-ttu-id="2e71e-265">Als deze kenmerken worden opgegeven, wordt 'dummy' knooppunten worden toegevoegd aan de boven- en ondergrenzen ends van iedere dimensie van de invoer laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-265">When these attributes are specified, "dummy" nodes are added to the lower and upper ends of each dimension of the input layer.</span></span> <span data-ttu-id="2e71e-266">Het aantal knooppunten die zijn toegevoegd aan de boven- en ondergrenzen ends in elke dimensie wordt bepaald door **LowerPad**[i] en **UpperPad**[i] respectievelijk.</span><span class="sxs-lookup"><span data-stu-id="2e71e-266">The number of nodes added to the lower and upper ends in each dimension is determined by **LowerPad**[i] and **UpperPad**[i] respectively.</span></span> <span data-ttu-id="2e71e-267">Om ervoor te zorgen dat kernels alleen naar 'echte' knooppunten en niet 'dummy' knooppunten overeenkomen, moeten de volgende voorwaarden worden voldaan:</span><span class="sxs-lookup"><span data-stu-id="2e71e-267">To ensure that kernels correspond only to "real" nodes and not to "dummy" nodes, the following conditions must be met:</span></span>
  * <span data-ttu-id="2e71e-268">Elk onderdeel van **LowerPad** moet strikt kleiner zijn dan KernelShape [d] / 2.</span><span class="sxs-lookup"><span data-stu-id="2e71e-268">Each component of **LowerPad** must be strictly less than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="2e71e-269">Elk onderdeel van **UpperPad** mag niet langer zijn dan KernelShape [d] / 2.</span><span class="sxs-lookup"><span data-stu-id="2e71e-269">Each component of **UpperPad** must be no greater than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="2e71e-270">De standaardwaarde van deze kenmerken is een tuple met alle onderdelen die gelijk zijn aan 0.</span><span class="sxs-lookup"><span data-stu-id="2e71e-270">The default value of these attributes is a tuple with all components equal to 0.</span></span> 

<span data-ttu-id="2e71e-271">De instelling **opvulling** = true kunt zoveel opvulling te houden van het 'midden' van de kernel binnen de 'werkelijke' invoer nodig is.</span><span class="sxs-lookup"><span data-stu-id="2e71e-271">The setting **Padding** = true allows as much padding as is needed to keep the "center" of the kernel inside the "real" input.</span></span> <span data-ttu-id="2e71e-272">Hiermee wijzigt u de math iets voor het berekenen van de uitvoergrootte van de.</span><span class="sxs-lookup"><span data-stu-id="2e71e-272">This changes the math a bit for computing the output size.</span></span> <span data-ttu-id="2e71e-273">In het algemeen de uitvoergrootte van de *D* wordt berekend als *D = (I - K) / S + 1*, waarbij *ik* is de ingevoerde grootte *K* is de grootte kernel *S*  is de stride en  */*  deling van geheel getal (afronden op nul) is.</span><span class="sxs-lookup"><span data-stu-id="2e71e-273">Generally, the output size *D* is computed as *D = (I - K) / S + 1*, where *I* is the input size, *K* is the kernel size, *S* is the stride, and */* is integer division (round toward zero).</span></span> <span data-ttu-id="2e71e-274">Als u UpperPad instellen = [1, 1], de grootte van de invoer *ik* is in feite 29, en dus *D = (29-5) / 2 + 1 = 13*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-274">If you set UpperPad = [1, 1], the input size *I* is effectively 29, and thus *D = (29 - 5) / 2 + 1 = 13*.</span></span> <span data-ttu-id="2e71e-275">Echter, wanneer **opvulling** = true, wordt in wezen *ik* opgehaald tegenaan door *K - 1*; daarom *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-275">However, when **Padding** = true, essentially *I* gets bumped up by *K - 1*; hence *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span></span> <span data-ttu-id="2e71e-276">Door op te geven waarden voor **UpperPad** en **LowerPad** dat u veel meer controle over de opvulling dan als u zojuist hebt ingesteld **opvulling** = true.</span><span class="sxs-lookup"><span data-stu-id="2e71e-276">By specifying values for **UpperPad** and **LowerPad** you get much more control over the padding than if you just set **Padding** = true.</span></span>

<span data-ttu-id="2e71e-277">Zie voor meer informatie over convolutional netwerken en hun toepassingen in deze artikelen:</span><span class="sxs-lookup"><span data-stu-id="2e71e-277">For more information about convolutional networks and their applications, see these articles:</span></span>  

* [<span data-ttu-id="2e71e-278">http://deeplearning.NET/Tutorial/lenet.HTML</span><span class="sxs-lookup"><span data-stu-id="2e71e-278">http://deeplearning.net/tutorial/lenet.html </span></span>](http://deeplearning.net/tutorial/lenet.html)
* [<span data-ttu-id="2e71e-279">http://Research.Microsoft.com/pubs/68920/icdar03.PDF</span><span class="sxs-lookup"><span data-stu-id="2e71e-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span></span>](http://research.microsoft.com/pubs/68920/icdar03.pdf) 
* [<span data-ttu-id="2e71e-280">http://People.csail.MIT.edu/jvb/Papers/cnn_tutorial.PDF</span><span class="sxs-lookup"><span data-stu-id="2e71e-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span></span>](http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf)  

## <a name="pooling-bundles"></a><span data-ttu-id="2e71e-281">Bundels groeperen</span><span class="sxs-lookup"><span data-stu-id="2e71e-281">Pooling bundles</span></span>
<span data-ttu-id="2e71e-282">Een **groeperen bundel** van toepassing is vergelijkbaar met convolutional connectiviteit geometrie maar vooraf gedefinieerde waarden van de bron-functies worden afgeleid van de waarde van de doel-knooppunt wordt gebruikt.</span><span class="sxs-lookup"><span data-stu-id="2e71e-282">A **pooling bundle** applies geometry similar to convolutional connectivity, but it uses predefined functions to source node values to derive the destination node value.</span></span> <span data-ttu-id="2e71e-283">Groepering bundels hebben daarom geen trainable status (gewichten of vooroordelen).</span><span class="sxs-lookup"><span data-stu-id="2e71e-283">Hence, pooling bundles have no trainable state (weights or biases).</span></span> <span data-ttu-id="2e71e-284">Groepering bundels ondersteuning voor alle convolutional kenmerken behalve **delen**, **MapCount**, en **gewichten**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-284">Pooling bundles support all the convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

<span data-ttu-id="2e71e-285">Normaal gesproken overlappen de kernels samengevat door aangrenzende groepering eenheden niet.</span><span class="sxs-lookup"><span data-stu-id="2e71e-285">Typically, the kernels summarized by adjacent pooling units do not overlap.</span></span> <span data-ttu-id="2e71e-286">Als Stride [d] gelijk aan KernelShape [d] in elke dimensie is, is de laag verkregen de traditionele lokale groepering laag, die meestal in convolutional neural netwerken gebruikt wordt.</span><span class="sxs-lookup"><span data-stu-id="2e71e-286">If Stride[d] is equal to KernelShape[d] in each dimension, the layer obtained is the traditional local pooling layer, which is commonly employed in convolutional neural networks.</span></span> <span data-ttu-id="2e71e-287">Elke doelknooppunt berekent het maximum of het gemiddelde van de activiteiten van de kernel in de bronlaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-287">Each destination node computes the maximum or the mean of the activities of its kernel in the source layer.</span></span>  

<span data-ttu-id="2e71e-288">Het volgende voorbeeld wordt een groepering bundel:</span><span class="sxs-lookup"><span data-stu-id="2e71e-288">The following example illustrates a pooling bundle:</span></span> 

    hidden P1 [5, 12, 12]
      from C1 max pool {
        InputShape  = [ 5, 24, 24];
        KernelShape = [ 1,  2,  2];
        Stride      = [ 1,  2,  2];
      }  

* <span data-ttu-id="2e71e-289">De ariteit van de bundel is 3 (de lengte van de tuples **InputShape**, **KernelShape**, en **Stride**).</span><span class="sxs-lookup"><span data-stu-id="2e71e-289">The arity of the bundle is 3 (the length of the tuples **InputShape**, **KernelShape**, and **Stride**).</span></span> 
* <span data-ttu-id="2e71e-290">Het aantal knooppunten in de bronlaag is *5 * 24 * 24 = 2880*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-290">The number of nodes in the source layer is *5 * 24 * 24 = 2880*.</span></span> 
* <span data-ttu-id="2e71e-291">Dit is een traditionele lokale groepering laag omdat **KernelShape** en **Stride** gelijk zijn.</span><span class="sxs-lookup"><span data-stu-id="2e71e-291">This is a traditional local pooling layer because **KernelShape** and **Stride** are equal.</span></span> 
* <span data-ttu-id="2e71e-292">Het aantal knooppunten in de doellaag is *5 * 12 * 12 = 1440*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-292">The number of nodes in the destination layer is *5 * 12 * 12 = 1440*.</span></span>  

<span data-ttu-id="2e71e-293">Zie voor meer informatie over groepering lagen deze artikelen:</span><span class="sxs-lookup"><span data-stu-id="2e71e-293">For more information about pooling layers, see these articles:</span></span>  

* <span data-ttu-id="2e71e-294">[http://www.cs.Toronto.edu/~hinton/absps/imagenet.PDF](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (sectie 3.4)</span><span class="sxs-lookup"><span data-stu-id="2e71e-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Section 3.4)</span></span>
* [<span data-ttu-id="2e71e-295">http://CS.Nyu.edu/~koray/publis/lecun-iscas-10.PDF</span><span class="sxs-lookup"><span data-stu-id="2e71e-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span></span>](http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf) 
* [<span data-ttu-id="2e71e-296">http://CS.Nyu.edu/~koray/publis/jarrett-iccv-09.PDF</span><span class="sxs-lookup"><span data-stu-id="2e71e-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span></span>](http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf)

## <a name="response-normalization-bundles"></a><span data-ttu-id="2e71e-297">Antwoord normalisatie bundels</span><span class="sxs-lookup"><span data-stu-id="2e71e-297">Response normalization bundles</span></span>
<span data-ttu-id="2e71e-298">**Antwoord normalisatie** is een lokale normalisatie-schema dat is geïntroduceerd door Geoffrey Hinton, et al., in het artikel [ImageNet Classiﬁcation met Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span><span class="sxs-lookup"><span data-stu-id="2e71e-298">**Response normalization** is a local normalization scheme that was first introduced by Geoffrey Hinton, et al, in the paper [ImageNet Classiﬁcation with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span></span> <span data-ttu-id="2e71e-299">Antwoord normalisatie wordt gebruikt om u te helpen generaliseren van neural netten.</span><span class="sxs-lookup"><span data-stu-id="2e71e-299">Response normalization is used to aid generalization in neural nets.</span></span> <span data-ttu-id="2e71e-300">Wanneer een neuron wordt uitgevoerd op een zeer hoge Activeringsniveau, wordt in een lokale antwoord normalisatie-laag het Activeringsniveau van de omringende neurons onderdrukt.</span><span class="sxs-lookup"><span data-stu-id="2e71e-300">When one neuron is firing at a very high activation level, a local response normalization layer suppresses the activation level of the surrounding neurons.</span></span> <span data-ttu-id="2e71e-301">Dit wordt gedaan met drie parameters (***α***, ***β***, en ***k***) en een convolutional structuur (of groep vorm).</span><span class="sxs-lookup"><span data-stu-id="2e71e-301">This is done by using three parameters (***α***, ***β***, and ***k***) and a convolutional structure (or neighborhood shape).</span></span> <span data-ttu-id="2e71e-302">Elke neuron in de doellaag ***y*** komt overeen met een neuron ***x*** in de bronlaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-302">Every neuron in the destination layer ***y*** corresponds to a neuron ***x*** in the source layer.</span></span> <span data-ttu-id="2e71e-303">Het Activeringsniveau van ***y*** wordt bepaald door de volgende formule, waarbij ***f*** is het Activeringsniveau van een neuron en ***Nx*** is de kernel (of de set met de neurons in de groep van ***x***), zoals gedefinieerd door de volgende convolutional structuur:</span><span class="sxs-lookup"><span data-stu-id="2e71e-303">The activation level of ***y*** is given by the following formula, where ***f*** is the activation level of a neuron, and ***Nx*** is the kernel (or the set that contains the neurons in the neighborhood of ***x***), as defined by the following convolutional structure:</span></span>  

![][1]  

<span data-ttu-id="2e71e-304">Antwoord normalisatie bundels ondersteuning voor alle convolutional kenmerken behalve **delen**, **MapCount**, en **gewichten**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-304">Response normalization bundles support all the convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

* <span data-ttu-id="2e71e-305">Als de kernel neurons in dezelfde toewijzing als bevat ***x***, het schema van normalisatie wordt aangeduid als **dezelfde normalisatie toewijzen**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-305">If the kernel contains neurons in the same map as ***x***, the normalization scheme is referred to as **same map normalization**.</span></span> <span data-ttu-id="2e71e-306">Voor het definiëren van dezelfde kaart normalisatie wordt de eerste coördinaat in **InputShape** moet de waarde 1 hebben.</span><span class="sxs-lookup"><span data-stu-id="2e71e-306">To define same map normalization, the first coordinate in **InputShape** must have the value 1.</span></span>
* <span data-ttu-id="2e71e-307">Als de kernel neurons in dezelfde ruimtelijke positie als bevat ***x***, maar de neurons zijn in andere toewijzingen, de normalisatie-schema heet **meerdere toegewezen normalisatie**.</span><span class="sxs-lookup"><span data-stu-id="2e71e-307">If the kernel contains neurons in the same spatial position as ***x***, but the neurons are in other maps, the normalization scheme is called **across maps normalization**.</span></span> <span data-ttu-id="2e71e-308">Dit type antwoord normalisatie implementeert een vorm van laterale maar die is geïnspireerd op het type gevonden in de echte neurons concurrentie voor big activering niveaus onder neuron uitvoer berekend op verschillende maps maken.</span><span class="sxs-lookup"><span data-stu-id="2e71e-308">This type of response normalization implements a form of lateral inhibition inspired by the type found in real neurons, creating competition for big activation levels amongst neuron outputs computed on different maps.</span></span> <span data-ttu-id="2e71e-309">Om te definiëren tussen maps normalisatie, moet de eerste coördinaat een geheel getal groter dan één en niet groter zijn dan het aantal maps en de rest van de coördinaten moet de waarde 1 hebben.</span><span class="sxs-lookup"><span data-stu-id="2e71e-309">To define across maps normalization, the first coordinate must be an integer greater than one and no greater than the number of maps, and the rest of the coordinates must have the value 1.</span></span>  

<span data-ttu-id="2e71e-310">Omdat een vooraf gedefinieerde functie antwoord normalisatie bundels op bron knooppuntwaarden om te bepalen van de waarde van de doel-knooppunt toepassen, hebben ze geen trainable status (gewichten of vooroordelen).</span><span class="sxs-lookup"><span data-stu-id="2e71e-310">Because response normalization bundles apply a predefined function to source node values to determine the destination node value, they have no trainable state (weights or biases).</span></span>   

<span data-ttu-id="2e71e-311">**Waarschuwing**: de knooppunten in de doellaag komen overeen met neurons die de centrale knooppunten van de kernels.</span><span class="sxs-lookup"><span data-stu-id="2e71e-311">**Alert**: The nodes in the destination layer correspond to neurons that are the central nodes of the kernels.</span></span> <span data-ttu-id="2e71e-312">Bijvoorbeeld, als KernelShape [d] oneven en wordt vervolgens *KernelShape [d] / 2* komt overeen met het centrale kernel-knooppunt.</span><span class="sxs-lookup"><span data-stu-id="2e71e-312">For example, if KernelShape[d] is odd, then *KernelShape[d]/2* corresponds to the central kernel node.</span></span> <span data-ttu-id="2e71e-313">Als *KernelShape [d]* een even getal is, is het centrale knooppunt *KernelShape [d] / 2-1*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-313">If *KernelShape[d]* is even, the central node is at *KernelShape[d]/2 - 1*.</span></span> <span data-ttu-id="2e71e-314">Daarom als **opvulling**[d] is False, de eerste en de laatste *KernelShape [d] / 2* knooppunten hebben geen overeenkomstige knooppunten in de doellaag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-314">Therefore, if **Padding**[d] is False, the first and the last *KernelShape[d]/2* nodes do not have corresponding nodes in the destination layer.</span></span> <span data-ttu-id="2e71e-315">Om te voorkomen dat deze situatie, definiëren **opvulling** als [true, true,..., true].</span><span class="sxs-lookup"><span data-stu-id="2e71e-315">To avoid this situation, define **Padding** as [true, true, …, true].</span></span>  

<span data-ttu-id="2e71e-316">Naast de vier kenmerken die eerder zijn beschreven, ondersteuning antwoord normalisatie bundels ook voor de volgende kenmerken:</span><span class="sxs-lookup"><span data-stu-id="2e71e-316">In addition to the four attributes described earlier, response normalization bundles also support the following attributes:</span></span>  

* <span data-ttu-id="2e71e-317">**Alpha**: (vereist) geeft een drijvende-kommawaarde die overeenkomt met ***α*** in de vorige formule.</span><span class="sxs-lookup"><span data-stu-id="2e71e-317">**Alpha**: (required) Specifies a floating-point value that corresponds to ***α*** in the previous formula.</span></span> 
* <span data-ttu-id="2e71e-318">**Beta**: (vereist) geeft een drijvende-kommawaarde die overeenkomt met ***β*** in de vorige formule.</span><span class="sxs-lookup"><span data-stu-id="2e71e-318">**Beta**: (required) Specifies a floating-point value that corresponds to ***β*** in the previous formula.</span></span> 
* <span data-ttu-id="2e71e-319">**Offset**: (optioneel) geeft een drijvende-kommawaarde die overeenkomt met ***k*** in de vorige formule.</span><span class="sxs-lookup"><span data-stu-id="2e71e-319">**Offset**: (optional) Specifies a floating-point value that corresponds to ***k*** in the previous formula.</span></span> <span data-ttu-id="2e71e-320">Wordt standaard op 1.</span><span class="sxs-lookup"><span data-stu-id="2e71e-320">It defaults to 1.</span></span>  

<span data-ttu-id="2e71e-321">Het volgende voorbeeld wordt een antwoord normalisatie-bundel met behulp van deze kenmerken gedefinieerd:</span><span class="sxs-lookup"><span data-stu-id="2e71e-321">The following example defines a response normalization bundle using these attributes:</span></span>  

    hidden RN1 [5, 10, 10]
      from P1 response norm {
        InputShape  = [ 5, 12, 12];
        KernelShape = [ 1,  3,  3];
        Alpha = 0.001;
        Beta = 0.75;
      }  

* <span data-ttu-id="2e71e-322">De bronlaag bevat vijf maps, elk met aof dimensie van 12 x 12 Samentelling in 1440 knooppunten.</span><span class="sxs-lookup"><span data-stu-id="2e71e-322">The source layer includes five maps, each with aof dimension of 12x12, totaling in 1440 nodes.</span></span> 
* <span data-ttu-id="2e71e-323">De waarde van **KernelShape** geeft aan dat dit een dezelfde normalisatie kaartLaag, waarbij de groep een rechthoek 3 x 3 is.</span><span class="sxs-lookup"><span data-stu-id="2e71e-323">The value of **KernelShape** indicates that this is a same map normalization layer, where the neighborhood is a 3x3 rectangle.</span></span> 
* <span data-ttu-id="2e71e-324">De standaardwaarde van **opvulling** is ingesteld op False, de laag bestemming heeft dus alleen 10 knooppunten in elke dimensie.</span><span class="sxs-lookup"><span data-stu-id="2e71e-324">The default value of **Padding** is False, thus the destination layer has only 10 nodes in each dimension.</span></span> <span data-ttu-id="2e71e-325">Toevoegen zodat één knooppunt in de doellaag die overeenkomt met elk knooppunt in de bronlaag opvulling = [true, true, true]; en wijzig de grootte van RN1 [5, 12, 12].</span><span class="sxs-lookup"><span data-stu-id="2e71e-325">To include one node in the destination layer that corresponds to every node in the source layer, add Padding = [true, true, true]; and change the size of RN1 to [5, 12, 12].</span></span>  

## <a name="share-declaration"></a><span data-ttu-id="2e71e-326">Share-declaratie</span><span class="sxs-lookup"><span data-stu-id="2e71e-326">Share declaration</span></span>
<span data-ttu-id="2e71e-327">NET # ondersteunt eventueel meerdere pakketten met gedeelde gewichten definiëren.</span><span class="sxs-lookup"><span data-stu-id="2e71e-327">Net# optionally supports defining multiple bundles with shared weights.</span></span> <span data-ttu-id="2e71e-328">Het gewicht van elke twee bundels kunnen worden gedeeld als hun structuren hetzelfde zijn.</span><span class="sxs-lookup"><span data-stu-id="2e71e-328">The weights of any two bundles can be shared if their structures are the same.</span></span> <span data-ttu-id="2e71e-329">De volgende syntaxis definieert bundels met gedeelde gewichten:</span><span class="sxs-lookup"><span data-stu-id="2e71e-329">The following syntax defines bundles with shared weights:</span></span>  

    share-declaration:
        share    {    layer-list    }
        share    {    bundle-list    }
       share    {    bias-list    }

    layer-list:
        layer-name    ,    layer-name
        layer-list    ,    layer-name

    bundle-list:
       bundle-spec    ,    bundle-spec
        bundle-list    ,    bundle-spec

    bundle-spec:
       layer-name    =>     layer-name

    bias-list:
        bias-spec    ,    bias-spec
        bias-list    ,    bias-spec

    bias-spec:
        1    =>    layer-name

    layer-name:
        identifier  

<span data-ttu-id="2e71e-330">De volgende share-declaratie geeft bijvoorbeeld de namen van de lagen die aangeeft dat de gewichten en vooroordelen worden gedeeld op:</span><span class="sxs-lookup"><span data-stu-id="2e71e-330">For example, the following share-declaration specifies the layer names, indicating that both weights and biases should be shared:</span></span>  

    Const {
      InputSize = 37;
      HiddenSize = 50;
    }
    input {
      Data1 [InputSize];
      Data2 [InputSize];
    }
    hidden {
      H1 [HiddenSize] from Data1 all;
      H2 [HiddenSize] from Data2 all;
    }
    output Result [2] {
      from H1 all;
      from H2 all;
    }
    share { H1, H2 } // share both weights and biases  

* <span data-ttu-id="2e71e-331">De invoer functies worden gepartitioneerd in twee gelijke grootte invoer lagen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-331">The input features are partitioned into two equal sized input layers.</span></span> 
* <span data-ttu-id="2e71e-332">Verborgen lagen berekent hoger niveau functies op de twee lagen van de invoer.</span><span class="sxs-lookup"><span data-stu-id="2e71e-332">The hidden layers then compute higher level features on the two input layers.</span></span> 
* <span data-ttu-id="2e71e-333">De share-declaratie geeft aan dat *H1* en *H2* op dezelfde manier uit hun respectieve invoer moet worden berekend.</span><span class="sxs-lookup"><span data-stu-id="2e71e-333">The share-declaration specifies that *H1* and *H2* must be computed in the same way from their respective inputs.</span></span>  

<span data-ttu-id="2e71e-334">U kunt ook kan dit worden opgegeven met twee afzonderlijke share-declaraties als volgt:</span><span class="sxs-lookup"><span data-stu-id="2e71e-334">Alternatively, this could be specified with two separate share-declarations as follows:</span></span>  

    share { Data1 => H1, Data2 => H2 } // share weights  

<!-- -->

    share { 1 => H1, 1 => H2 } // share biases  

<span data-ttu-id="2e71e-335">U kunt de korte vorm alleen als de lagen één bundel bevatten.</span><span class="sxs-lookup"><span data-stu-id="2e71e-335">You can use the short form only when the layers contain a single bundle.</span></span> <span data-ttu-id="2e71e-336">In het algemeen is delen mogelijk alleen wanneer de structuur van de relevante identiek zijn is, zodat ze dezelfde grootte hebben, dezelfde convolutional geometrie, enzovoort.</span><span class="sxs-lookup"><span data-stu-id="2e71e-336">In general, sharing is possible only when the relevant structure is identical, meaning that they have the same size, same convolutional geometry, and so forth.</span></span>  

## <a name="examples-of-net-usage"></a><span data-ttu-id="2e71e-337">Voorbeelden van Net # gebruik</span><span class="sxs-lookup"><span data-stu-id="2e71e-337">Examples of Net# usage</span></span>
<span data-ttu-id="2e71e-338">Deze sectie vindt enkele voorbeelden van hoe u Net # kunt verborgen lagen toevoegen, het definiëren van de manier waarop verborgen lagen met andere lagen communiceren en convolutional netwerken maken.</span><span class="sxs-lookup"><span data-stu-id="2e71e-338">This section provides some examples of how you can use Net# to add hidden layers, define the way that hidden layers interact with other layers, and build convolutional networks.</span></span>   

### <a name="define-a-simple-custom-neural-network-hello-world-example"></a><span data-ttu-id="2e71e-339">Een eenvoudig aangepaste neurale netwerk definiëren: 'Hallo wereld'-voorbeeld</span><span class="sxs-lookup"><span data-stu-id="2e71e-339">Define a simple custom neural network: "Hello World" example</span></span>
<span data-ttu-id="2e71e-340">Dit eenvoudige voorbeeld laat zien hoe een neural network-model met één verborgen laag maken.</span><span class="sxs-lookup"><span data-stu-id="2e71e-340">This simple example demonstrates how to create a neural network model that has a single hidden layer.</span></span>  

    input Data auto;
    hidden H [200] from Data all;
    output Out [10] sigmoid from H all;  

<span data-ttu-id="2e71e-341">Het voorbeeld wordt een aantal basisopdrachten als volgt:</span><span class="sxs-lookup"><span data-stu-id="2e71e-341">The example illustrates some basic commands as follows:</span></span>  

* <span data-ttu-id="2e71e-342">De eerste regel definieert de invoer-laag (met de naam *gegevens*).</span><span class="sxs-lookup"><span data-stu-id="2e71e-342">The first line defines the input layer (named *Data*).</span></span> <span data-ttu-id="2e71e-343">Wanneer u gebruikt de **automatisch** sleutelwoord, het neurale netwerk omvat alle kolommen van de functie automatisch in de invoer voorbeelden.</span><span class="sxs-lookup"><span data-stu-id="2e71e-343">When you use the  **auto** keyword, the neural network automatically includes all feature columns in the input examples.</span></span> 
* <span data-ttu-id="2e71e-344">De tweede regel maakt de verborgen laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-344">The second line creates the hidden layer.</span></span> <span data-ttu-id="2e71e-345">De naam van de *H* is toegewezen aan de verborgen laag waarvoor 200 knooppunten.</span><span class="sxs-lookup"><span data-stu-id="2e71e-345">The name *H* is assigned to the hidden layer, which has 200 nodes.</span></span> <span data-ttu-id="2e71e-346">Deze laag volledig wordt verbonden met de invoer laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-346">This layer is fully connected to the input layer.</span></span>
* <span data-ttu-id="2e71e-347">De derde regel definieert de uitvoer-laag (met de naam *O*), die 10 uitvoerknooppunten bevat.</span><span class="sxs-lookup"><span data-stu-id="2e71e-347">The third line defines the output layer (named *O*), which contains 10 output nodes.</span></span> <span data-ttu-id="2e71e-348">Als het neurale netwerk wordt gebruikt voor classificatie, is er één knooppunt van de uitvoer per klasse.</span><span class="sxs-lookup"><span data-stu-id="2e71e-348">If the neural network is used for classification, there is one output node per class.</span></span> <span data-ttu-id="2e71e-349">Het sleutelwoord **sigmoid** geeft aan dat de uitvoer-functie wordt toegepast op de uitvoer-laag.</span><span class="sxs-lookup"><span data-stu-id="2e71e-349">The keyword **sigmoid** indicates that the output function is applied to the output layer.</span></span>   

### <a name="define-multiple-hidden-layers-computer-vision-example"></a><span data-ttu-id="2e71e-350">Meerdere verborgen lagen definiëren: computer vision-voorbeeld</span><span class="sxs-lookup"><span data-stu-id="2e71e-350">Define multiple hidden layers: computer vision example</span></span>
<span data-ttu-id="2e71e-351">Het volgende voorbeeld laat zien hoe een enigszins complexere neurale netwerk, met meerdere lagen voor aangepaste verborgen definiëren.</span><span class="sxs-lookup"><span data-stu-id="2e71e-351">The following example demonstrates how to define a slightly more complex neural network, with multiple custom hidden layers.</span></span>  

    // Define the input layers 
    input Pixels [10, 20];
    input MetaData [7];

    // Define the first two hidden layers, using data only from the Pixels input
    hidden ByRow [10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol [5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;

    // Define the third hidden layer, which uses as source the hidden layers ByRow and ByCol
    hidden Gather [100] 
    {
      from ByRow all;
      from ByCol all;
    }

    // Define the output layer and its sources
    output Result [10]  
    {
      from Gather all;
      from MetaData all;
    }  

<span data-ttu-id="2e71e-352">In dit voorbeeld ziet u enkele functies van de taal van de specificatie neural netwerken:</span><span class="sxs-lookup"><span data-stu-id="2e71e-352">This example illustrates several features of the neural networks specification language:</span></span>  

* <span data-ttu-id="2e71e-353">De structuur heeft twee invoer lagen, *Pixels* en *metagegevens*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-353">The structure has two input layers, *Pixels* and *MetaData*.</span></span>
* <span data-ttu-id="2e71e-354">De *Pixels* laag is een bronlaag voor twee verbinding-bundels met lagen van de bestemming, *ByRow* en *ByCol*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-354">The *Pixels* layer is a source layer for two connection bundles, with destination layers, *ByRow* and *ByCol*.</span></span>
* <span data-ttu-id="2e71e-355">De lagen *verzamelen* en *resultaat* bestemming lagen in meerdere pakketten van de verbinding zijn.</span><span class="sxs-lookup"><span data-stu-id="2e71e-355">The layers *Gather* and *Result* are destination layers in multiple connection bundles.</span></span>
* <span data-ttu-id="2e71e-356">De laag uitvoer *resultaat*, is een doellaag in twee verbinding bundels; één met de tweede niveau als een laag bestemming verborgen (verzamelen) en de andere met de invoer-laag (MetaData) als een laag bestemming.</span><span class="sxs-lookup"><span data-stu-id="2e71e-356">The output layer, *Result*, is a destination layer in two connection bundles; one with the second level hidden (Gather) as a destination layer, and the other with the input layer (MetaData) as a destination layer.</span></span>
* <span data-ttu-id="2e71e-357">Het verborgen lagen *ByRow* en *ByCol*, gefilterde verbinding opgeven met behulp van predikaat expressies.</span><span class="sxs-lookup"><span data-stu-id="2e71e-357">The hidden layers, *ByRow* and *ByCol*, specify filtered connectivity by using predicate expressions.</span></span> <span data-ttu-id="2e71e-358">Preciezer, het knooppunt in *ByRow* op [x, y] is verbonden met de knooppunten in *Pixels* dat zijn de eerste index coördineren gelijk zijn aan het knooppunt van de eerste coördinaat, x.</span><span class="sxs-lookup"><span data-stu-id="2e71e-358">More precisely, the node in *ByRow* at [x, y] is connected to the nodes in *Pixels* that have the first index coordinate equal to the node's first coordinate, x.</span></span> <span data-ttu-id="2e71e-359">Op deze manier het knooppunt in *ByCol op [x, y] is verbonden met de knooppunten in _Pixels* dat hebben de tweede index coördineren binnen één van het knooppunt van de tweede coördinaat, y.</span><span class="sxs-lookup"><span data-stu-id="2e71e-359">Similarly, the node in *ByCol at [x, y] is connected to the nodes in _Pixels* that have the second index coordinate within one of the node's second coordinate, y.</span></span>  

### <a name="define-a-convolutional-network-for-multiclass-classification-digit-recognition-example"></a><span data-ttu-id="2e71e-360">Definieer een convolutional netwerk voor multiklassen classificatie: cijfer erkenning voorbeeld</span><span class="sxs-lookup"><span data-stu-id="2e71e-360">Define a convolutional network for multiclass classification: digit recognition example</span></span>
<span data-ttu-id="2e71e-361">De definitie van de volgende netwerk is ontworpen voor het herkennen van cijfers en sommige geavanceerde technieken voor het aanpassen van een neural netwerk worden geïllustreerd.</span><span class="sxs-lookup"><span data-stu-id="2e71e-361">The definition of the following network is designed to recognize numbers, and it illustrates some advanced techniques for customizing a neural network.</span></span>  

    input Image [29, 29];
    hidden Conv1 [5, 13, 13] from Image convolve 
    {
       InputShape  = [29, 29];
       KernelShape = [ 5,  5];
       Stride      = [ 2,  2];
       MapCount    = 5;
    }
    hidden Conv2 [50, 5, 5]
    from Conv1 convolve 
    {
       InputShape  = [ 5, 13, 13];
       KernelShape = [ 1,  5,  5];
       Stride      = [ 1,  2,  2];
       Sharing     = [false, true, true];
       MapCount    = 10;
    }
    hidden Hid3 [100] from Conv2 all;
    output Digit [10] from Hid3 all;  


* <span data-ttu-id="2e71e-362">De structuur heeft één invoer laag *installatiekopie*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-362">The structure has a single input layer, *Image*.</span></span>
* <span data-ttu-id="2e71e-363">Het sleutelwoord **convolve** geeft aan dat de lagen naam *Conv1* en *Conv2* convolutional lagen.</span><span class="sxs-lookup"><span data-stu-id="2e71e-363">The keyword **convolve** indicates that the layers named *Conv1* and *Conv2* are convolutional layers.</span></span> <span data-ttu-id="2e71e-364">Elk van deze laag declaraties wordt gevolgd door een lijst van de kenmerken convolutiefilter.</span><span class="sxs-lookup"><span data-stu-id="2e71e-364">Each of these layer declarations is followed by a list of the convolution attributes.</span></span>
* <span data-ttu-id="2e71e-365">De net is een derde verborgen laag *Hid3*, die volledig is verbonden met de tweede verborgen laag *Conv2*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-365">The net has a third hidden layer, *Hid3*, which is fully connected to the second hidden layer, *Conv2*.</span></span>
* <span data-ttu-id="2e71e-366">De laag uitvoer *cijfer*, is alleen verbonden met de derde verborgen laag *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-366">The output layer, *Digit*, is connected only to the third hidden layer, *Hid3*.</span></span> <span data-ttu-id="2e71e-367">Het sleutelwoord **alle** geeft aan dat de uitvoer-laag volledig is verbonden met *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-367">The keyword **all** indicates that the output layer is fully connected to *Hid3*.</span></span>
* <span data-ttu-id="2e71e-368">De ariteit van de convolutiefilter is drie (de lengte van de tuples **InputShape**, **KernelShape**, **Stride**, en **delen**).</span><span class="sxs-lookup"><span data-stu-id="2e71e-368">The arity of the convolution is three (the length of the tuples **InputShape**, **KernelShape**, **Stride**, and **Sharing**).</span></span> 
* <span data-ttu-id="2e71e-369">Het aantal van de gewichten per kernel *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape** \[ 2] = 1 + 1 * 5 * 5 = 26. Of 26 * 50 = 1300*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-369">The number of weights per kernel is *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape**\[2] = 1 + 1 * 5 * 5 = 26. Or 26 * 50 = 1300*.</span></span>
* <span data-ttu-id="2e71e-370">U kunt de knooppunten in de verborgen laag als volgt berekenen:</span><span class="sxs-lookup"><span data-stu-id="2e71e-370">You can calculate the nodes in each hidden layer as follows:</span></span>
  * <span data-ttu-id="2e71e-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="2e71e-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span></span>
  * <span data-ttu-id="2e71e-372">**NodeCount**\[1] = (13-5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="2e71e-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span></span> 
  * <span data-ttu-id="2e71e-373">**NodeCount**\[2] (13-5) = / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="2e71e-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span></span> 
* <span data-ttu-id="2e71e-374">Het totale aantal knooppunten kan worden berekend met behulp van de gedeclareerde dimensionaliteit van de laag [50, 5, 5], als volgt:  ***MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span><span class="sxs-lookup"><span data-stu-id="2e71e-374">The total number of nodes can be calculated by using the declared dimensionality of the layer, [50, 5, 5], as follows: ***MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span></span>
* <span data-ttu-id="2e71e-375">Omdat **delen**[d] False is alleen voor *d == 0*, is het aantal kernels  ***MapCount** * **NodeCount** \[0] = 10 * 5 = 50*.</span><span class="sxs-lookup"><span data-stu-id="2e71e-375">Because **Sharing**[d] is False only for *d == 0*, the number of kernels is ***MapCount** * **NodeCount**\[0] = 10 * 5 = 50*.</span></span> 

## <a name="acknowledgements"></a><span data-ttu-id="2e71e-376">Bevestigingen</span><span class="sxs-lookup"><span data-stu-id="2e71e-376">Acknowledgements</span></span>
<span data-ttu-id="2e71e-377">De taal Net # voor het aanpassen van de architectuur van neural networks is ontwikkeld aan Microsoft door Shon Katzenberger (Architect, Machine Learning) en Alexey Kamenev (Software Engineer, Microsoft Research).</span><span class="sxs-lookup"><span data-stu-id="2e71e-377">The Net# language for customizing the architecture of neural networks was developed at Microsoft by Shon Katzenberger (Architect, Machine Learning) and Alexey Kamenev (Software Engineer, Microsoft Research).</span></span> <span data-ttu-id="2e71e-378">Het wordt intern gebruikt voor machine learning-projecten en toepassingen, variërend van detectie van de afbeelding tot tekstanalyse.</span><span class="sxs-lookup"><span data-stu-id="2e71e-378">It is used internally for machine learning projects and applications ranging from image detection to text analytics.</span></span> <span data-ttu-id="2e71e-379">Zie voor meer informatie [Neural netten in Azure ML - Inleiding tot Net #](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span><span class="sxs-lookup"><span data-stu-id="2e71e-379">For more information, see [Neural Nets in Azure ML - Introduction to Net#](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span></span>

<span data-ttu-id="2e71e-380">[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif</span><span class="sxs-lookup"><span data-stu-id="2e71e-380">[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif</span></span>

