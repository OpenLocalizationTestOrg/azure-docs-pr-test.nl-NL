---
title: aaaOverview van Gegevenswetenschap met Spark op Azure HDInsight | Microsoft Docs
description: Hallo Spark MLlib toolkit biedt aanzienlijke machine learning modelleren mogelijkheden toohello gedistribueerd HDInsight-omgeving.
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 515705684a46917c2741bf063d439b1cda016abb
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 10/06/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="a45d2-103">Overzicht van gegevenswetenschap met Spark op Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="a45d2-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="a45d2-104">Deze reeks onderwerpen ziet u hoe toouse HDInsight Spark toocomplete algemene gegevenswetenschap taken zoals gegevensopname, functie-engineering, modellering en evaluatie van het model.</span><span class="sxs-lookup"><span data-stu-id="a45d2-104">This suite of topics shows how toouse HDInsight Spark toocomplete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="a45d2-105">Hallo-gegevens die worden gebruikt, is een voorbeeld van Hallo 2013 NYC taxi reis en tarief gegevensset.</span><span class="sxs-lookup"><span data-stu-id="a45d2-105">hello data used is a sample of hello 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="a45d2-106">Hallo-modellen gebouwd bevatten logistic en lineaire regressie, willekeurige forests en kleurovergang gestimuleerd structuren.</span><span class="sxs-lookup"><span data-stu-id="a45d2-106">hello models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="a45d2-107">Hallo onderwerpen ook laten zien hoe toostore deze modellen in Azure blob storage (WASB) en hoe tooscore en evalueren hun voorspellende prestaties.</span><span class="sxs-lookup"><span data-stu-id="a45d2-107">hello topics also show how toostore these models in Azure blob storage (WASB) and how tooscore and evaluate their predictive performance.</span></span> <span data-ttu-id="a45d2-108">Meer geavanceerde onderwerpen wordt uitgelegd hoe modellen kunnen worden getraind met sweeping kruisvalidatie en hyper-parameter.</span><span class="sxs-lookup"><span data-stu-id="a45d2-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="a45d2-109">In dit onderwerp verwijst ook naar Hallo onderwerpen waarin wordt beschreven hoe tooset up Hallo Spark-cluster die u nodig hebt toocomplete Hallo stappen in Hallo-scenario's.</span><span class="sxs-lookup"><span data-stu-id="a45d2-109">This overview topic also references hello topics that describe how tooset up hello Spark cluster that you need toocomplete hello steps in hello walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="a45d2-110">Spark en MLlib</span><span class="sxs-lookup"><span data-stu-id="a45d2-110">Spark and MLlib</span></span>
<span data-ttu-id="a45d2-111">[Spark](http://spark.apache.org/) is een parallelle verwerking van open-source framework die ondersteuning biedt voor in het geheugen verwerkingsprestaties tooboost Hallo van analytische big data-toepassingen.</span><span class="sxs-lookup"><span data-stu-id="a45d2-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="a45d2-112">Hallo Spark-verwerkingsengine is gebouwd voor snelheid, gebruiksgemak en geavanceerde analyses.</span><span class="sxs-lookup"><span data-stu-id="a45d2-112">hello Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="a45d2-113">De Spark in-memory gedistribueerde rekencapaciteiten kunnen u een goede keuze voor Hallo zich herhalende algoritmen in machine learning- en grafiekberekeningen gebruikt.</span><span class="sxs-lookup"><span data-stu-id="a45d2-113">Spark's in-memory distributed computation capabilities make it a good choice for hello iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="a45d2-114">[MLlib](http://spark.apache.org/mllib/) is modelleren van Spark schaalbare machine learning-bibliotheek waardoor het Hallo algoritmische mogelijkheden toothis gedistribueerde omgeving.</span><span class="sxs-lookup"><span data-stu-id="a45d2-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings hello algorithmic modeling capabilities toothis distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="a45d2-115">Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="a45d2-115">HDInsight Spark</span></span>
<span data-ttu-id="a45d2-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is hello Azure gehoste aanbieden van open-source Spark.</span><span class="sxs-lookup"><span data-stu-id="a45d2-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is hello Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="a45d2-117">Biedt ook ondersteuning voor **Jupyter PySpark-notebooks** op Hallo Spark-cluster dat Spark SQL interactieve query's voor het transformeren, te filteren en visualiseren van gegevens die zijn opgeslagen in Azure BLOB's (WASB) kan worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="a45d2-117">It also includes support for **Jupyter PySpark notebooks** on hello Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="a45d2-118">PySpark is hello Python-API voor Spark.</span><span class="sxs-lookup"><span data-stu-id="a45d2-118">PySpark is hello Python API for Spark.</span></span> <span data-ttu-id="a45d2-119">Hallo-codefragmenten die Hallo-oplossingen bieden en weergeven van de relevante Hallo gegevenspunten toovisualize Hallo hier uitvoeren in Jupyter-notebooks geïnstalleerd op Hallo Spark-clusters.</span><span class="sxs-lookup"><span data-stu-id="a45d2-119">hello code snippets that provide hello solutions and show hello relevant plots toovisualize hello data here run in Jupyter notebooks installed on hello Spark clusters.</span></span> <span data-ttu-id="a45d2-120">Hallo modellering stappen in de volgende onderwerpen bevatten code die laat zien hoe tootrain, evalueren, opslaan en gebruiken van elk type model.</span><span class="sxs-lookup"><span data-stu-id="a45d2-120">hello modeling steps in these topics contain code that shows how tootrain, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="a45d2-121">Instellen: De Spark-clusters en Jupyter-notebooks</span><span class="sxs-lookup"><span data-stu-id="a45d2-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="a45d2-122">Instellingsstappen en code vindt u in dit scenario voor het gebruik van een HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="a45d2-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="a45d2-123">Maar Jupyter-notebooks zijn opgegeven voor zowel HDInsight Spark 1.6 en 2.0 Spark-clusters.</span><span class="sxs-lookup"><span data-stu-id="a45d2-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="a45d2-124">Een beschrijving van het Hallo-notitieblokken en -koppelingen toothem vindt u in Hallo [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) voor Hallo GitHub-opslagplaats met ze.</span><span class="sxs-lookup"><span data-stu-id="a45d2-124">A description of hello notebooks and links toothem are provided in hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for hello GitHub repository containing them.</span></span> <span data-ttu-id="a45d2-125">Bovendien Hallo code hier en in notitieblokken Hallo gekoppeld is algemeen en moet werken op een Spark-cluster.</span><span class="sxs-lookup"><span data-stu-id="a45d2-125">Moreover, hello code here and in hello linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="a45d2-126">Als u geen van HDInsight Spark, Hallo clusterinstallatie gebruikmaakt en management stappen mogelijk enigszins afwijken van wat hier moet worden weergegeven.</span><span class="sxs-lookup"><span data-stu-id="a45d2-126">If you are not using HDInsight Spark, hello cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="a45d2-127">Voor het gemak vindt hier u koppelingen Hallo toohello Jupyter-notebooks voor Spark 1.6 (toobe worden uitgevoerd in de pySpark-kernel Hallo Hallo Jupyter-Notebook server) en Spark 2.0 (toobe in Hallo pySpark3 kernel Hallo Jupyter-Notebook server worden uitgevoerd):</span><span class="sxs-lookup"><span data-stu-id="a45d2-127">For convenience, here are hello links toohello Jupyter notebooks for Spark 1.6 (toobe run in hello pySpark kernel of hello Jupyter Notebook server) and  Spark 2.0 (toobe run in hello pySpark3 kernel of hello Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="a45d2-128">Spark 1.6 laptops</span><span class="sxs-lookup"><span data-stu-id="a45d2-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="a45d2-129">Deze laptops zijn toobe in Hallo pySpark-kernel van Jupyter-notebook server worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="a45d2-129">These notebooks are toobe run in hello pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="a45d2-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): bevat informatie over het tooperform gegevensverkenning, modelleren en batchscoreberekening met diverse verschillende algoritmen.</span><span class="sxs-lookup"><span data-stu-id="a45d2-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how tooperform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="a45d2-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): bevat onderwerpen in de notebook #1 en de ontwikkeling van het model met hyperparameter afstemmen en kruisvalidatie.</span><span class="sxs-lookup"><span data-stu-id="a45d2-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="a45d2-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): ziet u hoe toooperationalize een opgeslagen model met behulp van Python op HDInsight-clusters.</span><span class="sxs-lookup"><span data-stu-id="a45d2-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how toooperationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="a45d2-133">Spark 2.0-laptops</span><span class="sxs-lookup"><span data-stu-id="a45d2-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="a45d2-134">Deze laptops zijn toobe in Hallo pySpark3 kernel van Jupyter-notebook server worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="a45d2-134">These notebooks are toobe run in hello pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="a45d2-135">[Spark2.0-pySpark3-machine-Learning-Data-Science-Spark-Advanced-Data-Exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): dit bestand bevat informatie over hoe tooperform gegevensverkenning, modelleren en scores in Spark 2.0 opslagclusters die gebruikmaken van Hallo NYC Taxi reis en tarief gegevensset-beschreven [hier](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="a45d2-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how tooperform data exploration, modeling, and scoring in Spark 2.0 clusters using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="a45d2-136">Deze laptop is mogelijk een goed uitgangspunt voor het snel verkennen Hallo-code die we voor Spark 2.0 hebt opgegeven.</span><span class="sxs-lookup"><span data-stu-id="a45d2-136">This notebook may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> <span data-ttu-id="a45d2-137">Voor een meer gedetailleerde notebook Hallo NYC Taxi gegevens analyseert, Zie de volgende notebook Hallo in deze lijst.</span><span class="sxs-lookup"><span data-stu-id="a45d2-137">For a more detailed notebook analyzes hello NYC Taxi data, see hello next notebook in this list.</span></span> <span data-ttu-id="a45d2-138">Zie na deze lijst Hallo-opmerkingen die deze laptops vergelijken.</span><span class="sxs-lookup"><span data-stu-id="a45d2-138">See hello notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="a45d2-139">[Spark2.0 pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): dit bestand ziet u hoe tooperform gegevens worsteling (Spark SQL en dataframe bewerkingen), exploratie, model en score berekenen met behulp van Hallo NYC Taxi reis en tarief set gegevens die worden beschreven [ Hier](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="a45d2-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="a45d2-140">[Spark2.0 pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): dit bestand ziet u hoe tooperform gegevens worsteling (Spark SQL en dataframe bewerkingen), exploratie, model en score berekenen met behulp van bekende luchtvaartmaatschappij tijdige vertrek Hallo de gegevensset van 2011 en 2012.</span><span class="sxs-lookup"><span data-stu-id="a45d2-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="a45d2-141">We Hallo luchtvaartmaatschappij gegevensset geïntegreerd met Hallo luchthaven weer gegevens (bijvoorbeeld windsnelheid, temperatuur en hoogte enz.) voorafgaande toomodeling, zodat deze weer-functies kunnen worden opgenomen in het Hallo-model.</span><span class="sxs-lookup"><span data-stu-id="a45d2-141">We integrated hello airline dataset with hello airport weather data (e.g. windspeed, temperature, altitude etc.) prior toomodeling, so these weather features can be included in hello model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="a45d2-142">Hallo luchtvaartmaatschappij dataset is toegevoegd toohello Spark 2.0 notitieblokken toobetter illustreren Hallo gebruik van de classificatie-algoritmen.</span><span class="sxs-lookup"><span data-stu-id="a45d2-142">hello airline dataset was added toohello Spark 2.0 notebooks toobetter illustrate hello use of classification algorithms.</span></span> <span data-ttu-id="a45d2-143">Zie Hallo koppelingen voor meer informatie over luchtvaartmaatschappij tijdige vertrek gegevensset en weer gegevensset te volgen:</span><span class="sxs-lookup"><span data-stu-id="a45d2-143">See hello following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="a45d2-144">Luchtvaartmaatschappij tijdige vertrek gegevens: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="a45d2-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="a45d2-145">Luchthaven weergegevens: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="a45d2-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="a45d2-146">Hallo Spark 2.0 notitieblokken op Hallo NYC taxi en luchtvaartmaatschappij vlucht vertraging-gegevenssets duurt 10 minuten of meer toorun (afhankelijk van de grootte van de Hallo van uw HDI-cluster).</span><span class="sxs-lookup"><span data-stu-id="a45d2-146">hello Spark 2.0 notebooks on hello NYC taxi and airline flight delay data-sets can take 10 mins or more toorun (depending on hello size of your HDI cluster).</span></span> <span data-ttu-id="a45d2-147">Hallo eerste laptop in Hallo boven lijst geeft veel aspecten van Hallo gegevensverkenning, visualisatie en ML-model training in een laptop die minder tijd toorun met een lagere actieve NYC gegevensset duurt, in welke Hallo taxi en tarief bestanden vooraf lid zijn: [ Spark2.0-pySpark3-machine-Learning-Data-Science-Spark-Advanced-Data-Exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) deze notebook neemt een veel kortere tijd toofinish (2-3 minuten) en kan worden een goed startpunt voor Hallo code snel verkennen we hebben opgegeven voor Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="a45d2-147">hello first notebook in hello above list shows many aspects of hello data exploration, visualization and ML model training in a notebook that takes less time toorun with down-sampled NYC data set, in which hello taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time toofinish (2-3 mins) and may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="a45d2-148">Zie voor instructies over Hallo uitoefening van een model voor Spark 2.0 en de model-verbruik voor score berekenen, Hallo [Spark 1.6 document over het verbruik](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) voor een voorbeeld waarin wordt beschreven Hallo stappen die nodig zijn.</span><span class="sxs-lookup"><span data-stu-id="a45d2-148">For guidance on hello operationalization of a Spark 2.0 model and model consumption for scoring, see hello [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining hello steps required.</span></span> <span data-ttu-id="a45d2-149">toouse op Spark 2.0, vervang Hallo Python code-bestand met [dit bestand](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="a45d2-149">toouse this on Spark 2.0, replace hello Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="a45d2-150">Vereisten</span><span class="sxs-lookup"><span data-stu-id="a45d2-150">Prerequisites</span></span>
<span data-ttu-id="a45d2-151">Hallo volgen procedures zijn verwante tooSpark 1.6.</span><span class="sxs-lookup"><span data-stu-id="a45d2-151">hello following procedures are related tooSpark 1.6.</span></span> <span data-ttu-id="a45d2-152">Voor Hallo Spark 2.0-versie: gebruik Hallo notitieblokken beschreven en toopreviously gekoppeld.</span><span class="sxs-lookup"><span data-stu-id="a45d2-152">For  hello Spark 2.0 version, use hello notebooks described and linked toopreviously.</span></span> 

<span data-ttu-id="a45d2-153">1. u moet een Azure-abonnement hebben.</span><span class="sxs-lookup"><span data-stu-id="a45d2-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="a45d2-154">Als u nog geen een, Zie [gratis proefversie van Azure ophalen](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="a45d2-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="a45d2-155">2. u moet een toocomplete 1.6 Spark-cluster in dit scenario.</span><span class="sxs-lookup"><span data-stu-id="a45d2-155">2.You need a Spark 1.6 cluster toocomplete this walkthrough.</span></span> <span data-ttu-id="a45d2-156">toocreate, Zie Hallo instructies in [aan de slag: maken van Apache Spark in Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="a45d2-156">toocreate one, see hello instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="a45d2-157">Hallo-clustertype en -versie is opgegeven vanuit Hallo **clustertype Selecteer** menu.</span><span class="sxs-lookup"><span data-stu-id="a45d2-157">hello cluster type and version is specified from hello **Select Cluster Type** menu.</span></span> 

![Cluster configureren](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="a45d2-159">Zie voor een onderwerp waarin wordt uitgelegd hoe toouse Scala in plaats van Python toocomplete taken voor een end-to-end gegevens wetenschap proces, Hallo [Gegevenswetenschap met Spark op Azure met behulp van Scala](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="a45d2-159">For a topic that shows how toouse Scala rather than Python toocomplete tasks for an end-to-end data science process, see hello [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="hello-nyc-2013-taxi-data"></a><span data-ttu-id="a45d2-160">Hallo NYC 2013 Taxi gegevens</span><span class="sxs-lookup"><span data-stu-id="a45d2-160">hello NYC 2013 Taxi data</span></span>
<span data-ttu-id="a45d2-161">Hallo NYC Taxi reis gegevens is ongeveer 20 GB gecomprimeerde door komma's gescheiden waarden (CSV)-bestanden (~ 48 GB ongecomprimeerde), die bestaat uit meer dan 173 miljoen afzonderlijke reizen en Hallo ervoor staat voor elke reis betaald.</span><span class="sxs-lookup"><span data-stu-id="a45d2-161">hello NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and hello fares paid for each trip.</span></span> <span data-ttu-id="a45d2-162">Elke record reis omvat Hallo ophalen en afgiftepunt en tijd, geanonimiseerde hack (van stuurprogramma) licentienummer, en nummer straten (taxi van unieke id).</span><span class="sxs-lookup"><span data-stu-id="a45d2-162">Each trip record includes hello pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="a45d2-163">Hallo-gegevens bevat informatie over alle reizen Hallo jaar 2013 en is beschikbaar in twee gegevenssets voor elke maand na Hallo:</span><span class="sxs-lookup"><span data-stu-id="a45d2-163">hello data covers all trips in hello year 2013 and is provided in hello following two datasets for each month:</span></span>

1. <span data-ttu-id="a45d2-164">Hallo 'trip_data' CSV-bestanden reis details, zoals het aantal passagiers bevatten, kunnen worden opgepikt en dropoff verwijst, krachtvoertuigen duur en reis lengte.</span><span class="sxs-lookup"><span data-stu-id="a45d2-164">hello 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="a45d2-165">Hier volgen enkele voorbeeldrecords:</span><span class="sxs-lookup"><span data-stu-id="a45d2-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="a45d2-166">Hallo 'trip_fare' CSV-bestanden bevatten details van Hallo tarief betaald voor elke reis, zoals betalingstype tarief bedrag, extra kosten en belastingen, tips en tolgelden en Hallo totaalbedrag betaald.</span><span class="sxs-lookup"><span data-stu-id="a45d2-166">hello 'trip_fare' CSV files contain details of hello fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and hello total amount paid.</span></span> <span data-ttu-id="a45d2-167">Hier volgen enkele voorbeeldrecords:</span><span class="sxs-lookup"><span data-stu-id="a45d2-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="a45d2-168">We hebben een steekproef 0,1% van deze bestanden en gekoppelde Hallo reis genomen\_gegevens en reis\_ritbedrag CSV-bestanden in een toouse één gegevensset als Hallo invoergegevensset voor dit scenario.</span><span class="sxs-lookup"><span data-stu-id="a45d2-168">We have taken a 0.1% sample of these files and joined hello trip\_data and trip\_fare CVS files into a single dataset toouse as hello input dataset for this walkthrough.</span></span> <span data-ttu-id="a45d2-169">Hallo unieke sleutel toojoin reis\_gegevens en reis\_tarief dat bestaat uit Hallo velden: straten, hack\_en ophalen van certificaat\_datetime.</span><span class="sxs-lookup"><span data-stu-id="a45d2-169">hello unique key toojoin trip\_data and trip\_fare is composed of hello fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="a45d2-170">Elke record van Hallo gegevensset bevat Hallo kenmerken die vertegenwoordigt een reis NYC Taxi te volgen:</span><span class="sxs-lookup"><span data-stu-id="a45d2-170">Each record of hello dataset contains hello following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="a45d2-171">Veld</span><span class="sxs-lookup"><span data-stu-id="a45d2-171">Field</span></span> | <span data-ttu-id="a45d2-172">Korte beschrijving</span><span class="sxs-lookup"><span data-stu-id="a45d2-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="a45d2-173">straten</span><span class="sxs-lookup"><span data-stu-id="a45d2-173">medallion</span></span> |<span data-ttu-id="a45d2-174">Geanonimiseerde taxi straten (taxi unieke id)</span><span class="sxs-lookup"><span data-stu-id="a45d2-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="a45d2-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="a45d2-175">hack_license</span></span> |<span data-ttu-id="a45d2-176">Geanonimiseerde Hackney regeleinde licentienummer</span><span class="sxs-lookup"><span data-stu-id="a45d2-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="a45d2-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="a45d2-177">vendor_id</span></span> |<span data-ttu-id="a45d2-178">Taxi leveranciers-id</span><span class="sxs-lookup"><span data-stu-id="a45d2-178">Taxi vendor id</span></span> |
| <span data-ttu-id="a45d2-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="a45d2-179">rate_code</span></span> |<span data-ttu-id="a45d2-180">Snelheid van de NYC taxi van tarief</span><span class="sxs-lookup"><span data-stu-id="a45d2-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="a45d2-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="a45d2-181">store_and_fwd_flag</span></span> |<span data-ttu-id="a45d2-182">Store en voorwaarts markering</span><span class="sxs-lookup"><span data-stu-id="a45d2-182">Store and forward flag</span></span> |
| <span data-ttu-id="a45d2-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="a45d2-183">pickup_datetime</span></span> |<span data-ttu-id="a45d2-184">Datum en tijd kunnen worden opgepikt</span><span class="sxs-lookup"><span data-stu-id="a45d2-184">Pick up date & time</span></span> |
| <span data-ttu-id="a45d2-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="a45d2-185">dropoff_datetime</span></span> |<span data-ttu-id="a45d2-186">Dropoff datum en tijd</span><span class="sxs-lookup"><span data-stu-id="a45d2-186">Dropoff date & time</span></span> |
| <span data-ttu-id="a45d2-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="a45d2-187">pickup_hour</span></span> |<span data-ttu-id="a45d2-188">Uur ophalen</span><span class="sxs-lookup"><span data-stu-id="a45d2-188">Pick up hour</span></span> |
| <span data-ttu-id="a45d2-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="a45d2-189">pickup_week</span></span> |<span data-ttu-id="a45d2-190">Week van jaar Hallo ophalen</span><span class="sxs-lookup"><span data-stu-id="a45d2-190">Pick up week of hello year</span></span> |
| <span data-ttu-id="a45d2-191">werkdag</span><span class="sxs-lookup"><span data-stu-id="a45d2-191">weekday</span></span> |<span data-ttu-id="a45d2-192">Werkdag (bereik 1-7)</span><span class="sxs-lookup"><span data-stu-id="a45d2-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="a45d2-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="a45d2-193">passenger_count</span></span> |<span data-ttu-id="a45d2-194">Aantal passagiers in een reis taxi</span><span class="sxs-lookup"><span data-stu-id="a45d2-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="a45d2-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="a45d2-195">trip_time_in_secs</span></span> |<span data-ttu-id="a45d2-196">Reis tijd in seconden</span><span class="sxs-lookup"><span data-stu-id="a45d2-196">Trip time in seconds</span></span> |
| <span data-ttu-id="a45d2-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="a45d2-197">trip_distance</span></span> |<span data-ttu-id="a45d2-198">Reis afstand afgelegd in mijl</span><span class="sxs-lookup"><span data-stu-id="a45d2-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="a45d2-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="a45d2-199">pickup_longitude</span></span> |<span data-ttu-id="a45d2-200">Lengtegraad ophalen</span><span class="sxs-lookup"><span data-stu-id="a45d2-200">Pick up longitude</span></span> |
| <span data-ttu-id="a45d2-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="a45d2-201">pickup_latitude</span></span> |<span data-ttu-id="a45d2-202">Breedtegraad ophalen</span><span class="sxs-lookup"><span data-stu-id="a45d2-202">Pick up latitude</span></span> |
| <span data-ttu-id="a45d2-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="a45d2-203">dropoff_longitude</span></span> |<span data-ttu-id="a45d2-204">Lengtegraad Dropoff</span><span class="sxs-lookup"><span data-stu-id="a45d2-204">Dropoff longitude</span></span> |
| <span data-ttu-id="a45d2-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="a45d2-205">dropoff_latitude</span></span> |<span data-ttu-id="a45d2-206">Dropoff breedtegraad</span><span class="sxs-lookup"><span data-stu-id="a45d2-206">Dropoff latitude</span></span> |
| <span data-ttu-id="a45d2-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="a45d2-207">direct_distance</span></span> |<span data-ttu-id="a45d2-208">Afstand tussen pick up directe en dropoff locaties</span><span class="sxs-lookup"><span data-stu-id="a45d2-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="a45d2-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="a45d2-209">payment_type</span></span> |<span data-ttu-id="a45d2-210">Betalingstype (CA's, creditcard enz.)</span><span class="sxs-lookup"><span data-stu-id="a45d2-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="a45d2-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="a45d2-211">fare_amount</span></span> |<span data-ttu-id="a45d2-212">Tarief bedrag in</span><span class="sxs-lookup"><span data-stu-id="a45d2-212">Fare amount in</span></span> |
| <span data-ttu-id="a45d2-213">Extra kosten</span><span class="sxs-lookup"><span data-stu-id="a45d2-213">surcharge</span></span> |<span data-ttu-id="a45d2-214">Extra kosten</span><span class="sxs-lookup"><span data-stu-id="a45d2-214">Surcharge</span></span> |
| <span data-ttu-id="a45d2-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="a45d2-215">mta_tax</span></span> |<span data-ttu-id="a45d2-216">MTA belasting</span><span class="sxs-lookup"><span data-stu-id="a45d2-216">Mta tax</span></span> |
| <span data-ttu-id="a45d2-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="a45d2-217">tip_amount</span></span> |<span data-ttu-id="a45d2-218">Tip bedrag</span><span class="sxs-lookup"><span data-stu-id="a45d2-218">Tip amount</span></span> |
| <span data-ttu-id="a45d2-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="a45d2-219">tolls_amount</span></span> |<span data-ttu-id="a45d2-220">Tolgelden bedrag</span><span class="sxs-lookup"><span data-stu-id="a45d2-220">Tolls amount</span></span> |
| <span data-ttu-id="a45d2-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="a45d2-221">total_amount</span></span> |<span data-ttu-id="a45d2-222">Totale hoeveelheid</span><span class="sxs-lookup"><span data-stu-id="a45d2-222">Total amount</span></span> |
| <span data-ttu-id="a45d2-223">punt</span><span class="sxs-lookup"><span data-stu-id="a45d2-223">tipped</span></span> |<span data-ttu-id="a45d2-224">Gekantelde (0/1 voor Nee of Ja)</span><span class="sxs-lookup"><span data-stu-id="a45d2-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="a45d2-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="a45d2-225">tip_class</span></span> |<span data-ttu-id="a45d2-226">Tip klasse (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span><span class="sxs-lookup"><span data-stu-id="a45d2-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-hello-spark-cluster"></a><span data-ttu-id="a45d2-227">Code van een Jupyter-notebook in Spark-cluster Hallo uitvoeren</span><span class="sxs-lookup"><span data-stu-id="a45d2-227">Execute code from a Jupyter notebook on hello Spark cluster</span></span>
<span data-ttu-id="a45d2-228">U kunt starten Hallo Jupyter-Notebook van hello Azure-portal.</span><span class="sxs-lookup"><span data-stu-id="a45d2-228">You can launch hello Jupyter Notebook from hello Azure portal.</span></span> <span data-ttu-id="a45d2-229">Zoek uw Spark-cluster op uw dashboard en klik op de pagina voor het beheer voor uw cluster tooenter.</span><span class="sxs-lookup"><span data-stu-id="a45d2-229">Find your Spark cluster on your dashboard and click it tooenter management page for your cluster.</span></span> <span data-ttu-id="a45d2-230">tooopen hello laptop die is gekoppeld aan Hallo Spark-cluster, klik op **Clusterdashboards** -> **Jupyter-Notebook** .</span><span class="sxs-lookup"><span data-stu-id="a45d2-230">tooopen hello notebook associated with hello Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Clusterdashboards](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="a45d2-232">U kunt ook te bladeren***https://CLUSTERNAME.azurehdinsight.NET/jupyter*** tooaccess Hallo Jupyter-Notebooks.</span><span class="sxs-lookup"><span data-stu-id="a45d2-232">You can also browse too***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter Notebooks.</span></span> <span data-ttu-id="a45d2-233">Hallo CLUSTERNAME deel uitmaken van deze URL vervangen door Hallo-naam van uw eigen cluster.</span><span class="sxs-lookup"><span data-stu-id="a45d2-233">Replace hello CLUSTERNAME part of this URL with hello name of your own cluster.</span></span> <span data-ttu-id="a45d2-234">Hallo-wachtwoord moet u voor uw admin-account tooaccess Hallo laptops.</span><span class="sxs-lookup"><span data-stu-id="a45d2-234">You need hello password for your admin account tooaccess hello notebooks.</span></span>

![Jupyter-Notebooks bladeren](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="a45d2-236">Selecteer PySpark toosee een map met een paar voorbeelden van vooraf verpakte laptops die gebruikmaken van de PySpark API.hello laptops die de codevoorbeelden Hallo voor dit pakket van Spark onderwerp bevatten zijn beschikbaar op Hallo [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="a45d2-236">Select PySpark toosee a directory that contains a few examples of pre-packaged notebooks that use hello PySpark API.hello notebooks that contain hello code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="a45d2-237">U kunt uploaden Hallo notitieblokken rechtstreeks vanuit [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello Jupyter-notebook server op uw Spark-cluster.</span><span class="sxs-lookup"><span data-stu-id="a45d2-237">You can upload hello notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="a45d2-238">Klik op de introductiepagina Hallo van uw Jupyter, Hallo **uploaden** knop op Hallo rechts deel uit van welkomstscherm.</span><span class="sxs-lookup"><span data-stu-id="a45d2-238">On hello home page of your Jupyter, click hello **Upload** button on hello right part of hello screen.</span></span> <span data-ttu-id="a45d2-239">Hiermee opent u een Windows Verkenner.</span><span class="sxs-lookup"><span data-stu-id="a45d2-239">It opens a file explorer.</span></span> <span data-ttu-id="a45d2-240">Hier kunt u Hallo GitHub (onbewerkte inhoud)-URL van hello laptop- en klik op Plakken **Open**.</span><span class="sxs-lookup"><span data-stu-id="a45d2-240">Here you can paste hello GitHub (raw content) URL of hello Notebook and click **Open**.</span></span> 

<span data-ttu-id="a45d2-241">U ziet Hallo-bestandsnaam in de lijst met Jupyter-bestand met een **uploaden** knop opnieuw.</span><span class="sxs-lookup"><span data-stu-id="a45d2-241">You see hello file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="a45d2-242">Klik hierop **uploaden** knop.</span><span class="sxs-lookup"><span data-stu-id="a45d2-242">Click this **Upload** button.</span></span> <span data-ttu-id="a45d2-243">U hebt nu Hallo notebook geïmporteerd.</span><span class="sxs-lookup"><span data-stu-id="a45d2-243">Now you have imported hello notebook.</span></span> <span data-ttu-id="a45d2-244">Herhaal deze stappen tooupload Hallo andere notitieblokken van dit scenario.</span><span class="sxs-lookup"><span data-stu-id="a45d2-244">Repeat these steps tooupload hello other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="a45d2-245">U kunt met de rechtermuisknop op Hallo koppelingen in de browser en selecteer **koppeling kopiëren** tooget Hallo github onbewerkte URL van inhoud.</span><span class="sxs-lookup"><span data-stu-id="a45d2-245">You can right-click hello links on your browser and select **Copy Link** tooget hello github raw content URL.</span></span> <span data-ttu-id="a45d2-246">U kunt deze URL plakken in Hallo Jupyter uploaden bestand explorer in het dialoogvenster.</span><span class="sxs-lookup"><span data-stu-id="a45d2-246">You can paste this URL into hello Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="a45d2-247">U kunt nu:</span><span class="sxs-lookup"><span data-stu-id="a45d2-247">Now you can:</span></span>

* <span data-ttu-id="a45d2-248">Hallo code door te klikken op Hallo notebook bekijken.</span><span class="sxs-lookup"><span data-stu-id="a45d2-248">See hello code by clicking hello notebook.</span></span>
* <span data-ttu-id="a45d2-249">elke cel uitvoeren door te drukken **SHIFT + ENTER**.</span><span class="sxs-lookup"><span data-stu-id="a45d2-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="a45d2-250">Hallo gehele notebook uitvoeren door te klikken op **cel** -> **uitvoeren**.</span><span class="sxs-lookup"><span data-stu-id="a45d2-250">Run hello entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="a45d2-251">Gebruik automatische visualisatie Hallo van query's.</span><span class="sxs-lookup"><span data-stu-id="a45d2-251">Use hello automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="a45d2-252">Hallo PySpark-kernel visualiseren automatisch Hallo-uitvoer van SQL (HiveQL)-query's.</span><span class="sxs-lookup"><span data-stu-id="a45d2-252">hello PySpark kernel automatically visualizes hello output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="a45d2-253">U krijgt u Hallo optie tooselect tussen verschillende soorten visualisaties (tabel-, cirkel, regel, gebied of balk) met behulp van Hallo **Type** menuknoppen in de notebook Hallo:</span><span class="sxs-lookup"><span data-stu-id="a45d2-253">You are given hello option tooselect among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using hello **Type** menu buttons in hello notebook:</span></span>
> 
> 

![Logistic regression ROC-curve voor algemene methode](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="a45d2-255">Volgende stappen</span><span class="sxs-lookup"><span data-stu-id="a45d2-255">What's next?</span></span>
<span data-ttu-id="a45d2-256">Nu u een HDInsight Spark-cluster is ingesteld en Hallo Jupyter-notebooks met licentie zijn geüpload, bent u klaar toowork door Hallo-onderwerpen die overeenkomen met toohello drie PySpark laptops.</span><span class="sxs-lookup"><span data-stu-id="a45d2-256">Now that you are set up with an HDInsight Spark cluster and have uploaded hello Jupyter notebooks, you are ready toowork through hello topics that correspond toohello three PySpark notebooks.</span></span> <span data-ttu-id="a45d2-257">Ze geven weer hoe tooexplore uw gegevens en vervolgens het toocreate en modellen in beslag nemen.</span><span class="sxs-lookup"><span data-stu-id="a45d2-257">They show how tooexplore your data and then how toocreate and consume models.</span></span> <span data-ttu-id="a45d2-258">Hallo geavanceerde gegevensverkenning en laptop toont hoe modelleren tooinclude kruisvalidatie, hyper-parameter sweeping en evaluatie van het model.</span><span class="sxs-lookup"><span data-stu-id="a45d2-258">hello advanced data exploration and modeling notebook shows how tooinclude cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="a45d2-259">**Gegevensverkenning en modellering met Spark:** Hallo gegevensset verkennen en maken, beoordelen en evalueren Hallo machine learning-modellen doorloopt Hallo [binaire classificatie en regressie modellen voor gegevens met Hallo Spark maken MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) onderwerp.</span><span class="sxs-lookup"><span data-stu-id="a45d2-259">**Data Exploration and modeling with Spark:** Explore hello dataset and create, score, and evaluate hello machine learning models by working through hello [Create binary classification and regression models for data with hello Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="a45d2-260">**Model verbruik:** toolearn hoe tooscore Hallo classificatie en regressie modellen gemaakt in dit onderwerp raadpleegt [Score en evalueren van Spark is gebouwd machine learning-modellen](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="a45d2-260">**Model consumption:** toolearn how tooscore hello classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="a45d2-261">**Kruisvalidatie en hyperparameter sweeping**: Zie [geavanceerde gegevensverkenning en modellering met Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) over de manier waarop modellen kunnen getraind met behulp van kruisvalidatie en hyper-parameter sweeping</span><span class="sxs-lookup"><span data-stu-id="a45d2-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

