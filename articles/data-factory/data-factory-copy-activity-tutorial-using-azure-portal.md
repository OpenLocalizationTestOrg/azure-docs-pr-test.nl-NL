---
title: "Zelfstudie: een Azure Data Factory-pijplijn maken om gegevens te kopiëren (Azure Portal) | Microsoft Docs"
description: "In deze zelfstudie gebruikt u Azure Portal om een Azure Data Factory-pijplijn te maken met een kopieeractiviteit om gegevens uit een Azure-blobopslag naar een Azure SQL-database te kopiëren."
services: data-factory
documentationcenter: 
author: spelluru
manager: jhubbard
editor: monicar
ms.assetid: d9317652-0170-4fd3-b9b2-37711272162b
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 07/10/2017
ms.author: spelluru
ms.openlocfilehash: 8072a863fab0b304ccbbba639aa56b403e8f37c7
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/03/2017
---
# <a name="tutorial-use-azure-portal-to-create-a-data-factory-pipeline-to-copy-data"></a><span data-ttu-id="af32b-103">Zelfstudie: Azure Portal gebruiken voor het maken van een Data Factory-pijplijn om gegevens te kopiëren</span><span class="sxs-lookup"><span data-stu-id="af32b-103">Tutorial: Use Azure portal to create a Data Factory pipeline to copy data</span></span> 
> [!div class="op_single_selector"]
> * [<span data-ttu-id="af32b-104">Overzicht en vereisten</span><span class="sxs-lookup"><span data-stu-id="af32b-104">Overview and prerequisites</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md)
> * [<span data-ttu-id="af32b-105">De wizard Kopiëren</span><span class="sxs-lookup"><span data-stu-id="af32b-105">Copy Wizard</span></span>](data-factory-copy-data-wizard-tutorial.md)
> * [<span data-ttu-id="af32b-106">Azure Portal</span><span class="sxs-lookup"><span data-stu-id="af32b-106">Azure portal</span></span>](data-factory-copy-activity-tutorial-using-azure-portal.md)
> * [<span data-ttu-id="af32b-107">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="af32b-107">Visual Studio</span></span>](data-factory-copy-activity-tutorial-using-visual-studio.md)
> * [<span data-ttu-id="af32b-108">PowerShell</span><span class="sxs-lookup"><span data-stu-id="af32b-108">PowerShell</span></span>](data-factory-copy-activity-tutorial-using-powershell.md)
> * [<span data-ttu-id="af32b-109">Azure Resource Manager-sjabloon</span><span class="sxs-lookup"><span data-stu-id="af32b-109">Azure Resource Manager template</span></span>](data-factory-copy-activity-tutorial-using-azure-resource-manager-template.md)
> * [<span data-ttu-id="af32b-110">REST API</span><span class="sxs-lookup"><span data-stu-id="af32b-110">REST API</span></span>](data-factory-copy-activity-tutorial-using-rest-api.md)
> * [<span data-ttu-id="af32b-111">.NET-API</span><span class="sxs-lookup"><span data-stu-id="af32b-111">.NET API</span></span>](data-factory-copy-activity-tutorial-using-dotnet-api.md)
> 
> 

<span data-ttu-id="af32b-112">In dit artikel leert u hoe u [Azure Portal](https://portal.azure.com) kunt gebruiken om een gegevensfactory te maken met een pijplijn waarmee gegevens worden gekopieerd van een Azure blobopslag naar een Azure SQL-database.</span><span class="sxs-lookup"><span data-stu-id="af32b-112">In this article, you learn how to use [Azure portal](https://portal.azure.com) to create a data factory with a pipeline that copies data from an Azure blob storage to an Azure SQL database.</span></span> <span data-ttu-id="af32b-113">Als u niet bekend bent met Azure Data Factory, lees dan het artikel [Inleiding tot Azure Data Factory](data-factory-introduction.md) voordat u deze zelfstudie volgt.</span><span class="sxs-lookup"><span data-stu-id="af32b-113">If you are new to Azure Data Factory, read through the [Introduction to Azure Data Factory](data-factory-introduction.md) article before doing this tutorial.</span></span>   

<span data-ttu-id="af32b-114">In deze zelfstudie maakt u een pijplijn met één activiteit erin: kopieeractiviteit.</span><span class="sxs-lookup"><span data-stu-id="af32b-114">In this tutorial, you create a pipeline with one activity in it: Copy Activity.</span></span> <span data-ttu-id="af32b-115">De kopieeractiviteit in Data Factory kopieert gegevens uit een ondersteund gegevensarchief naar een ondersteund sinkgegevensarchief.</span><span class="sxs-lookup"><span data-stu-id="af32b-115">The copy activity copies data from a supported data store to a supported sink data store.</span></span> <span data-ttu-id="af32b-116">Zie [Ondersteunde gegevensarchieven](data-factory-data-movement-activities.md#supported-data-stores-and-formats) voor een lijst met gegevensarchieven die worden ondersteund als bron en als sink.</span><span class="sxs-lookup"><span data-stu-id="af32b-116">For a list of data stores supported as sources and sinks, see [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span></span> <span data-ttu-id="af32b-117">De activiteit wordt mogelijk gemaakt door een wereldwijd beschikbare service waarmee gegevens veilig, betrouwbaar en schaalbaar kunnen worden gekopieerd tussen verschillende gegevensarchieven.</span><span class="sxs-lookup"><span data-stu-id="af32b-117">The activity is powered by a globally available service that can copy data between various data stores in a secure, reliable, and scalable way.</span></span> <span data-ttu-id="af32b-118">Zie het artikel [Activiteiten voor gegevensverplaatsing](data-factory-data-movement-activities.md) voor meer informatie over kopieeractiviteiten.</span><span class="sxs-lookup"><span data-stu-id="af32b-118">For more information about the Copy Activity, see [Data Movement Activities](data-factory-data-movement-activities.md).</span></span>

<span data-ttu-id="af32b-119">Een pijplijn kan meer dan één activiteit hebben.</span><span class="sxs-lookup"><span data-stu-id="af32b-119">A pipeline can have more than one activity.</span></span> <span data-ttu-id="af32b-120">Ook kunt u twee activiteiten koppelen (de ene activiteit na de andere laten uitvoeren) door de uitvoergegevensset van één activiteit in te stellen als invoergegevensset voor een andere activiteit.</span><span class="sxs-lookup"><span data-stu-id="af32b-120">And, you can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="af32b-121">Zie [Meerdere activiteiten in een pijplijn](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="af32b-121">For more information, see [multiple activities in a pipeline](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline).</span></span> 

> [!NOTE] 
> <span data-ttu-id="af32b-122">In de gegevenspijplijn in deze zelfstudie worden gegevens van een brongegevensarchief gekopieerd naar een doelgegevensarchief.</span><span class="sxs-lookup"><span data-stu-id="af32b-122">The data pipeline in this tutorial copies data from a source data store to a destination data store.</span></span> <span data-ttu-id="af32b-123">Zie [Zelfstudie: een pijplijn maken om gegevens te transformeren met een Hadoop-cluster](data-factory-build-your-first-pipeline.md) voor meer informatie over het transformeren van gegevens met Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="af32b-123">For a tutorial on how to transform data using Azure Data Factory, see [Tutorial: Build a pipeline to transform data using Hadoop cluster](data-factory-build-your-first-pipeline.md).</span></span>

## <a name="prerequisites"></a><span data-ttu-id="af32b-124">Vereisten</span><span class="sxs-lookup"><span data-stu-id="af32b-124">Prerequisites</span></span>
<span data-ttu-id="af32b-125">U dient eerst te voldoen aan de vereisten in het artikel [Vereisten voor de zelfstudie](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) voordat u deze zelfstudie volgt.</span><span class="sxs-lookup"><span data-stu-id="af32b-125">Complete prerequisites listed in the [tutorial prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) article before performing this tutorial.</span></span>

## <a name="steps"></a><span data-ttu-id="af32b-126">Stappen</span><span class="sxs-lookup"><span data-stu-id="af32b-126">Steps</span></span>
<span data-ttu-id="af32b-127">Hier volgen de stappen die u uitvoert als onderdeel van deze zelfstudie:</span><span class="sxs-lookup"><span data-stu-id="af32b-127">Here are the steps you perform as part of this tutorial:</span></span>

1. <span data-ttu-id="af32b-128">Een Azure-**gegevensfactory** maken.</span><span class="sxs-lookup"><span data-stu-id="af32b-128">Create an Azure **data factory**.</span></span> <span data-ttu-id="af32b-129">In deze stap maakt u een gegevensfactory met de naam ADFTutorialDataFactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-129">In this step, you create a data factory named ADFTutorialDataFactory.</span></span> 
2. <span data-ttu-id="af32b-130">**Gekoppelde services** maken in de gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-130">Create **linked services** in the data factory.</span></span> <span data-ttu-id="af32b-131">In deze stap maakt u twee gekoppelde services van het type: Azure Storage en Azure SQL Database.</span><span class="sxs-lookup"><span data-stu-id="af32b-131">In this step, you create two linked services of types: Azure Storage and Azure SQL Database.</span></span> 
    
    <span data-ttu-id="af32b-132">De AzureStorageLinkedService koppelt uw Azure-opslagaccount aan de gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-132">The AzureStorageLinkedService links your Azure storage account to the data factory.</span></span> <span data-ttu-id="af32b-133">U hebt een container gemaakt en gegevens naar dit opslagaccount geüpload als onderdeel van de [vereisten](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="af32b-133">You created a container and uploaded data to this storage account as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>   

    <span data-ttu-id="af32b-134">De AzureSqlLinkedService koppelt uw Azure SQL-database aan de gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-134">AzureSqlLinkedService links your Azure SQL database to the data factory.</span></span> <span data-ttu-id="af32b-135">De gegevens die worden gekopieerd uit de blobopslag worden opgeslagen in deze database.</span><span class="sxs-lookup"><span data-stu-id="af32b-135">The data that is copied from the blob storage is stored in this database.</span></span> <span data-ttu-id="af32b-136">Als onderdeel van de [vereisten](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) hebt u een SQL-tabel in deze database gemaakt.</span><span class="sxs-lookup"><span data-stu-id="af32b-136">You created a SQL table in this database as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>   
3. <span data-ttu-id="af32b-137">Maak **invoer- en uitvoergegevenssets** in de gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-137">Create input and output **datasets** in the data factory.</span></span>  
    
    <span data-ttu-id="af32b-138">De gekoppelde Azure Storage-service geeft de verbindingsreeks op die de Data Factory-service tijdens runtime gebruikt om verbinding te maken met uw Azure-opslagaccount.</span><span class="sxs-lookup"><span data-stu-id="af32b-138">The Azure storage linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure storage account.</span></span> <span data-ttu-id="af32b-139">En de blobgegevensset voor invoer geeft de container en de map met de invoergegevens op.</span><span class="sxs-lookup"><span data-stu-id="af32b-139">And, the input blob dataset specifies the container and the folder that contains the input data.</span></span>  

    <span data-ttu-id="af32b-140">Op dezelfde manier geeft de gekoppelde Azure SQL Database-service de verbindingsreeks op die de Data Factory-service in runtime gebruikt om verbinding te maken met uw Azure SQL-database.</span><span class="sxs-lookup"><span data-stu-id="af32b-140">Similarly, the Azure SQL Database linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure SQL database.</span></span> <span data-ttu-id="af32b-141">En de uitvoergegevensset van de SQL-tabel geeft de tabel in de database op waarnaar de gegevens uit de blobopslag worden gekopieerd.</span><span class="sxs-lookup"><span data-stu-id="af32b-141">And, the output SQL table dataset specifies the table in the database to which the data from the blob storage is copied.</span></span>
4. <span data-ttu-id="af32b-142">Maak een **pijplijn** in de gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-142">Create a **pipeline** in the data factory.</span></span> <span data-ttu-id="af32b-143">In deze stap maakt u een pijplijn met een kopieeractiviteit.</span><span class="sxs-lookup"><span data-stu-id="af32b-143">In this step, you create a pipeline with a copy activity.</span></span>   
    
    <span data-ttu-id="af32b-144">Met de kopieeractiviteit worden gegevens uit een blob in de Azure-blobopslag naar een tabel in de Azure SQL-database gekopieerd.</span><span class="sxs-lookup"><span data-stu-id="af32b-144">The copy activity copies data from a blob in the Azure blob storage to a table in the Azure SQL database.</span></span> <span data-ttu-id="af32b-145">U kunt een kopieeractiviteit gebruiken in een pijplijn om gegevens uit ondersteunde bronnen te kopiëren naar een ondersteunde bestemming.</span><span class="sxs-lookup"><span data-stu-id="af32b-145">You can use a copy activity in a pipeline to copy data from any supported source to any supported destination.</span></span> <span data-ttu-id="af32b-146">Zie het artikel [Activiteiten voor gegevensverplaatsing](data-factory-data-movement-activities.md#supported-data-stores-and-formats) voor een lijst met ondersteunde gegevensarchieven.</span><span class="sxs-lookup"><span data-stu-id="af32b-146">For a list of supported data stores, see [data movement activities](data-factory-data-movement-activities.md#supported-data-stores-and-formats) article.</span></span> 
5. <span data-ttu-id="af32b-147">Bewaak de pijplijn.</span><span class="sxs-lookup"><span data-stu-id="af32b-147">Monitor the pipeline.</span></span> <span data-ttu-id="af32b-148">In deze stap **bewaakt** u segmenten van de invoer- en uitvoergegevenssets met behulp van Azure Portal.</span><span class="sxs-lookup"><span data-stu-id="af32b-148">In this step, you **monitor** the slices of input and output datasets by using Azure portal.</span></span> 

## <a name="create-data-factory"></a><span data-ttu-id="af32b-149">Een gegevensfactory maken</span><span class="sxs-lookup"><span data-stu-id="af32b-149">Create data factory</span></span>
> [!IMPORTANT]
> <span data-ttu-id="af32b-150">Voldoe aan de [vereisten voor de zelfstudie](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) als u dat nog niet hebt gedaan.</span><span class="sxs-lookup"><span data-stu-id="af32b-150">Complete [prerequisites for the tutorial](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) if you haven't already done so.</span></span>   

<span data-ttu-id="af32b-151">Een gegevensfactory kan één of meer pijplijnen hebben.</span><span class="sxs-lookup"><span data-stu-id="af32b-151">A data factory can have one or more pipelines.</span></span> <span data-ttu-id="af32b-152">Een pijplijn kan één of meer activiteiten bevatten.</span><span class="sxs-lookup"><span data-stu-id="af32b-152">A pipeline can have one or more activities in it.</span></span> <span data-ttu-id="af32b-153">Bijvoorbeeld een kopieeractiviteit om gegevens van een bron- naar een doelgegevensopslagplaats te kopiëren en een HDInsight Hive-activiteit om een Hive-script uit te voeren voor het transformeren van invoergegevens naar productuitvoergegevens.</span><span class="sxs-lookup"><span data-stu-id="af32b-153">For example, a Copy Activity to copy data from a source to a destination data store and a HDInsight Hive activity to run a Hive script to transform input data to product output data.</span></span> <span data-ttu-id="af32b-154">U begint in deze stap met het maken van de gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-154">Let's start with creating the data factory in this step.</span></span>

1. <span data-ttu-id="af32b-155">Meld u aan bij [Azure Portal](https://portal.azure.com/) en klik op **Nieuw** in het menu links. Selecteer **Gegevensanalyse** en klik op **Data Factory**.</span><span class="sxs-lookup"><span data-stu-id="af32b-155">After logging in to the [Azure portal](https://portal.azure.com/), click **New** on the left menu, click **Data + Analytics**, and click **Data Factory**.</span></span> 
   
   ![Nieuw -> DataFactory](./media/data-factory-copy-activity-tutorial-using-azure-portal/NewDataFactoryMenu.png)    
2. <span data-ttu-id="af32b-157">In de blade **Nieuwe gegevensfactory**:</span><span class="sxs-lookup"><span data-stu-id="af32b-157">In the **New data factory** blade:</span></span>
   
   1. <span data-ttu-id="af32b-158">Voer **ADFTutorialDataFactory** in als **naam**.</span><span class="sxs-lookup"><span data-stu-id="af32b-158">Enter **ADFTutorialDataFactory** for the **name**.</span></span> 
      
         ![Blade voor een nieuwe gegevensfactory](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-new-data-factory.png)
      
       <span data-ttu-id="af32b-160">De naam van de Azure-gegevensfactory moet **wereldwijd uniek** zijn.</span><span class="sxs-lookup"><span data-stu-id="af32b-160">The name of the Azure data factory must be **globally unique**.</span></span> <span data-ttu-id="af32b-161">Als u het volgende foutbericht krijgt, wijzigt u de naam van de gegevensfactory (bijvoorbeeld uwnaamADFTutorialDataFactory) en probeert u het opnieuw.</span><span class="sxs-lookup"><span data-stu-id="af32b-161">If you receive the following error, change the name of the data factory (for example, yournameADFTutorialDataFactory) and try creating again.</span></span> <span data-ttu-id="af32b-162">Raadpleeg het onderwerp [Data Factory - Naamgevingsregels](data-factory-naming-rules.md) voor meer informatie over naamgevingsregels voor Data Factory-artefacten.</span><span class="sxs-lookup"><span data-stu-id="af32b-162">See [Data Factory - Naming Rules](data-factory-naming-rules.md) topic for naming rules for Data Factory artifacts.</span></span>
      
           Data factory name “ADFTutorialDataFactory” is not available  
      
       ![Naam van gegevensfactory niet beschikbaar](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-data-factory-not-available.png)
   2. <span data-ttu-id="af32b-164">Selecteer het Azure-**abonnement** waarin u de gegevensfactory wilt maken.</span><span class="sxs-lookup"><span data-stu-id="af32b-164">Select your Azure **subscription** in which you want to create the data factory.</span></span> 
   3. <span data-ttu-id="af32b-165">Voer een van de volgende stappen uit voor de **Resourcegroep**:</span><span class="sxs-lookup"><span data-stu-id="af32b-165">For the **Resource Group**, do one of the following steps:</span></span>
      
      - <span data-ttu-id="af32b-166">Selecteer **Bestaande gebruiken** en selecteer een bestaande resourcegroep in de vervolgkeuzelijst.</span><span class="sxs-lookup"><span data-stu-id="af32b-166">Select **Use existing**, and select an existing resource group from the drop-down list.</span></span> 
      - <span data-ttu-id="af32b-167">Selecteer **Nieuwe maken** en voer de naam van een resourcegroep in.</span><span class="sxs-lookup"><span data-stu-id="af32b-167">Select **Create new**, and enter the name of a resource group.</span></span>   
         
          <span data-ttu-id="af32b-168">Voor sommige van de stappen in deze zelfstudie wordt ervan uitgegaan dat u voor de resourcegroep de naam **ADFTutorialResourceGroup** gebruikt.</span><span class="sxs-lookup"><span data-stu-id="af32b-168">Some of the steps in this tutorial assume that you use the name: **ADFTutorialResourceGroup** for the resource group.</span></span> <span data-ttu-id="af32b-169">Zie [Resourcegroepen gebruiken om Azure-resources te beheren](../azure-resource-manager/resource-group-overview.md) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="af32b-169">To learn about resource groups, see [Using resource groups to manage your Azure resources](../azure-resource-manager/resource-group-overview.md).</span></span>  
   4. <span data-ttu-id="af32b-170">Selecteer de **locatie** voor de gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-170">Select the **location** for the data factory.</span></span> <span data-ttu-id="af32b-171">Alleen regio's die worden ondersteund door de Data Factory-service worden weergegeven in de vervolgkeuzelijst.</span><span class="sxs-lookup"><span data-stu-id="af32b-171">Only regions supported by the Data Factory service are shown in the drop-down list.</span></span>
   5. <span data-ttu-id="af32b-172">Selecteer **Vastmaken aan dashboard**.</span><span class="sxs-lookup"><span data-stu-id="af32b-172">Select **Pin to dashboard**.</span></span>     
   6. <span data-ttu-id="af32b-173">Klik op **Create**.</span><span class="sxs-lookup"><span data-stu-id="af32b-173">Click **Create**.</span></span>
      
      > [!IMPORTANT]
      > <span data-ttu-id="af32b-174">Als u Data Factory-exemplaren wilt maken, moet u lid zijn van de rol [Inzender Data Factory](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) op abonnements-/resourcegroepsniveau.</span><span class="sxs-lookup"><span data-stu-id="af32b-174">To create Data Factory instances, you must be a member of the [Data Factory Contributor](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) role at the subscription/resource group level.</span></span>
      > 
      > <span data-ttu-id="af32b-175">De naam van de gegevensfactory wordt in de toekomst mogelijk geregistreerd als DNS-naam en wordt daarmee ook voor iedereen zichtbaar.</span><span class="sxs-lookup"><span data-stu-id="af32b-175">The name of the data factory may be registered as a DNS name in the future and hence become publically visible.</span></span>                
      > 
      > 
3. <span data-ttu-id="af32b-176">Op het dashboard ziet u de volgende tegel met de status: **Gegevensfactory implementeren**.</span><span class="sxs-lookup"><span data-stu-id="af32b-176">On the dashboard, you see the following tile with status: **Deploying data factory**.</span></span> 

    ![tegel met de status 'gegevensfactory implementeren'](media/data-factory-copy-activity-tutorial-using-azure-portal/deploying-data-factory.png)
4. <span data-ttu-id="af32b-178">Wanneer het maken is voltooid, ziet u de blade **Data Factory** zoals in de afbeelding is weergegeven.</span><span class="sxs-lookup"><span data-stu-id="af32b-178">After the creation is complete, you see the **Data Factory** blade as shown in the image.</span></span>
   
   ![Startpagina van de gegevensfactory](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-data-factory-home-page.png)

## <a name="create-linked-services"></a><span data-ttu-id="af32b-180">Gekoppelde services maken</span><span class="sxs-lookup"><span data-stu-id="af32b-180">Create linked services</span></span>
<span data-ttu-id="af32b-181">U maakt gekoppelde services in een gegevensfactory om uw gegevensarchieven en compute-services aan de gegevensfactory te koppelen.</span><span class="sxs-lookup"><span data-stu-id="af32b-181">You create linked services in a data factory to link your data stores and compute services to the data factory.</span></span> <span data-ttu-id="af32b-182">In deze zelfstudie gebruikt u niet een willekeurige compute-service, zoals Azure HDInsight of Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="af32b-182">In this tutorial, you don't use any compute service such as Azure HDInsight or Azure Data Lake Analytics.</span></span> <span data-ttu-id="af32b-183">U gebruikt twee gegevensarchieven van het type Azure Storage (bron) en Azure SQL Database (doel).</span><span class="sxs-lookup"><span data-stu-id="af32b-183">You use two data stores of type Azure Storage (source) and Azure SQL Database (destination).</span></span> 

<span data-ttu-id="af32b-184">Daarom maakt u twee gekoppelde services met de naam AzureStorageLinkedService en AzureSqlLinkedService van het type: AzureStorage en AzureSqlDatabase.</span><span class="sxs-lookup"><span data-stu-id="af32b-184">Therefore, you create two linked services named AzureStorageLinkedService and AzureSqlLinkedService of types: AzureStorage and AzureSqlDatabase.</span></span>  

<span data-ttu-id="af32b-185">De AzureStorageLinkedService koppelt uw Azure-opslagaccount aan de gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-185">The AzureStorageLinkedService links your Azure storage account to the data factory.</span></span> <span data-ttu-id="af32b-186">Dit opslagaccount is het account waarin u een container hebt gemaakt en gegevens hebt geüpload als onderdeel van de [vereisten](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="af32b-186">This storage account is the one in which you created a container and uploaded the data as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>   

<span data-ttu-id="af32b-187">De AzureSqlLinkedService koppelt uw Azure SQL-database aan de gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-187">AzureSqlLinkedService links your Azure SQL database to the data factory.</span></span> <span data-ttu-id="af32b-188">De gegevens die worden gekopieerd uit de blobopslag worden opgeslagen in deze database.</span><span class="sxs-lookup"><span data-stu-id="af32b-188">The data that is copied from the blob storage is stored in this database.</span></span> <span data-ttu-id="af32b-189">Als onderdeel van de [vereisten](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) hebt u de emp-tabel in deze database gemaakt.</span><span class="sxs-lookup"><span data-stu-id="af32b-189">You created the emp table in this database as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>  

### <a name="create-azure-storage-linked-service"></a><span data-ttu-id="af32b-190">Een gekoppelde Azure Storage-service maken</span><span class="sxs-lookup"><span data-stu-id="af32b-190">Create Azure Storage linked service</span></span>
<span data-ttu-id="af32b-191">In deze stap koppelt u uw Azure Storage-account aan uw gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-191">In this step, you link your Azure storage account to your data factory.</span></span> <span data-ttu-id="af32b-192">In deze sectie geeft u de naam en sleutel van uw Azure Storage-account op.</span><span class="sxs-lookup"><span data-stu-id="af32b-192">You specify the name and key of your Azure storage account in this section.</span></span>  

1. <span data-ttu-id="af32b-193">Klik op de blade **Data Factory** op **Maken en implementeren**.</span><span class="sxs-lookup"><span data-stu-id="af32b-193">In the **Data Factory** blade, click **Author and deploy** tile.</span></span>
   
   ![Tegel Ontwerpen en implementeren](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-author-deploy-tile.png) 
2. <span data-ttu-id="af32b-195">U ziet de **Data Factory-Editor** zoals weergegeven op de volgende afbeelding:</span><span class="sxs-lookup"><span data-stu-id="af32b-195">You see the **Data Factory Editor** as shown in the following image:</span></span> 

    ![Data Factory Editor](./media/data-factory-copy-activity-tutorial-using-azure-portal/data-factory-editor.png)
3. <span data-ttu-id="af32b-197">Klik in de editor op de knop **Nieuw gegevensarchief** op de werkbalk en selecteer **Azure Storage** in de vervolgkeuzelijst.</span><span class="sxs-lookup"><span data-stu-id="af32b-197">In the editor, click **New data store** button on the toolbar and select **Azure storage** from the drop-down menu.</span></span> <span data-ttu-id="af32b-198">U ziet het JSON-sjabloon voor het maken van een gekoppelde Azure-service in het rechterdeelvenster.</span><span class="sxs-lookup"><span data-stu-id="af32b-198">You should see the JSON template for creating an Azure storage linked service in the right pane.</span></span> 
   
    ![Knop Nieuw gegevensarchief in de editor](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-newdatastore-button.png)    
3. <span data-ttu-id="af32b-200">Vervang `<accountname>` en `<accountkey>` door de naam van uw account en de accountsleutel van uw Azure-opslagaccount.</span><span class="sxs-lookup"><span data-stu-id="af32b-200">Replace `<accountname>` and `<accountkey>` with the account name and account key values for your Azure storage account.</span></span> 
   
    ![JSON voor Blob Storage in de editor](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-blob-storage-json.png)    
4. <span data-ttu-id="af32b-202">Klik op **Implementeren** op de werkbalk.</span><span class="sxs-lookup"><span data-stu-id="af32b-202">Click **Deploy** on the toolbar.</span></span> <span data-ttu-id="af32b-203">De geïmplementeerde **AzureStorageLinkedService** wordt nu in de structuurweergave weergeven.</span><span class="sxs-lookup"><span data-stu-id="af32b-203">You should see the deployed **AzureStorageLinkedService** in the tree view now.</span></span> 
   
    ![Blob Storage implementeren in de editor](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-blob-storage-deploy.png)

    <span data-ttu-id="af32b-205">Zie het artikel [Azure Blob Storage-connector](data-factory-azure-blob-connector.md#linked-service-properties) voor meer informatie over de JSON-eigenschappen in de definitie van de gekoppelde service.</span><span class="sxs-lookup"><span data-stu-id="af32b-205">For more information about JSON properties in the linked service definition, see [Azure Blob Storage connector](data-factory-azure-blob-connector.md#linked-service-properties) article.</span></span>

### <a name="create-a-linked-service-for-the-azure-sql-database"></a><span data-ttu-id="af32b-206">Een gekoppelde service maken voor de Azure SQL Database</span><span class="sxs-lookup"><span data-stu-id="af32b-206">Create a linked service for the Azure SQL Database</span></span>
<span data-ttu-id="af32b-207">In deze stap koppelt u uw Azure SQL Database aan uw gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-207">In this step, you link your Azure SQL database to your data factory.</span></span> <span data-ttu-id="af32b-208">U geeft in deze sectie de Azure SQL-servernaam, -databasenaam, -gebruikersnaam en -wachtwoord op.</span><span class="sxs-lookup"><span data-stu-id="af32b-208">You specify the Azure SQL server name, database name, user name, and user password in this section.</span></span> 

1. <span data-ttu-id="af32b-209">In de **Data Factory-editor** klikt u op **Nieuw gegevensarchief** op de werkbalk en selecteert u **Azure SQL Database** uit de vervolgkeuzelijst.</span><span class="sxs-lookup"><span data-stu-id="af32b-209">In the **Data Factory Editor**, click **New data store** button on the toolbar and select **Azure SQL Database** from the drop-down menu.</span></span> <span data-ttu-id="af32b-210">U ziet het JSON-sjabloon voor het maken van een gekoppelde Azure SQL-service in het rechterdeelvenster.</span><span class="sxs-lookup"><span data-stu-id="af32b-210">You should see the JSON template for creating the Azure SQL linked service in the right pane.</span></span>
2. <span data-ttu-id="af32b-211">Vervang `<servername>`, `<databasename>`, `<username>@<servername>` en `<password>` door de namen van uw Azure SQL-server, -database en -gebruikersaccount en voer uw wachtwoord in.</span><span class="sxs-lookup"><span data-stu-id="af32b-211">Replace `<servername>`, `<databasename>`, `<username>@<servername>`, and `<password>` with names of your Azure SQL server, database, user account, and password.</span></span> 
3. <span data-ttu-id="af32b-212">Klik op **Implementeren** op de werkbalk om **AzureSqlLinkedService** te maken en te implementeren.</span><span class="sxs-lookup"><span data-stu-id="af32b-212">Click **Deploy** on the toolbar to create and deploy the **AzureSqlLinkedService**.</span></span>
4. <span data-ttu-id="af32b-213">Bevestig dat **AzureSqlLinkedService** in de structuurweergave onder **Gekoppelde services** wordt weergegeven.</span><span class="sxs-lookup"><span data-stu-id="af32b-213">Confirm that you see **AzureSqlLinkedService** in the tree view under **Linked services**.</span></span>  

    <span data-ttu-id="af32b-214">Zie [Azure SQL Database-connector](data-factory-azure-sql-connector.md#linked-service-properties) voor meer informatie over deze JSON-eigenschappen.</span><span class="sxs-lookup"><span data-stu-id="af32b-214">For more information about these JSON properties, see [Azure SQL Database connector](data-factory-azure-sql-connector.md#linked-service-properties).</span></span>

## <a name="create-datasets"></a><span data-ttu-id="af32b-215">Gegevenssets maken</span><span class="sxs-lookup"><span data-stu-id="af32b-215">Create datasets</span></span>
<span data-ttu-id="af32b-216">In de vorige stap hebt u gekoppelde services gemaakt om uw Azure-opslagaccount en Azure SQL-database aan de gegevensfactory te koppelen.</span><span class="sxs-lookup"><span data-stu-id="af32b-216">In the previous step, you created linked services to link your Azure Storage account and Azure SQL database to your data factory.</span></span> <span data-ttu-id="af32b-217">In deze stap definieert u twee gegevenssets, InputDataset en OutputDataset genaamd, die staan voor de invoer- en uitvoergegevens die zijn opgeslagen in de gegevensarchieven waarnaar wordt verwezen door respectievelijk de AzureStorageLinkedService en de AzureSqlLinkedService.</span><span class="sxs-lookup"><span data-stu-id="af32b-217">In this step, you define two datasets named InputDataset and OutputDataset that represent input and output data that is stored in the data stores referred by AzureStorageLinkedService and AzureSqlLinkedService respectively.</span></span>

<span data-ttu-id="af32b-218">De gekoppelde Azure Storage-service geeft de verbindingsreeks op die de Data Factory-service tijdens runtime gebruikt om verbinding te maken met uw Azure-opslagaccount.</span><span class="sxs-lookup"><span data-stu-id="af32b-218">The Azure storage linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure storage account.</span></span> <span data-ttu-id="af32b-219">En de blobgegevensset voor invoer (InputDataset) geeft de container en de map met de invoergegevens op.</span><span class="sxs-lookup"><span data-stu-id="af32b-219">And, the input blob dataset (InputDataset) specifies the container and the folder that contains the input data.</span></span>  

<span data-ttu-id="af32b-220">Op dezelfde manier geeft de gekoppelde Azure SQL Database-service de verbindingsreeks op die de Data Factory-service in runtime gebruikt om verbinding te maken met uw Azure SQL-database.</span><span class="sxs-lookup"><span data-stu-id="af32b-220">Similarly, the Azure SQL Database linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure SQL database.</span></span> <span data-ttu-id="af32b-221">En de uitvoergegevensset van de SQL-tabel (OututDataset) geeft de tabel in de database op waarnaar de gegevens uit de blobopslag worden gekopieerd.</span><span class="sxs-lookup"><span data-stu-id="af32b-221">And, the output SQL table dataset (OututDataset) specifies the table in the database to which the data from the blob storage is copied.</span></span> 

### <a name="create-input-dataset"></a><span data-ttu-id="af32b-222">Invoergegevensset maken</span><span class="sxs-lookup"><span data-stu-id="af32b-222">Create input dataset</span></span>
<span data-ttu-id="af32b-223">In deze stap maakt u een gegevensset met de naam InputDataset die verwijst naar een blobbestand (emp.txt) in de hoofdmap van een blobcontainer (adftutorial) in Azure Storage. Deze container wordt vertegenwoordigd door de gekoppelde AzureStorageLinkedService-service.</span><span class="sxs-lookup"><span data-stu-id="af32b-223">In this step, you create a dataset named InputDataset that points to a blob file (emp.txt) in the root folder of a blob container (adftutorial) in the Azure Storage represented by the AzureStorageLinkedService linked service.</span></span> <span data-ttu-id="af32b-224">Als u geen waarde voor de fileName hebt opgeven (of hebt overgeslagen), worden gegevens uit alle blobs in de invoermap naar het doel gekopieerd.</span><span class="sxs-lookup"><span data-stu-id="af32b-224">If you don't specify a value for the fileName (or skip it), data from all blobs in the input folder are copied to the destination.</span></span> <span data-ttu-id="af32b-225">In deze zelfstudie geeft u een waarde op voor de fileName.</span><span class="sxs-lookup"><span data-stu-id="af32b-225">In this tutorial, you specify a value for the fileName.</span></span> 

1. <span data-ttu-id="af32b-226">In de **Editor** voor de Data Factory, klikt u op **... Meer**, **Nieuwe gegevensset** en vervolgens op **Azure Blob-opslag** in de vervolgkeuzelijst.</span><span class="sxs-lookup"><span data-stu-id="af32b-226">In the **Editor** for the Data Factory, click **... More**, click **New dataset**, and click **Azure Blob storage** from the drop-down menu.</span></span> 
   
    ![Nieuw gegevenssetmenu](./media/data-factory-copy-activity-tutorial-using-azure-portal/new-dataset-menu.png)
2. <span data-ttu-id="af32b-228">Vervang JSON in het rechterdeelvenster met het volgende JSON-fragment:</span><span class="sxs-lookup"><span data-stu-id="af32b-228">Replace JSON in the right pane with the following JSON snippet:</span></span> 
   
    ```json
    {
      "name": "InputDataset",
      "properties": {
        "structure": [
          {
            "name": "FirstName",
            "type": "String"
          },
          {
            "name": "LastName",
            "type": "String"
          }
        ],
        "type": "AzureBlob",
        "linkedServiceName": "AzureStorageLinkedService",
        "typeProperties": {
          "folderPath": "adftutorial/",
          "fileName": "emp.txt",
          "format": {
            "type": "TextFormat",
            "columnDelimiter": ","
          }
        },
        "external": true,
        "availability": {
          "frequency": "Hour",
          "interval": 1
        }
      }
    }
    ```   

    <span data-ttu-id="af32b-229">De volgende tabel bevat beschrijvingen van de JSON-eigenschappen die in het codefragment worden gebruikt:</span><span class="sxs-lookup"><span data-stu-id="af32b-229">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    | <span data-ttu-id="af32b-230">Eigenschap</span><span class="sxs-lookup"><span data-stu-id="af32b-230">Property</span></span> | <span data-ttu-id="af32b-231">Beschrijving</span><span class="sxs-lookup"><span data-stu-id="af32b-231">Description</span></span> |
    |:--- |:--- |
    | <span data-ttu-id="af32b-232">type</span><span class="sxs-lookup"><span data-stu-id="af32b-232">type</span></span> | <span data-ttu-id="af32b-233">De eigenschap type wordt ingesteld op **AzureBlob**, omdat de gegevens zich in een Azure-blobopslag bevinden.</span><span class="sxs-lookup"><span data-stu-id="af32b-233">The type property is set to **AzureBlob** because data resides in an Azure blob storage.</span></span> |
    | <span data-ttu-id="af32b-234">linkedServiceName</span><span class="sxs-lookup"><span data-stu-id="af32b-234">linkedServiceName</span></span> | <span data-ttu-id="af32b-235">Deze eigenschap verwijst naar de **AzureStorageLinkedService** die u eerder hebt gemaakt.</span><span class="sxs-lookup"><span data-stu-id="af32b-235">Refers to the **AzureStorageLinkedService** that you created earlier.</span></span> |
    | <span data-ttu-id="af32b-236">folderPath</span><span class="sxs-lookup"><span data-stu-id="af32b-236">folderPath</span></span> | <span data-ttu-id="af32b-237">Deze eigenschap verwijst naar de blob**container** en de **map** die de blobs voor invoer bevat.</span><span class="sxs-lookup"><span data-stu-id="af32b-237">Specifies the blob **container** and the **folder** that contains input blobs.</span></span> <span data-ttu-id="af32b-238">In deze zelfstudie is adftutorial de blobcontainer en is folder de hoofdmap.</span><span class="sxs-lookup"><span data-stu-id="af32b-238">In this tutorial, adftutorial is the blob container and folder is the root folder.</span></span> | 
    | <span data-ttu-id="af32b-239">fileName</span><span class="sxs-lookup"><span data-stu-id="af32b-239">fileName</span></span> | <span data-ttu-id="af32b-240">Deze eigenschap is optioneel.</span><span class="sxs-lookup"><span data-stu-id="af32b-240">This property is optional.</span></span> <span data-ttu-id="af32b-241">Als u deze eigenschap niet opgeeft, worden alle bestanden uit folderPath gekozen.</span><span class="sxs-lookup"><span data-stu-id="af32b-241">If you omit this property, all files from the folderPath are picked.</span></span> <span data-ttu-id="af32b-242">In deze zelfstudie wordt **emp.txt** opgegeven voor de fileName, zodat alleen dat bestand wordt opgehaald voor de verwerking.</span><span class="sxs-lookup"><span data-stu-id="af32b-242">In this tutorial, **emp.txt** is specified for the fileName, so only that file is picked up for processing.</span></span> |
    | <span data-ttu-id="af32b-243">format -> type</span><span class="sxs-lookup"><span data-stu-id="af32b-243">format -> type</span></span> |<span data-ttu-id="af32b-244">Het invoerbestand is in de tekstindeling, zodat we **TextFormat** gebruiken.</span><span class="sxs-lookup"><span data-stu-id="af32b-244">The input file is in the text format, so we use **TextFormat**.</span></span> |
    | <span data-ttu-id="af32b-245">columnDelimiter</span><span class="sxs-lookup"><span data-stu-id="af32b-245">columnDelimiter</span></span> | <span data-ttu-id="af32b-246">De kolommen in het invoerbestand worden gescheiden door een **komma (`,`)**.</span><span class="sxs-lookup"><span data-stu-id="af32b-246">The columns in the input file are delimited by **comma character (`,`)**.</span></span> |
    | <span data-ttu-id="af32b-247">frequency/interval</span><span class="sxs-lookup"><span data-stu-id="af32b-247">frequency/interval</span></span> | <span data-ttu-id="af32b-248">Als frequency wordt ingesteld op **Hour** en het interval wordt ingesteld op **1**, betekent dit dat de invoersegmenten één keer per **uur** beschikbaar worden gemaakt.</span><span class="sxs-lookup"><span data-stu-id="af32b-248">The frequency is set to **Hour** and interval is  set to **1**, which means that the input slices are available **hourly**.</span></span> <span data-ttu-id="af32b-249">Met andere woorden, de Data Factory-service zoekt elk uur naar invoergegevens in de hoofdmap van de opgegeven blobcontainer (**adftutorial**).</span><span class="sxs-lookup"><span data-stu-id="af32b-249">In other words, the Data Factory service looks for input data every hour in the root folder of blob container (**adftutorial**) you specified.</span></span> <span data-ttu-id="af32b-250">Er wordt gezocht naar gegevens binnen de begin- en eindtijd van de pijplijn, niet voor of na deze tijden.</span><span class="sxs-lookup"><span data-stu-id="af32b-250">It looks for the data within the pipeline start and end times, not before or after these times.</span></span>  |
    | <span data-ttu-id="af32b-251">external</span><span class="sxs-lookup"><span data-stu-id="af32b-251">external</span></span> | <span data-ttu-id="af32b-252">Deze eigenschap wordt ingesteld op **true** als de gegevens niet worden gegenereerd door deze pijplijn.</span><span class="sxs-lookup"><span data-stu-id="af32b-252">This property is set to **true** if the data is not generated by this pipeline.</span></span> <span data-ttu-id="af32b-253">De invoergegevens in deze zelfstudie bevinden zich in het bestand emp.txt, dat niet wordt gegenereerd door deze pijplijn. Daarom stellen we deze eigenschap in op true.</span><span class="sxs-lookup"><span data-stu-id="af32b-253">The input data in this tutorial is in the emp.txt file, which is not generated by this pipeline, so we set this property to true.</span></span> |

    <span data-ttu-id="af32b-254">Zie het [artikel over Azure Blob-connectoren](data-factory-azure-blob-connector.md#dataset-properties) voor meer informatie over deze JSON-eigenschappen.</span><span class="sxs-lookup"><span data-stu-id="af32b-254">For more information about these JSON properties, see [Azure Blob connector article](data-factory-azure-blob-connector.md#dataset-properties).</span></span>      
3. <span data-ttu-id="af32b-255">Klik op **Implementeren** op de werkbalk om de tabel **InputDataset** te implementeren.</span><span class="sxs-lookup"><span data-stu-id="af32b-255">Click **Deploy** on the toolbar to create and deploy the **InputDataset** dataset.</span></span> <span data-ttu-id="af32b-256">Bevestig dat **InputDataset** in de structuurweergave wordt weergegeven.</span><span class="sxs-lookup"><span data-stu-id="af32b-256">Confirm that you see the **InputDataset** in the tree view.</span></span>

### <a name="create-output-dataset"></a><span data-ttu-id="af32b-257">Uitvoergegevensset maken</span><span class="sxs-lookup"><span data-stu-id="af32b-257">Create output dataset</span></span>
<span data-ttu-id="af32b-258">De gekoppelde Azure SQL Database-service geeft de verbindingsreeks op die de Data Factory-service in runtime gebruikt om verbinding te maken met uw Azure SQL-database.</span><span class="sxs-lookup"><span data-stu-id="af32b-258">The Azure SQL Database linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure SQL database.</span></span> <span data-ttu-id="af32b-259">De uitvoergegevensset van de SQL-tabel (OututDataset) die u in deze stap hebt gemaakt, geeft de tabel in de database op waarnaar de gegevens uit de blobopslag worden gekopieerd.</span><span class="sxs-lookup"><span data-stu-id="af32b-259">The output SQL table dataset (OututDataset) you create in this step specifies the table in the database to which the data from the blob storage is copied.</span></span>

1. <span data-ttu-id="af32b-260">In de **Editor** voor de Data Factory, klikt u op **... Meer**, **Nieuwe gegevensset** en vervolgens op **Azure SQL** in de vervolgkeuzelijst.</span><span class="sxs-lookup"><span data-stu-id="af32b-260">In the **Editor** for the Data Factory, click **... More**, click **New dataset**, and click **Azure SQL** from the drop-down menu.</span></span> 
2. <span data-ttu-id="af32b-261">Vervang JSON in het rechterdeelvenster met het volgende JSON-fragment:</span><span class="sxs-lookup"><span data-stu-id="af32b-261">Replace JSON in the right pane with the following JSON snippet:</span></span>

    ```json   
    {
      "name": "OutputDataset",
      "properties": {
        "structure": [
          {
            "name": "FirstName",
            "type": "String"
          },
          {
            "name": "LastName",
            "type": "String"
          }
        ],
        "type": "AzureSqlTable",
        "linkedServiceName": "AzureSqlLinkedService",
        "typeProperties": {
          "tableName": "emp"
        },
        "availability": {
          "frequency": "Hour",
          "interval": 1
        }
      }
    }
    ```     

    <span data-ttu-id="af32b-262">De volgende tabel bevat beschrijvingen van de JSON-eigenschappen die in het codefragment worden gebruikt:</span><span class="sxs-lookup"><span data-stu-id="af32b-262">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    | <span data-ttu-id="af32b-263">Eigenschap</span><span class="sxs-lookup"><span data-stu-id="af32b-263">Property</span></span> | <span data-ttu-id="af32b-264">Beschrijving</span><span class="sxs-lookup"><span data-stu-id="af32b-264">Description</span></span> |
    |:--- |:--- |
    | <span data-ttu-id="af32b-265">type</span><span class="sxs-lookup"><span data-stu-id="af32b-265">type</span></span> | <span data-ttu-id="af32b-266">De eigenschap type wordt ingesteld op **AzureSqlTable** omdat gegevens naar een tabel in een Azure SQL-database worden gekopieerd.</span><span class="sxs-lookup"><span data-stu-id="af32b-266">The type property is set to **AzureSqlTable** because data is copied to a table in an Azure SQL database.</span></span> |
    | <span data-ttu-id="af32b-267">linkedServiceName</span><span class="sxs-lookup"><span data-stu-id="af32b-267">linkedServiceName</span></span> | <span data-ttu-id="af32b-268">Deze eigenschap verwijst naar de **AzureSqlLinkedService** die u eerder hebt gemaakt.</span><span class="sxs-lookup"><span data-stu-id="af32b-268">Refers to the **AzureSqlLinkedService** that you created earlier.</span></span> |
    | <span data-ttu-id="af32b-269">tableName</span><span class="sxs-lookup"><span data-stu-id="af32b-269">tableName</span></span> | <span data-ttu-id="af32b-270">Geeft de **tabel** aan waarnaar de gegevens worden gekopieerd.</span><span class="sxs-lookup"><span data-stu-id="af32b-270">Specified the **table** to which the data is copied.</span></span> | 
    | <span data-ttu-id="af32b-271">frequency/interval</span><span class="sxs-lookup"><span data-stu-id="af32b-271">frequency/interval</span></span> | <span data-ttu-id="af32b-272">De frequentie is ingesteld op **Hour** en het interval is **1**, wat betekent dat de uitvoersegmenten worden geproduceerd **per uur** tussen de begin- en eindtijd van de pijplijn, niet voor of na deze tijden.</span><span class="sxs-lookup"><span data-stu-id="af32b-272">The frequency is set to **Hour** and interval is **1**, which means that the output slices are produced **hourly** between the pipeline start and end times, not before or after these times.</span></span>  |

    <span data-ttu-id="af32b-273">De tabel emp in de database bevat drie kolommen: **ID**, **FirstName** en **LastName**.</span><span class="sxs-lookup"><span data-stu-id="af32b-273">There are three columns – **ID**, **FirstName**, and **LastName** – in the emp table in the database.</span></span> <span data-ttu-id="af32b-274">ID is een identiteitskolom, zodat u alleen **FirstName** en **LastName** hoeft op te geven.</span><span class="sxs-lookup"><span data-stu-id="af32b-274">ID is an identity column, so you need to specify only **FirstName** and **LastName** here.</span></span>

    <span data-ttu-id="af32b-275">Zie het [artikel over Azure SQL-connectoren](data-factory-azure-sql-connector.md#dataset-properties) voor meer informatie over deze JSON-eigenschappen.</span><span class="sxs-lookup"><span data-stu-id="af32b-275">For more information about these JSON properties, see [Azure SQL connector article](data-factory-azure-sql-connector.md#dataset-properties).</span></span>
3. <span data-ttu-id="af32b-276">Klik op **Implementeren** op de werkbalk om de tabel **OutputDataset** te implementeren.</span><span class="sxs-lookup"><span data-stu-id="af32b-276">Click **Deploy** on the toolbar to create and deploy the **OutputDataset** dataset.</span></span> <span data-ttu-id="af32b-277">Bevestig dat **OutputDataset** in de structuurweergave onder **Gegevenssets** wordt weergegeven.</span><span class="sxs-lookup"><span data-stu-id="af32b-277">Confirm that you see the **OutputDataset** in the tree view under **Datasets**.</span></span> 

## <a name="create-pipeline"></a><span data-ttu-id="af32b-278">Pijplijn maken</span><span class="sxs-lookup"><span data-stu-id="af32b-278">Create pipeline</span></span>
<span data-ttu-id="af32b-279">In deze stap maakt u een pijplijn met een **kopieeractiviteit** die gebruikmaakt van **InputDataset** als invoer en **OutputDataset** als uitvoer.</span><span class="sxs-lookup"><span data-stu-id="af32b-279">In this step, you create a pipeline with a **copy activity** that uses **InputDataset** as an input and **OutputDataset** as an output.</span></span>

<span data-ttu-id="af32b-280">Momenteel is de uitvoergegevensset dat wat de planning aanstuurt.</span><span class="sxs-lookup"><span data-stu-id="af32b-280">Currently, output dataset is what drives the schedule.</span></span> <span data-ttu-id="af32b-281">In deze zelfstudie is de uitvoergegevensset geconfigureerd voor het produceren van een segment eenmaal per uur.</span><span class="sxs-lookup"><span data-stu-id="af32b-281">In this tutorial, output dataset is configured to produce a slice once an hour.</span></span> <span data-ttu-id="af32b-282">De pijplijn heeft een begintijd en eindtijd die één dag uit elkaar liggen, ofwel 24 uur.</span><span class="sxs-lookup"><span data-stu-id="af32b-282">The pipeline has a start time and end time that are one day apart, which is 24 hours.</span></span> <span data-ttu-id="af32b-283">Daarom worden 24 segmenten van de uitvoergegevensset door de pijplijn geproduceerd.</span><span class="sxs-lookup"><span data-stu-id="af32b-283">Therefore, 24 slices of output dataset are produced by the pipeline.</span></span> 

1. <span data-ttu-id="af32b-284">In de **Editor** voor de Data Factory, klikt u op **... Meer** en vervolgens op **Nieuwe pijplijn**.</span><span class="sxs-lookup"><span data-stu-id="af32b-284">In the **Editor** for the Data Factory, click **... More**, and click **New pipeline**.</span></span> <span data-ttu-id="af32b-285">U kunt ook met de rechtermuisknop op **Pijplijnen** klikken in de boomstructuur vervolgens klikken op **Nieuwe pijplijn**.</span><span class="sxs-lookup"><span data-stu-id="af32b-285">Alternatively, you can right-click **Pipelines** in the tree view and click **New pipeline**.</span></span>
2. <span data-ttu-id="af32b-286">Vervang JSON in het rechterdeelvenster met het volgende JSON-fragment:</span><span class="sxs-lookup"><span data-stu-id="af32b-286">Replace JSON in the right pane with the following JSON snippet:</span></span> 

    ```json   
    {
      "name": "ADFTutorialPipeline",
      "properties": {
        "description": "Copy data from a blob to Azure SQL table",
        "activities": [
          {
            "name": "CopyFromBlobToSQL",
            "type": "Copy",
            "inputs": [
              {
                "name": "InputDataset"
              }
            ],
            "outputs": [
              {
                "name": "OutputDataset"
              }
            ],
            "typeProperties": {
              "source": {
                "type": "BlobSource"
              },
              "sink": {
                "type": "SqlSink",
                "writeBatchSize": 10000,
                "writeBatchTimeout": "60:00:00"
              }
            },
            "Policy": {
              "concurrency": 1,
              "executionPriorityOrder": "NewestFirst",
              "retry": 0,
              "timeout": "01:00:00"
            }
          }
        ],
        "start": "2017-05-11T00:00:00Z",
        "end": "2017-05-12T00:00:00Z"
      }
    } 
    ```   
    
    <span data-ttu-id="af32b-287">Houd rekening met de volgende punten:</span><span class="sxs-lookup"><span data-stu-id="af32b-287">Note the following points:</span></span>
   
    - <span data-ttu-id="af32b-288">In het gedeelte Activiteiten is er slechts één activiteit waarvan **type** is ingesteld op **Copy**.</span><span class="sxs-lookup"><span data-stu-id="af32b-288">In the activities section, there is only one activity whose **type** is set to **Copy**.</span></span> <span data-ttu-id="af32b-289">Zie het artikel [Activiteiten voor gegevensverplaatsing](data-factory-data-movement-activities.md) voor meer informatie over kopieeractiviteiten.</span><span class="sxs-lookup"><span data-stu-id="af32b-289">For more information about the copy activity, see [data movement activities](data-factory-data-movement-activities.md).</span></span> <span data-ttu-id="af32b-290">In Data Factory-oplossingen kunt u ook [activiteiten voor gegevenstransformatie](data-factory-data-transformation-activities.md) gebruiken.</span><span class="sxs-lookup"><span data-stu-id="af32b-290">In Data Factory solutions, you can also use [data transformation activities](data-factory-data-transformation-activities.md).</span></span>
    - <span data-ttu-id="af32b-291">De invoer voor de activiteit is ingesteld op **InputDataset** en de uitvoer voor de activiteit is ingesteld op **OutputDataset**.</span><span class="sxs-lookup"><span data-stu-id="af32b-291">Input for the activity is set to **InputDataset** and output for the activity is set to **OutputDataset**.</span></span> 
    - <span data-ttu-id="af32b-292">In het gedeelte **typeProperties** is **BlobSource** opgegeven als het brontype en **SqlSink** als het sink-type.</span><span class="sxs-lookup"><span data-stu-id="af32b-292">In the **typeProperties** section, **BlobSource** is specified as the source type and **SqlSink** is specified as the sink type.</span></span> <span data-ttu-id="af32b-293">Zie [Ondersteunde gegevensarchieven](data-factory-data-movement-activities.md#supported-data-stores-and-formats) voor een volledige lijst van gegevensarchieven die worden ondersteund door kopieeractiviteiten als bronnen en sinks.</span><span class="sxs-lookup"><span data-stu-id="af32b-293">For a complete list of data stores supported by the copy activity as sources and sinks, see [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span></span> <span data-ttu-id="af32b-294">Klik op de koppeling in de tabel voor informatie over het gebruik van een specifiek ondersteund gegevensarchief als een bron/sink.</span><span class="sxs-lookup"><span data-stu-id="af32b-294">To learn how to use a specific supported data store as a source/sink, click the link in the table.</span></span>
    - <span data-ttu-id="af32b-295">Zowel de begin- als einddatum en -tijd moeten de [ISO-indeling](http://en.wikipedia.org/wiki/ISO_8601) hebben.</span><span class="sxs-lookup"><span data-stu-id="af32b-295">Both start and end datetimes must be in [ISO format](http://en.wikipedia.org/wiki/ISO_8601).</span></span> <span data-ttu-id="af32b-296">Bijvoorbeeld: 2016-10-14T16:32:41Z.</span><span class="sxs-lookup"><span data-stu-id="af32b-296">For example: 2016-10-14T16:32:41Z.</span></span> <span data-ttu-id="af32b-297">De **eindtijd** is optioneel, maar we gebruiken hem in deze zelfstudie.</span><span class="sxs-lookup"><span data-stu-id="af32b-297">The **end** time is optional, but we use it in this tutorial.</span></span> <span data-ttu-id="af32b-298">Als u geen waarde opgeeft voor de eigenschap **end**, wordt automatisch **start + 48 uur** gebruikt.</span><span class="sxs-lookup"><span data-stu-id="af32b-298">If you do not specify value for the **end** property, it is calculated as "**start + 48 hours**".</span></span> <span data-ttu-id="af32b-299">Als u de pijplijn voor onbepaalde tijd wilt uitvoeren, geeft u **9999-09-09** op als waarde voor de eigenschap **end**.</span><span class="sxs-lookup"><span data-stu-id="af32b-299">To run the pipeline indefinitely, specify **9999-09-09** as the value for the **end** property.</span></span>
     
    <span data-ttu-id="af32b-300">In het voorgaande voorbeeld zijn er 24 gegevenssegmenten omdat er elk uur één gegevenssegment wordt gemaakt.</span><span class="sxs-lookup"><span data-stu-id="af32b-300">In the preceding example, there are 24 data slices as each data slice is produced hourly.</span></span>

    <span data-ttu-id="af32b-301">Zie het artikel [Pijplijnen maken](data-factory-create-pipelines.md) voor beschrijvingen van JSON-eigenschappen in de definitie van een pijplijn.</span><span class="sxs-lookup"><span data-stu-id="af32b-301">For descriptions of JSON properties in a pipeline definition, see [create pipelines](data-factory-create-pipelines.md) article.</span></span> <span data-ttu-id="af32b-302">Zie [Gegevensverplaatsingsactiviteiten](data-factory-data-movement-activities.md) voor beschrijvingen van JSON-eigenschappen in de definitie van een kopieeractiviteit.</span><span class="sxs-lookup"><span data-stu-id="af32b-302">For descriptions of JSON properties in a copy activity definition, see [data movement activities](data-factory-data-movement-activities.md).</span></span> <span data-ttu-id="af32b-303">Zie het [artikel over Azure Blob-connectoren](data-factory-azure-blob-connector.md) voor beschrijvingen van JSON-eigenschappen die worden ondersteund door BlobSource.</span><span class="sxs-lookup"><span data-stu-id="af32b-303">For descriptions of JSON properties supported by BlobSource, see [Azure Blob connector article](data-factory-azure-blob-connector.md).</span></span> <span data-ttu-id="af32b-304">Zie het [artikel over Azure SQL Database-connectoren](data-factory-azure-sql-connector.md) voor beschrijvingen van JSON-eigenschappen die worden ondersteund door SqlSink.</span><span class="sxs-lookup"><span data-stu-id="af32b-304">For descriptions of JSON properties supported by SqlSink, see [Azure SQL Database connector article](data-factory-azure-sql-connector.md).</span></span>
3. <span data-ttu-id="af32b-305">Klik op **Implementeren** op de werkbalk om de tabel **ADFTutorialPipeline** te implementeren.</span><span class="sxs-lookup"><span data-stu-id="af32b-305">Click **Deploy** on the toolbar to create and deploy the **ADFTutorialPipeline**.</span></span> <span data-ttu-id="af32b-306">Controleer of de pijplijn in de structuurweergave wordt weergegeven.</span><span class="sxs-lookup"><span data-stu-id="af32b-306">Confirm that you see the pipeline in the tree view.</span></span> 
4. <span data-ttu-id="af32b-307">Sluit nu de blade **Editor** door op **X** te klikken. Klik opnieuw op **X** om de **Data Factory**-startpagina te zien voor de **ADFTutorialDataFactory**.</span><span class="sxs-lookup"><span data-stu-id="af32b-307">Now, close the **Editor** blade by clicking **X**. Click **X** again to see the **Data Factory** home page for the **ADFTutorialDataFactory**.</span></span>

<span data-ttu-id="af32b-308">**Gefeliciteerd!**</span><span class="sxs-lookup"><span data-stu-id="af32b-308">**Congratulations!**</span></span> <span data-ttu-id="af32b-309">U hebt een Azure-gegevensfactory gemaakt met een pijplijn die gegevens van een Azure-blobopslag kopieert naar een Azure SQL-database.</span><span class="sxs-lookup"><span data-stu-id="af32b-309">You have successfully created an Azure data factory with a pipeline to copy data from an Azure blob storage to an Azure SQL database.</span></span> 


## <a name="monitor-pipeline"></a><span data-ttu-id="af32b-310">De pijplijn bewaken</span><span class="sxs-lookup"><span data-stu-id="af32b-310">Monitor pipeline</span></span>
<span data-ttu-id="af32b-311">In deze stap gebruikt u Azure Portal om te controleren wat er gebeurt in een Azure data factory.</span><span class="sxs-lookup"><span data-stu-id="af32b-311">In this step, you use the Azure portal to monitor what’s going on in an Azure data factory.</span></span>    

### <a name="monitor-pipeline-using-monitor--manage-app"></a><span data-ttu-id="af32b-312">De pijplijn bewaken met de app Bewaking en beheer</span><span class="sxs-lookup"><span data-stu-id="af32b-312">Monitor pipeline using Monitor & Manage App</span></span>
<span data-ttu-id="af32b-313">In de volgende stappen ziet u hoe u pijplijnen in uw gegevensfactory kunt bewaken met behulp van de toepassing Bewaking en beheer:</span><span class="sxs-lookup"><span data-stu-id="af32b-313">The following steps show you how to monitor pipelines in your data factory by using the Monitor & Manage application:</span></span> 

1. <span data-ttu-id="af32b-314">Klik op de tegel **Bewaking en beheer** op de startpagina van uw gegevensfactory.</span><span class="sxs-lookup"><span data-stu-id="af32b-314">Click **Monitor & Manage** tile on the home page for your data factory.</span></span>
   
    ![De tegel Bewaking en beheer](./media/data-factory-copy-activity-tutorial-using-azure-portal/monitor-manage-tile.png) 
2. <span data-ttu-id="af32b-316">De toepassing **Bewaking en beheer** wordt op een afzonderlijk tabblad weergegeven.</span><span class="sxs-lookup"><span data-stu-id="af32b-316">You should see **Monitor & Manage application** in a separate tab.</span></span> 

    > [!NOTE]
    > <span data-ttu-id="af32b-317">Als u ziet dat de webbrowser is vastgelopen bij "Autoriseren..." gaat u op een van de volgende manieren te werk: schakel het selectievakje **Cookies van derden en sitegegevens blokkeren** uit (of) maak een uitzondering voor **login.microsoftonline.com** en probeer de toepassing opnieuw te openen.</span><span class="sxs-lookup"><span data-stu-id="af32b-317">If you see that the web browser is stuck at "Authorizing...", do one of the following: clear the **Block third-party cookies and site data** check box (or) create an exception for **login.microsoftonline.com**, and then try to open the app again.</span></span>

    ![De app Bewaking en beheer](./media/data-factory-copy-activity-tutorial-using-azure-portal/monitor-and-manage-app.png)
3. <span data-ttu-id="af32b-319">Wijzig de **Begintijd** en de **Eindtijd** om de starttijd (2017-05-11) en de eindtijd (2017-05-12) van uw pijplijn op te geven. Klik vervolgens op **Toepassen**.</span><span class="sxs-lookup"><span data-stu-id="af32b-319">Change the **Start time** and **End time** to include start (2017-05-11) and end times (2017-05-12) of your pipeline, and click **Apply**.</span></span>       
3. <span data-ttu-id="af32b-320">U ziet de **activiteitsvensters** die zijn gekoppeld aan elk uur tussen de begin- en eindtijd van de pijplijn in de lijst in het middelste deelvenster.</span><span class="sxs-lookup"><span data-stu-id="af32b-320">You see the **activity windows** associated with each hour between pipeline start and end times in the list in the middle pane.</span></span> 
4. <span data-ttu-id="af32b-321">Selecteer een activiteitsvenster in de lijst **Activiteitsvensters** om de details van een activiteitsvenster te bekijken.</span><span class="sxs-lookup"><span data-stu-id="af32b-321">To see details about an activity window, select the activity window in the **Activity Windows** list.</span></span> 
    <span data-ttu-id="af32b-322">![Details van activiteitsvenster](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-window-details.png)</span><span class="sxs-lookup"><span data-stu-id="af32b-322">![Activity window details](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-window-details.png)</span></span>

    <span data-ttu-id="af32b-323">In de activiteitsvensterverkenner aan de rechterkant ziet u dat de segmenten tot aan de huidige UTC-tijd (8:12 PM) alle zijn verwerkt (groen).</span><span class="sxs-lookup"><span data-stu-id="af32b-323">In Activity Window Explorer on the right, you see that the slices up to the current UTC time (8:12 PM) are all processed (in green color).</span></span> <span data-ttu-id="af32b-324">De segmenten 8-9 PM, 9 - 10 PM, 10 - 11 PM, 11 PM - 12 AM zijn nog niet verwerkt.</span><span class="sxs-lookup"><span data-stu-id="af32b-324">The 8-9 PM, 9 - 10 PM, 10 - 11 PM, 11 PM - 12 AM slices are not processed yet.</span></span>

    <span data-ttu-id="af32b-325">De sectie **Pogingen** in het rechterdeelvenster bevat informatie over de activiteit die wordt uitgevoerd voor het gegevenssegment.</span><span class="sxs-lookup"><span data-stu-id="af32b-325">The **Attempts** section in the right pane provides information about the activity run for the data slice.</span></span> <span data-ttu-id="af32b-326">Als er een fout is, staat er meer informatie over de fout.</span><span class="sxs-lookup"><span data-stu-id="af32b-326">If there was an error, it provides details about the error.</span></span> <span data-ttu-id="af32b-327">Als bijvoorbeeld de invoermap of de container niet bestaat en de segmentverwerking mislukt, ziet u een foutbericht dat aangeeft dat de container of de map niet bestaat.</span><span class="sxs-lookup"><span data-stu-id="af32b-327">For example, if the input folder or container does not exist and the slice processing fails, you see an error message stating that the container or folder does not exist.</span></span>

    ![Pogingen tot uitvoering van activiteit](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-run-attempts.png) 
4. <span data-ttu-id="af32b-329">Open **SQL Server Management Studio**, maak verbinding maken met de Azure SQL Database en controleer of de rijen zijn ingevoegd in de tabel **emp** in de database.</span><span class="sxs-lookup"><span data-stu-id="af32b-329">Launch **SQL Server Management Studio**, connect to the Azure SQL Database, and verify that the rows are inserted in to the **emp** table in the database.</span></span>
    
    ![SQL-queryresultaten](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-sql-query-results.png)

<span data-ttu-id="af32b-331">Zie [Azure Data Factory-pijplijnen bewaken en beheren met de app voor bewaking en beheer](data-factory-monitor-manage-app.md) voor meer informatie over het gebruik van deze toepassing.</span><span class="sxs-lookup"><span data-stu-id="af32b-331">For detailed information about using this application, see [Monitor and manage Azure Data Factory pipelines using Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

### <a name="monitor-pipeline-using-diagram-view"></a><span data-ttu-id="af32b-332">De pijplijn bewaken met Diagramweergave</span><span class="sxs-lookup"><span data-stu-id="af32b-332">Monitor pipeline using Diagram View</span></span>
<span data-ttu-id="af32b-333">U kunt ook gegevenspijplijnen bewaken met behulp van de diagramweergave.</span><span class="sxs-lookup"><span data-stu-id="af32b-333">You can also monitor data pipelines by using the diagram view.</span></span>  

1. <span data-ttu-id="af32b-334">In de blade **Gegevensfactory** klikt u op **Diagram**.</span><span class="sxs-lookup"><span data-stu-id="af32b-334">In the **Data Factory** blade, click **Diagram**.</span></span>
   
    ![Blade Gegevensfactory - tegel Diagram](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-datafactoryblade-diagramtile.png)
2. <span data-ttu-id="af32b-336">U ziet een diagram dat lijkt op de volgende afbeelding:</span><span class="sxs-lookup"><span data-stu-id="af32b-336">You should see the diagram similar to the following image:</span></span> 
   
    ![Diagramweergave](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-diagram-blade.png)  
5. <span data-ttu-id="af32b-338">Dubbelklik in de diagramweergave op **InputDataset** om segmenten voor de gegevensset weer te geven.</span><span class="sxs-lookup"><span data-stu-id="af32b-338">In the diagram view, double-click **InputDataset** to see slices for the dataset.</span></span>  
   
    ![Gegevenssets waarvoor InputDataset is geselecteerd](./media/data-factory-copy-activity-tutorial-using-azure-portal/DataSetsWithInputDatasetFromBlobSelected.png)   
5. <span data-ttu-id="af32b-340">Klik op **Alles bekijken** om alle gegevenssegmenten te bekijken.</span><span class="sxs-lookup"><span data-stu-id="af32b-340">Click **See more** link to see all the data slices.</span></span> <span data-ttu-id="af32b-341">U ziet 24 uurlijkse segmenten tussen de begin- en eindtijd van de pijplijn.</span><span class="sxs-lookup"><span data-stu-id="af32b-341">You see 24 hourly slices between pipeline start and end times.</span></span> 
   
    ![Alle invoergegevenssegmenten](./media/data-factory-copy-activity-tutorial-using-azure-portal/all-input-slices.png)  
   
    <span data-ttu-id="af32b-343">De gegevenssegmenten tot aan de huidige UTC-tijd hebben de status **Gereed** omdat het bestand **emp.txt** aanwezig is in de blobcontainer **adftutorial\input**.</span><span class="sxs-lookup"><span data-stu-id="af32b-343">Notice that all the data slices up to the current UTC time are **Ready** because the **emp.txt** file exists all the time in the blob container: **adftutorial\input**.</span></span> <span data-ttu-id="af32b-344">De segmenten voor de toekomstige tijden hebben nog niet de status Gereed.</span><span class="sxs-lookup"><span data-stu-id="af32b-344">The slices for the future times are not in ready state yet.</span></span> <span data-ttu-id="af32b-345">Controleer of er geen segmenten worden weergegeven in het gedeelte **Recent mislukte segmenten** onderaan.</span><span class="sxs-lookup"><span data-stu-id="af32b-345">Confirm that no slices show up in the **Recently failed slices** section at the bottom.</span></span>
6. <span data-ttu-id="af32b-346">Sluit de blades totdat u het diagram ziet (of) scroll naar links om de diagramweergave weer te geven.</span><span class="sxs-lookup"><span data-stu-id="af32b-346">Close the blades until you see the diagram view (or) scroll left to see the diagram view.</span></span> <span data-ttu-id="af32b-347">Dubbelklik vervolgens op **OutputDataset**.</span><span class="sxs-lookup"><span data-stu-id="af32b-347">Then, double-click **OutputDataset**.</span></span> 
8. <span data-ttu-id="af32b-348">Klik op de koppeling **Alles bekijken** op de blade **Tabel** voor **OutputDataset** om alle segmenten te bekijken.</span><span class="sxs-lookup"><span data-stu-id="af32b-348">Click **See more** link on the **Table** blade for **OutputDataset** to see all the slices.</span></span>

    ![blade gegevenssegmenten](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-dataslices-blade.png) 
9. <span data-ttu-id="af32b-350">U ziet dat alle segmenten tot aan de huidige UTC-tijd van de status **Uitvoering in behandeling** naar = > **Bezig** ==> **Gereed** gaan.</span><span class="sxs-lookup"><span data-stu-id="af32b-350">Notice that all the slices up to the current UTC time move from **pending execution** state => **In progress** ==> **Ready** state.</span></span> <span data-ttu-id="af32b-351">De segmenten in het verleden (voor de huidige tijd) worden standaard van laatste naar oudste verwerkt.</span><span class="sxs-lookup"><span data-stu-id="af32b-351">The slices from the past (before current time) are processed from latest to oldest by default.</span></span> <span data-ttu-id="af32b-352">Als de huidige tijd bijvoorbeeld 8:12 PM UTC is, wordt het segment voor 7 PM - 8 PM eerder verwerkt dan het segment 6 PM - 7 PM.</span><span class="sxs-lookup"><span data-stu-id="af32b-352">For example, if the current time is 8:12 PM UTC, the slice for 7 PM - 8 PM is processed ahead of the 6 PM - 7 PM slice.</span></span> <span data-ttu-id="af32b-353">Het segment 8 PM - 9 PM wordt standaard verwerkt aan het einde van het tijdsinterval, ofwel na 9 PM.</span><span class="sxs-lookup"><span data-stu-id="af32b-353">The 8 PM - 9 PM slice is processed at the end of the time interval by default, that is after 9 PM.</span></span>  
10. <span data-ttu-id="af32b-354">Als u op een gegevenssegment uit de lijst klikt, ziet u de blade **Gegevenssegment**.</span><span class="sxs-lookup"><span data-stu-id="af32b-354">Click any data slice from the list and you should see the **Data slice** blade.</span></span> <span data-ttu-id="af32b-355">Een hoeveelheid gegevens die is gekoppeld aan een activiteitsvenster wordt een segment genoemd.</span><span class="sxs-lookup"><span data-stu-id="af32b-355">A piece of data associated with an activity window is called a slice.</span></span> <span data-ttu-id="af32b-356">Een segment kan één bestand of meerdere bestanden zijn.</span><span class="sxs-lookup"><span data-stu-id="af32b-356">A slice can be one file or multiple files.</span></span>  
    
     ![blade Gegevenssegment](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-dataslice-blade.png)
    
     <span data-ttu-id="af32b-358">Als het segment niet de status **Gereed** heeft, kunt u de upstreamsegmenten bekijken die niet de status Gereed hebben en die voorkomen dat de huidige status wordt uitgevoerd. U ziet deze segmenten in de lijst **Upstreamsegmenten die niet gereed zijn**.</span><span class="sxs-lookup"><span data-stu-id="af32b-358">If the slice is not in the **Ready** state, you can see the upstream slices that are not Ready and are blocking the current slice from executing in the **Upstream slices that are not ready** list.</span></span>
11. <span data-ttu-id="af32b-359">In de blade **GEGEVENSSEGMENT** ziet u in de lijst onderaan alle activiteiten die worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="af32b-359">In the **DATA SLICE** blade, you should see all activity runs in the list at the bottom.</span></span> <span data-ttu-id="af32b-360">Klik op een **activiteit die wordt uitgevoerd** om de blade **Details uitvoering van activiteit** weer te geven.</span><span class="sxs-lookup"><span data-stu-id="af32b-360">Click an **activity run** to see the **Activity run details** blade.</span></span> 
    
    ![Details uitvoering van activiteit](./media/data-factory-copy-activity-tutorial-using-azure-portal/ActivityRunDetails.png)

    <span data-ttu-id="af32b-362">Op deze blade ziet u hoe lang de kopieerbewerking duurde, wat de doorvoer is, hoeveel bytes aan gegevens zijn gelezen en geschreven, de uitvoeringstijd, de begintijd, eindtijd, enzovoort.</span><span class="sxs-lookup"><span data-stu-id="af32b-362">In this blade, you see how long the copy operation took, what throughput is, how many bytes of data were read and written, run start time, run end time etc.</span></span>  
12. <span data-ttu-id="af32b-363">Klik op **X** om alle blades te sluiten tot u weer op de startblade bent voor **ADFTutorialDataFactory**.</span><span class="sxs-lookup"><span data-stu-id="af32b-363">Click **X** to close all the blades until you get back to the home blade for the **ADFTutorialDataFactory**.</span></span>
13. <span data-ttu-id="af32b-364">Klik op de tegel **Gegevenssets** of op de tegel **Pijplijnen** om de blades weer te geven die u hebt gezien in de voorgaande stappen (optioneel).</span><span class="sxs-lookup"><span data-stu-id="af32b-364">(optional) click the **Datasets** tile or **Pipelines** tile to get the blades you have seen the preceding steps.</span></span> 
14. <span data-ttu-id="af32b-365">Open **SQL Server Management Studio**, maak verbinding maken met de Azure SQL Database en controleer of de rijen zijn ingevoegd in de tabel **emp** in de database.</span><span class="sxs-lookup"><span data-stu-id="af32b-365">Launch **SQL Server Management Studio**, connect to the Azure SQL Database, and verify that the rows are inserted in to the **emp** table in the database.</span></span>
    
    ![SQL-queryresultaten](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-sql-query-results.png)


## <a name="summary"></a><span data-ttu-id="af32b-367">Samenvatting</span><span class="sxs-lookup"><span data-stu-id="af32b-367">Summary</span></span>
<span data-ttu-id="af32b-368">In deze zelfstudie hebt u een Azure-gegevensfactory gemaakt om gegevens te kopiëren van een Azure-blob naar een Azure SQL-database.</span><span class="sxs-lookup"><span data-stu-id="af32b-368">In this tutorial, you created an Azure data factory to copy data from an Azure blob to an Azure SQL database.</span></span> <span data-ttu-id="af32b-369">U gebruikt Azure Portal om de data factory, gekoppelde services, datasets en een pijplijn te maken.</span><span class="sxs-lookup"><span data-stu-id="af32b-369">You used the Azure portal to create the data factory, linked services, datasets, and a pipeline.</span></span> <span data-ttu-id="af32b-370">Hier volgen de hoofdstappen die u in deze zelfstudie hebt uitgevoerd:</span><span class="sxs-lookup"><span data-stu-id="af32b-370">Here are the high-level steps you performed in this tutorial:</span></span>  

1. <span data-ttu-id="af32b-371">U hebt een Azure-**gegevensfactory** gemaakt.</span><span class="sxs-lookup"><span data-stu-id="af32b-371">Created an Azure **data factory**.</span></span>
2. <span data-ttu-id="af32b-372">U hebt **gekoppelde services** gemaakt:</span><span class="sxs-lookup"><span data-stu-id="af32b-372">Created **linked services**:</span></span>
   1. <span data-ttu-id="af32b-373">Een gekoppelde **Azure Storage**-service om uw Azure-opslagaccount te koppelen dat invoergegevens bevat.</span><span class="sxs-lookup"><span data-stu-id="af32b-373">An **Azure Storage** linked service to link your Azure Storage account that holds input data.</span></span>     
   2. <span data-ttu-id="af32b-374">Een gekoppelde **Azure SQL**-service om uw Azure SQL Database te koppelen die uitvoergegevens bevat.</span><span class="sxs-lookup"><span data-stu-id="af32b-374">An **Azure SQL** linked service to link your Azure SQL database that holds the output data.</span></span> 
3. <span data-ttu-id="af32b-375">U hebt **gegevenssets** gemaakt waarin de invoer- en uitvoergegevens van pijplijnen worden beschreven.</span><span class="sxs-lookup"><span data-stu-id="af32b-375">Created **datasets** that describe input data and output data for pipelines.</span></span>
4. <span data-ttu-id="af32b-376">U hebt een **pijplijn** gemaakt met een **kopieeractiviteit** met **BlobSource** als bron en **SqlSink** als sink.</span><span class="sxs-lookup"><span data-stu-id="af32b-376">Created a **pipeline** with a **Copy Activity** with **BlobSource** as source and **SqlSink** as sink.</span></span>  

## <a name="next-steps"></a><span data-ttu-id="af32b-377">Volgende stappen</span><span class="sxs-lookup"><span data-stu-id="af32b-377">Next steps</span></span>
<span data-ttu-id="af32b-378">In deze zelfstudie hebt u voor een kopieerbewerking een Azure Blob-opslag gebruikt als brongegevensarchief en een Azure SQL-database als doelgegevensarchief.</span><span class="sxs-lookup"><span data-stu-id="af32b-378">In this tutorial, you used Azure blob storage as a source data store and an Azure SQL database as a destination data store in a copy operation.</span></span> <span data-ttu-id="af32b-379">De volgende tabel bevat een lijst met gegevensarchieven die worden ondersteund als bron en doel voor de kopieeractiviteit:</span><span class="sxs-lookup"><span data-stu-id="af32b-379">The following table provides a list of data stores supported as sources and destinations by the copy activity:</span></span> 

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="af32b-380">Klik op de koppeling voor de gegevensopslag in de tabel voor meer informatie over het kopiëren van gegevens naar/uit een gegevensarchief.</span><span class="sxs-lookup"><span data-stu-id="af32b-380">To learn about how to copy data to/from a data store, click the link for the data store in the table.</span></span>