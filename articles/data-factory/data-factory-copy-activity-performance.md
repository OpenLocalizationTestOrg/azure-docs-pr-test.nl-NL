---
title: "Prestaties van de activiteit en prestatieafstemming handleiding kopiëren | Microsoft Docs"
description: Meer informatie over de belangrijkste factoren die invloed hebben op de prestaties van de gegevensverplaatsing in Azure Data Factory als u Kopieeractiviteit gebruiken.
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: 2779655aee3af3a351b30f18b4c9d9918e9f2210
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/29/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="178fb-103">Prestaties van de activiteit en prestatieafstemming handleiding kopiëren</span><span class="sxs-lookup"><span data-stu-id="178fb-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="178fb-104">Azure Data Factory-Kopieeractiviteit biedt een uitstekende gegevens veilig, betrouwbaar en hoge prestaties bij het laden van oplossing.</span><span class="sxs-lookup"><span data-stu-id="178fb-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="178fb-105">Deze Hiermee kunt u voor het kopiëren van tientallen terabytes aan gegevens elke dag op uitgebreide tal van cloud en het on-premises gegevensopslagexemplaren.</span><span class="sxs-lookup"><span data-stu-id="178fb-105">It enables you to copy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="178fb-106">Razendsnelle snel gegevens laden van prestaties is sleutel zodat u zich kunt richten op het probleem van core 'big data': bouwen van oplossingen voor geavanceerde analyses om inzichten te verkrijgen grondige van die gegevens.</span><span class="sxs-lookup"><span data-stu-id="178fb-106">Blazing-fast data loading performance is key to ensure you can focus on the core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="178fb-107">Azure biedt een reeks bedrijfsniveau oplossingen voor opslag en data warehouse en Kopieeractiviteit biedt een maximaal geoptimaliseerd gegevens te laden ervaring die eenvoudig te configureren en instellen.</span><span class="sxs-lookup"><span data-stu-id="178fb-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy to configure and set up.</span></span> <span data-ttu-id="178fb-108">Met slechts één exemplaar-activiteit, kunt u bereiken:</span><span class="sxs-lookup"><span data-stu-id="178fb-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="178fb-109">Laden van gegevens in **Azure SQL Data Warehouse** op **1,2 GBps**.</span><span class="sxs-lookup"><span data-stu-id="178fb-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="178fb-110">Zie voor een overzicht met een gebruiksvoorbeeld [1 TB laden in Azure SQL Data Warehouse onder 15 minuten met Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="178fb-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="178fb-111">Laden van gegevens in **Azure Blob storage** op **1.0 GBps**</span><span class="sxs-lookup"><span data-stu-id="178fb-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="178fb-112">Laden van gegevens in **Azure Data Lake Store** op **1.0 GBps**</span><span class="sxs-lookup"><span data-stu-id="178fb-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="178fb-113">Dit artikel wordt beschreven:</span><span class="sxs-lookup"><span data-stu-id="178fb-113">This article describes:</span></span>

* <span data-ttu-id="178fb-114">[Prestaties nummers](#performance-reference) voor ondersteunde gegevensarchieven bron- en sink voor het plannen van uw project.</span><span class="sxs-lookup"><span data-stu-id="178fb-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores to help you plan your project;</span></span>
* <span data-ttu-id="178fb-115">Functies die de kopie doorvoer in verschillende scenario's, inclusief kunnen stimuleren [cloud data movement eenheden](#cloud-data-movement-units), [kopie parallelle](#parallel-copy), en [kopie gefaseerde](#staged-copy);</span><span class="sxs-lookup"><span data-stu-id="178fb-115">Features that can boost the copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="178fb-116">[Prestaties afstemmen richtlijnen](#performance-tuning-steps) op het afstemmen van de prestaties en de belangrijkste factoren die invloed op prestaties van de kopie hebben kunnen.</span><span class="sxs-lookup"><span data-stu-id="178fb-116">[Performance tuning guidance](#performance-tuning-steps) on how to tune the performance and the key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="178fb-117">Als u niet bekend met de Kopieeractiviteit in het algemeen bent, Zie [verplaatsen van gegevens met behulp van de Kopieeractiviteit](data-factory-data-movement-activities.md) voordat u dit artikel leest.</span><span class="sxs-lookup"><span data-stu-id="178fb-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="178fb-118">Verwijzing voor prestaties</span><span class="sxs-lookup"><span data-stu-id="178fb-118">Performance reference</span></span>

<span data-ttu-id="178fb-119">Bevat onderstaande tabel als referentie, het nummer van de doorvoer kopiëren in MBps voor de opgegeven bron- en sink-paren die zijn gebaseerd op het intern testen.</span><span class="sxs-lookup"><span data-stu-id="178fb-119">As a reference, below table shows the copy throughput number in MBps for the given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="178fb-120">Ter vergelijking: u ziet ook hoe verschillende instellingen van [cloud data movement eenheden](#cloud-data-movement-units) of [Data Management Gateway-schaalbaarheid](data-factory-data-management-gateway-high-availability-scalability.md) (meerdere gateway knooppunten) kunt u op de prestaties van de kopie.</span><span class="sxs-lookup"><span data-stu-id="178fb-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![Matrix van prestaties](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="178fb-122">**Verwijst naar Let op:**</span><span class="sxs-lookup"><span data-stu-id="178fb-122">**Points to note:**</span></span>
* <span data-ttu-id="178fb-123">Doorvoer wordt berekend met behulp van de volgende formule: [grootte van de gegevens lezen uit bron] / [Kopieeractiviteit uitvoeren duur].</span><span class="sxs-lookup"><span data-stu-id="178fb-123">Throughput is calculated by using the following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="178fb-124">De prestaties verwijzing getallen in de tabel zijn gemeten met behulp van [TPC-H](http://www.tpc.org/tpch/) gegevensset in een activiteit die één exemplaar wordt uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-124">The performance reference numbers in the table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="178fb-125">In Azure gegevensarchieven zich de bron- en sink in dezelfde Azure-regio.</span><span class="sxs-lookup"><span data-stu-id="178fb-125">In Azure data stores, the source and sink are in the same Azure region.</span></span>
* <span data-ttu-id="178fb-126">Voor hybride exemplaar tussen on-premises en cloud gegevensarchieven, elk gateway-knooppunt wordt uitgevoerd op een machine die gescheiden van het lokale gegevensarchief met hieronder specificatie is.</span><span class="sxs-lookup"><span data-stu-id="178fb-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from the on-premises data store with below specification.</span></span> <span data-ttu-id="178fb-127">Wanneer een enkele activiteit werd uitgevoerd op de gateway, wordt in de kopieerbewerking slechts een klein deel van de testmachine CPU, geheugen of netwerkbandbreedte verbruikt.</span><span class="sxs-lookup"><span data-stu-id="178fb-127">When a single activity was running on gateway, the copy operation consumed only a small portion of the test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="178fb-128">Klik hier als u meer wilt weten van [overweging voor Data Management Gateway](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="178fb-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="178fb-129">CPU</span><span class="sxs-lookup"><span data-stu-id="178fb-129">CPU</span></span></td>
        <td><span data-ttu-id="178fb-130">32 cores 2,20 GHz Intel Xeon E5-2660 v2</span><span class="sxs-lookup"><span data-stu-id="178fb-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="178fb-131">Geheugen</span><span class="sxs-lookup"><span data-stu-id="178fb-131">Memory</span></span></td>
        <td><span data-ttu-id="178fb-132">128 GB</span><span class="sxs-lookup"><span data-stu-id="178fb-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="178fb-133">Netwerk</span><span class="sxs-lookup"><span data-stu-id="178fb-133">Network</span></span></td>
        <td><span data-ttu-id="178fb-134">Internet-interface: 10 Gbps; intranet-interface: 40 Gbps</span><span class="sxs-lookup"><span data-stu-id="178fb-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="178fb-135">U kunt hogere doorvoer bereiken door gebruik te maken van meer gegevens gegevensverplaatsing eenheden (DMUs) dan de standaardwaarde maximale DMUs die 32 voor een exemplaar van cloud-naar-cloud activiteit die wordt uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than the default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="178fb-136">Bijvoorbeeld, met 100 DMUs bereikt u kopiëren van gegevens van Azure-Blob in Azure Data Lake Store op **1.0GBps**.</span><span class="sxs-lookup"><span data-stu-id="178fb-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="178fb-137">Zie de [Cloud data movement eenheden](#cloud-data-movement-units) sectie voor meer informatie over deze functie en de ondersteunde scenario.</span><span class="sxs-lookup"><span data-stu-id="178fb-137">See the [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and the supported scenario.</span></span> <span data-ttu-id="178fb-138">Neem contact op met [ondersteuning van Azure](https://azure.microsoft.com/support/) meer DMUs aanvragen.</span><span class="sxs-lookup"><span data-stu-id="178fb-138">Contact [Azure support](https://azure.microsoft.com/support/) to request more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="178fb-139">Parallelle kopie</span><span class="sxs-lookup"><span data-stu-id="178fb-139">Parallel copy</span></span>
<span data-ttu-id="178fb-140">U kunt gegevens van de bron lezen of schrijven van gegevens naar de bestemming **parallel in een Kopieeractiviteit uitvoeren**.</span><span class="sxs-lookup"><span data-stu-id="178fb-140">You can read data from the source or write data to the destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="178fb-141">Deze functie verbetert de doorvoer van een kopieerbewerking en vermindert de tijd die nodig is om gegevens te verplaatsen.</span><span class="sxs-lookup"><span data-stu-id="178fb-141">This feature enhances the throughput of a copy operation and reduces the time it takes to move data.</span></span>

<span data-ttu-id="178fb-142">Deze instelling verschilt van de **gelijktijdigheid** eigenschap in de definitie van de activiteit.</span><span class="sxs-lookup"><span data-stu-id="178fb-142">This setting is different from the **concurrency** property in the activity definition.</span></span> <span data-ttu-id="178fb-143">De **gelijktijdigheid** eigenschap bepaalt het aantal **gelijktijdige Kopieeractiviteit wordt uitgevoerd** om gegevens te verwerken van andere activiteit windows (1 uur naar 2 uur, 2 uur tot 3 uur en 3 uur tot en met 4 uur).</span><span class="sxs-lookup"><span data-stu-id="178fb-143">The **concurrency** property determines the number of **concurrent Copy Activity runs** to process data from different activity windows (1 AM to 2 AM, 2 AM to 3 AM, 3 AM to 4 AM, and so on).</span></span> <span data-ttu-id="178fb-144">Deze mogelijkheid is handig wanneer u een historisch belasting uitvoeren.</span><span class="sxs-lookup"><span data-stu-id="178fb-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="178fb-145">De mogelijkheid parallelle kopie is van toepassing op een **één activiteit die wordt uitgevoerd**.</span><span class="sxs-lookup"><span data-stu-id="178fb-145">The parallel copy capability applies to a **single activity run**.</span></span>

<span data-ttu-id="178fb-146">Bekijk een voorbeeldscenario.</span><span class="sxs-lookup"><span data-stu-id="178fb-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="178fb-147">Meerdere segmenten in het verleden moeten worden verwerkt in het volgende voorbeeld.</span><span class="sxs-lookup"><span data-stu-id="178fb-147">In the following example, multiple slices from the past need to be processed.</span></span> <span data-ttu-id="178fb-148">Data Factory uitvoert een exemplaar van de Kopieeractiviteit (een activiteit uitvoeren) voor elk segment:</span><span class="sxs-lookup"><span data-stu-id="178fb-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="178fb-149">Het gegevenssegment van het eerste activiteitvenster (1 uur naar 2 uur) == > activiteit uitgevoerd 1</span><span class="sxs-lookup"><span data-stu-id="178fb-149">The data slice from the first activity window (1 AM to 2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="178fb-150">Het gegevenssegment van het tweede venster van activiteit (2 uur op 3 uur) == > activiteit uitgevoerd 2</span><span class="sxs-lookup"><span data-stu-id="178fb-150">The data slice from the second activity window (2 AM to 3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="178fb-151">Het gegevenssegment van het tweede venster van activiteit (3 uur op 4 uur) == > activiteit 3 uitvoeren</span><span class="sxs-lookup"><span data-stu-id="178fb-151">The data slice from the second activity window (3 AM to 4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="178fb-152">Enzovoort.</span><span class="sxs-lookup"><span data-stu-id="178fb-152">And so on.</span></span>

<span data-ttu-id="178fb-153">In dit voorbeeld wanneer de **gelijktijdigheid** waarde is ingesteld op 2, **activiteit uitgevoerd 1** en **activiteit uitgevoerd 2** gegevens gekopieerd van de twee activiteitsvensters **gelijktijdig** data movement prestaties te verbeteren.</span><span class="sxs-lookup"><span data-stu-id="178fb-153">In this example, when the **concurrency** value is set to 2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** to improve data movement performance.</span></span> <span data-ttu-id="178fb-154">Echter als meerdere bestanden gekoppeld aan activiteit 1 uitvoert zijn, kopieert data movement service bestanden van de bron op de bestemming één bestand tegelijk.</span><span class="sxs-lookup"><span data-stu-id="178fb-154">However, if multiple files are associated with Activity run 1, the data movement service copies files from the source to the destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="178fb-155">Cloud data movement-eenheden</span><span class="sxs-lookup"><span data-stu-id="178fb-155">Cloud data movement units</span></span>
<span data-ttu-id="178fb-156">Een **cloud gegevensverplaatsing gegevenseenheid (DMU)** is een meting met de kracht (een combinatie van CPU, geheugen en netwerkresourcetoewijzing) van één eenheid in de Data Factory.</span><span class="sxs-lookup"><span data-stu-id="178fb-156">A **cloud data movement unit (DMU)** is a measure that represents the power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="178fb-157">Een DMU kan worden gebruikt in een cloud-naar-cloud kopieerbewerking, maar niet in een hybride-exemplaar.</span><span class="sxs-lookup"><span data-stu-id="178fb-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="178fb-158">Data Factory gebruikt standaard een één cloud DMU om uit te voeren van een enkele Kopieeractiviteit uitvoeren.</span><span class="sxs-lookup"><span data-stu-id="178fb-158">By default, Data Factory uses a single cloud DMU to perform a single Copy Activity run.</span></span> <span data-ttu-id="178fb-159">Om deze standaardinstelling negeren, Geef een waarde op voor de **cloudDataMovementUnits** eigenschap als volgt.</span><span class="sxs-lookup"><span data-stu-id="178fb-159">To override this default, specify a value for the **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="178fb-160">Zie voor informatie over het niveau van prestatieverbetering krijgt u mogelijk wanneer u meer eenheden voor een specifieke kopieerbron en sink configureert, de [prestaties verwijzing](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="178fb-160">For information about the level of performance gain you might get when you configure more units for a specific copy source and sink, see the [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="178fb-161">De **toegestane waarden** voor de **cloudDataMovementUnits** eigenschap 1 (standaard), 2, 4, 8, 16, 32 zijn.</span><span class="sxs-lookup"><span data-stu-id="178fb-161">The **allowed values** for the **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="178fb-162">De **werkelijke aantal cloud DMUs** dat de kopieerbewerking wordt gebruikt tijdens de uitvoering is gelijk aan of kleiner zijn dan de geconfigureerde waarde, afhankelijk van het patroon van uw gegevens.</span><span class="sxs-lookup"><span data-stu-id="178fb-162">The **actual number of cloud DMUs** that the copy operation uses at run time is equal to or less than the configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="178fb-163">Als u meer cloud DMUs voor een hogere doorvoer moet, neem dan contact op met [ondersteuning van Azure](https://azure.microsoft.com/support/).</span><span class="sxs-lookup"><span data-stu-id="178fb-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="178fb-164">Instellen van 8 en hoger momenteel werkt alleen als u **meerdere bestanden kopiëren van Blob-opslag/Data Lake Store/Amazon S3/cloud FTP-/ cloud SFTP naar Blob storage/Data Lake Store/Azure SQL Database**.</span><span class="sxs-lookup"><span data-stu-id="178fb-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP to Blob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="178fb-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="178fb-165">parallelCopies</span></span>
<span data-ttu-id="178fb-166">U kunt de **parallelCopies** eigenschap om aan te geven van de parallelle uitvoering die u wilt dat de Kopieeractiviteit gebruiken.</span><span class="sxs-lookup"><span data-stu-id="178fb-166">You can use the **parallelCopies** property to indicate the parallelism that you want Copy Activity to use.</span></span> <span data-ttu-id="178fb-167">U kunt deze eigenschap zien als het maximum aantal threads in de Kopieeractiviteit die kunnen lezen uit de bron- of schrijven naar uw gegevensarchieven sink parallel.</span><span class="sxs-lookup"><span data-stu-id="178fb-167">You can think of this property as the maximum number of threads within Copy Activity that can read from your source or write to your sink data stores in parallel.</span></span>

<span data-ttu-id="178fb-168">Data Factory bepaalt voor elke kopie-activiteit is uitgevoerd, het aantal parallelle exemplaren te gebruiken om gegevens te kopiëren van de bron gegevens opgeslagen en wordt opgeslagen in de doelgegevens.</span><span class="sxs-lookup"><span data-stu-id="178fb-168">For each Copy Activity run, Data Factory determines the number of parallel copies to use to copy data from the source data store and to the destination data store.</span></span> <span data-ttu-id="178fb-169">Het aantal parallelle exemplaren die worden gebruikt, hangt af van het type van de bron en sink die u gebruikt.</span><span class="sxs-lookup"><span data-stu-id="178fb-169">The default number of parallel copies that it uses depends on the type of source and sink that you are using.</span></span>  

| <span data-ttu-id="178fb-170">Bron- en sink</span><span class="sxs-lookup"><span data-stu-id="178fb-170">Source and sink</span></span> | <span data-ttu-id="178fb-171">Standaard parallelle kopie aantal bepaald door de service</span><span class="sxs-lookup"><span data-stu-id="178fb-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="178fb-172">Gegevens kopiëren tussen winkels op basis van bestanden (Blob-opslag; Data Lake Store; Amazon S3; een on-premises bestandssysteem; een lokale HDFS)</span><span class="sxs-lookup"><span data-stu-id="178fb-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="178fb-173">Tussen 1 en 32.</span><span class="sxs-lookup"><span data-stu-id="178fb-173">Between 1 and 32.</span></span> <span data-ttu-id="178fb-174">Afhankelijk van de grootte van de bestanden en het aantal cloud data movement eenheden (DMUs) gebruikt om te kopiëren van gegevens tussen twee cloud gegevensarchieven of de fysieke configuratie van het Gateway-apparaat gebruikt voor een hybride-exemplaar (om gegevens te kopiëren naar of van een on-premises gegevensopslag).</span><span class="sxs-lookup"><span data-stu-id="178fb-174">Depends on the size of the files and the number of cloud data movement units (DMUs) used to copy data between two cloud data stores, or the physical configuration of the Gateway machine used for a hybrid copy (to copy data to or from an on-premises data store).</span></span> |
| <span data-ttu-id="178fb-175">Kopiëren van gegevens van **alle brongegevens opslaan naar Azure Table storage**</span><span class="sxs-lookup"><span data-stu-id="178fb-175">Copy data from **any source data store to Azure Table storage**</span></span> |<span data-ttu-id="178fb-176">4</span><span class="sxs-lookup"><span data-stu-id="178fb-176">4</span></span> |
| <span data-ttu-id="178fb-177">Alle andere bron en sink paren</span><span class="sxs-lookup"><span data-stu-id="178fb-177">All other source and sink pairs</span></span> |<span data-ttu-id="178fb-178">1</span><span class="sxs-lookup"><span data-stu-id="178fb-178">1</span></span> |

<span data-ttu-id="178fb-179">Normaal gesproken geeft het standaardgedrag de beste doorvoer.</span><span class="sxs-lookup"><span data-stu-id="178fb-179">Usually, the default behavior should give you the best throughput.</span></span> <span data-ttu-id="178fb-180">Evenwel waarmee de belasting op computers die als host fungeren van uw gegevens opslaat of als u wilt kopiëren prestaties afstemmen, u kunt de standaardwaarde onderdrukken en een waarde opgeven voor de **parallelCopies** eigenschap.</span><span class="sxs-lookup"><span data-stu-id="178fb-180">However, to control the load on machines that host your data stores, or to tune copy performance, you may choose to override the default value and specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="178fb-181">De waarde moet tussen 1 en 32 liggen (zowel liggen).</span><span class="sxs-lookup"><span data-stu-id="178fb-181">The value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="178fb-182">Tijdens de runtime voor de beste prestaties Kopieeractiviteit maakt gebruik van een waarde die kleiner is dan of gelijk aan de waarde die u instelt.</span><span class="sxs-lookup"><span data-stu-id="178fb-182">At run time, for the best performance, Copy Activity uses a value that is less than or equal to the value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="178fb-183">Verwijst naar Let op:</span><span class="sxs-lookup"><span data-stu-id="178fb-183">Points to note:</span></span>

* <span data-ttu-id="178fb-184">Als u gegevens tussen winkels op basis van bestanden, kopieert de **parallelCopies** bepalen de parallelle uitvoering op bestandsniveau.</span><span class="sxs-lookup"><span data-stu-id="178fb-184">When you copy data between file-based stores, the **parallelCopies** determine the parallelism at the file level.</span></span> <span data-ttu-id="178fb-185">De verdeling in segmenten binnen één bestand gebeurt onder automatisch en transparant en deze is ontworpen voor het gebruik van de meest geschikte chunkgrootte voor een bepaalde bron-gegevenstype store laden van gegevens in de parallelle en rechthoekige naar parallelCopies.</span><span class="sxs-lookup"><span data-stu-id="178fb-185">The chunking within a single file would happen underneath automatically and transparently, and it's designed to use the best suitable chunk size for a given source data store type to load data in parallel and orthogonal to parallelCopies.</span></span> <span data-ttu-id="178fb-186">Het werkelijke aantal parallelle kopieën data movement service wordt gebruikt voor de kopieerbewerking tijdens de uitvoering is niet meer dan het aantal bestanden die u hebt.</span><span class="sxs-lookup"><span data-stu-id="178fb-186">The actual number of parallel copies the data movement service uses for the copy operation at run time is no more than the number of files you have.</span></span> <span data-ttu-id="178fb-187">Als u het gedrag van de kopie is **mergeFile**, Kopieeractiviteit kan niet profiteren van bestandsniveau parallelle uitvoering.</span><span class="sxs-lookup"><span data-stu-id="178fb-187">If the copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="178fb-188">Wanneer u een waarde opgeven voor de **parallelCopies** eigenschap, moet u overwegen de toename van de belasting op de bron- en sink-gegevensarchieven en gateway als dit een hybride-kopie is.</span><span class="sxs-lookup"><span data-stu-id="178fb-188">When you specify a value for the **parallelCopies** property, consider the load increase on your source and sink data stores, and to gateway if it is a hybrid copy.</span></span> <span data-ttu-id="178fb-189">Dit gebeurt met name wanneer er meerdere activiteiten of gelijktijdige wordt uitgevoerd dezelfde activiteiten die hetzelfde gegevensarchief uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-189">This happens especially when you have multiple activities or concurrent runs of the same activities that run against the same data store.</span></span> <span data-ttu-id="178fb-190">Als u merkt dat het gegevensarchief of de Gateway met de belasting wordt overbelast, vermindert u de **parallelCopies** waarde om te helpen de belasting.</span><span class="sxs-lookup"><span data-stu-id="178fb-190">If you notice that either the data store or Gateway is overwhelmed with the load, decrease the **parallelCopies** value to relieve the load.</span></span>
* <span data-ttu-id="178fb-191">Als u gegevens van winkels die zich niet op basis van bestanden naar winkels op basis van een bestand kopieert, data movement service negeert de **parallelCopies** eigenschap.</span><span class="sxs-lookup"><span data-stu-id="178fb-191">When you copy data from stores that are not file-based to stores that are file-based, the data movement service ignores the **parallelCopies** property.</span></span> <span data-ttu-id="178fb-192">Zelfs als parallelle uitvoering is opgegeven, wordt deze niet toegepast in dit geval.</span><span class="sxs-lookup"><span data-stu-id="178fb-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="178fb-193">Moet u Data Management Gateway 1.11 of hoger gebruiken de **parallelCopies** functie als u een kopie van de hybride doet.</span><span class="sxs-lookup"><span data-stu-id="178fb-193">You must use Data Management Gateway version 1.11 or later to use the **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="178fb-194">Zie voor een beter gebruik van deze twee eigenschappen en voor het verbeteren van de doorvoer van uw gegevens verkeer de [steekproef gebruiksvoorbeelden](#case-study-use-parallel-copy).</span><span class="sxs-lookup"><span data-stu-id="178fb-194">To better use these two properties, and to enhance your data movement throughput, see the [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="178fb-195">U hoeft niet te configureren **parallelCopies** om te profiteren van het standaardgedrag.</span><span class="sxs-lookup"><span data-stu-id="178fb-195">You don't need to configure **parallelCopies** to take advantage of the default behavior.</span></span> <span data-ttu-id="178fb-196">Als u configureert en **parallelCopies** is te klein, meerdere cloud DMUs mogelijk niet volledig worden gebruikt.</span><span class="sxs-lookup"><span data-stu-id="178fb-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="178fb-197">Gevolgen van facturering</span><span class="sxs-lookup"><span data-stu-id="178fb-197">Billing impact</span></span>
<span data-ttu-id="178fb-198">Deze heeft **belangrijke** te onthouden dat u in rekening worden gebracht op basis van de totale tijd van de kopieerbewerking.</span><span class="sxs-lookup"><span data-stu-id="178fb-198">It's **important** to remember that you are charged based on the total time of the copy operation.</span></span> <span data-ttu-id="178fb-199">Als een taak kopiëren gebruikt voor één uur duren voordat aan één cloud-eenheid en nu het met vier cloud eenheden 15 minuten duurt, blijft de algehele factuur bijna hetzelfde.</span><span class="sxs-lookup"><span data-stu-id="178fb-199">If a copy job used to take one hour with one cloud unit and now it takes 15 minutes with four cloud units, the overall bill remains almost the same.</span></span> <span data-ttu-id="178fb-200">Bijvoorbeeld, u vier eenheden van de cloud.</span><span class="sxs-lookup"><span data-stu-id="178fb-200">For example, you use four cloud units.</span></span> <span data-ttu-id="178fb-201">De eerste cloud unit doorbrengt 10 minuten, de tweede waarde 10 minuten, de derde, 5 minuten, en de vierde, 5 minuten, allemaal in één Kopieeractiviteit uitvoeren.</span><span class="sxs-lookup"><span data-stu-id="178fb-201">The first cloud unit spends 10 minutes, the second one, 10 minutes, the third one, 5 minutes, and the fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="178fb-202">Worden in rekening gebracht voor het totaal aantal copy (gegevensverplaatsing)-tijd 10 + 10 + 5 + 5 = 30 minuten is.</span><span class="sxs-lookup"><span data-stu-id="178fb-202">You are charged for the total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="178fb-203">Met behulp van **parallelCopies** heeft geen invloed op de facturering.</span><span class="sxs-lookup"><span data-stu-id="178fb-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="178fb-204">Gefaseerde kopiëren</span><span class="sxs-lookup"><span data-stu-id="178fb-204">Staged copy</span></span>
<span data-ttu-id="178fb-205">Wanneer u gegevens uit een brongegevensarchief naar een gegevensopslag sink kopiëren, kunt u kiezen om het Blob-opslag gebruiken als een tussentijdse staging store.</span><span class="sxs-lookup"><span data-stu-id="178fb-205">When you copy data from a source data store to a sink data store, you might choose to use Blob storage as an interim staging store.</span></span> <span data-ttu-id="178fb-206">Fasering is vooral nuttig in de volgende gevallen:</span><span class="sxs-lookup"><span data-stu-id="178fb-206">Staging is especially useful in the following cases:</span></span>

1. <span data-ttu-id="178fb-207">**U wilt opnemen van gegevens uit verschillende gegevensarchieven in SQL Data Warehouse met PolyBase**.</span><span class="sxs-lookup"><span data-stu-id="178fb-207">**You want to ingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="178fb-208">SQL Data Warehouse gebruikmaakt van PolyBase als een mechanisme voor hoge gegevensdoorvoer een grote hoeveelheid gegevens laden in SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="178fb-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism to load a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="178fb-209">Echter de brongegevens moet zich in de Blob-opslag en het moet voldoen aan de aanvullende criteria.</span><span class="sxs-lookup"><span data-stu-id="178fb-209">However, the source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="178fb-210">Wanneer u gegevens uit een ander gegevensarchief dan Blob-opslag laden, kunt u gegevens kopiëren via fasering tussentijdse Blob-opslag kunt activeren.</span><span class="sxs-lookup"><span data-stu-id="178fb-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="178fb-211">In dat geval voert Data Factory de vereiste gegevenstransformaties om ervoor te zorgen dat deze voldoet aan de vereisten van PolyBase.</span><span class="sxs-lookup"><span data-stu-id="178fb-211">In that case, Data Factory performs the required data transformations to ensure that it meets the requirements of PolyBase.</span></span> <span data-ttu-id="178fb-212">Vervolgens wordt PolyBase gegevens laadt in SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="178fb-212">Then it uses PolyBase to load data into SQL Data Warehouse.</span></span> <span data-ttu-id="178fb-213">Zie voor meer informatie [gebruik PolyBase gegevens laadt in Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="178fb-213">For more details, see [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="178fb-214">Zie voor een overzicht met een gebruiksvoorbeeld [1 TB laden in Azure SQL Data Warehouse onder 15 minuten met Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="178fb-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="178fb-215">**Soms duurt even om uit te voeren van een hybride gegevensverplaatsing (dat wil zeggen kopiëren tussen een on-premises gegevens opslaan en een cloudgegevens kunnen worden opgeslagen) via een trage netwerkverbinding**.</span><span class="sxs-lookup"><span data-stu-id="178fb-215">**Sometimes it takes a while to perform a hybrid data movement (that is, to copy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="178fb-216">Om prestaties te verbeteren, kunt u de gegevens on-premises comprimeren zodat kost het minder tijd om gegevens te verplaatsen naar de staging gegevensopslag in de cloud.</span><span class="sxs-lookup"><span data-stu-id="178fb-216">To improve performance, you can compress the data on-premises so that it takes less time to move data to the staging data store in the cloud.</span></span> <span data-ttu-id="178fb-217">Vervolgens kunt u de gegevens in het archief met staging decomprimeren voordat u de gegevens in het gegevensarchief van de bestemming laadt.</span><span class="sxs-lookup"><span data-stu-id="178fb-217">Then you can decompress the data in the staging store before you load it into the destination data store.</span></span>
3. <span data-ttu-id="178fb-218">**U niet wilt openen van poorten dan poort 80 en 443 in uw firewall poort vanwege zakelijke IT-beleid**.</span><span class="sxs-lookup"><span data-stu-id="178fb-218">**You don't want to open ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="178fb-219">Wanneer u gegevens uit een on-premises gegevensopslag naar een Azure SQL Database-sink of een Azure SQL Data Warehouse sink kopiëren, moet u bijvoorbeeld uitgaande TCP-communicatie op poort 1433 voor zowel de Windows firewall en uw bedrijfsfirewall activeren.</span><span class="sxs-lookup"><span data-stu-id="178fb-219">For example, when you copy data from an on-premises data store to an Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need to activate outbound TCP communication on port 1433 for both the Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="178fb-220">In dit scenario te profiteren van de gateway naar gegevens eerst kopiëren naar een exemplaar van Blob-opslag-staging via HTTP of HTTPS op poort 443.</span><span class="sxs-lookup"><span data-stu-id="178fb-220">In this scenario, take advantage of the gateway to first copy data to a Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="178fb-221">Vervolgens de gegevens in SQL-Database of SQL Data Warehouse laden van fasering van Blob-opslag.</span><span class="sxs-lookup"><span data-stu-id="178fb-221">Then, load the data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="178fb-222">In deze stroom moet u geen poort 1433 inschakelen.</span><span class="sxs-lookup"><span data-stu-id="178fb-222">In this flow, you don't need to enable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="178fb-223">Hoe gefaseerde kopiëren werkt</span><span class="sxs-lookup"><span data-stu-id="178fb-223">How staged copy works</span></span>
<span data-ttu-id="178fb-224">Wanneer u de functie voor gefaseerde installatie activeert, eerst de gegevens gekopieerd uit de gegevensopslag van de bron in het gegevensarchief fasering (bring uw eigen).</span><span class="sxs-lookup"><span data-stu-id="178fb-224">When you activate the staging feature, first the data is copied from the source data store to the staging data store (bring your own).</span></span> <span data-ttu-id="178fb-225">Vervolgens is de gegevens uit de staging gegevensopslag gekopieerd naar het sink-gegevensarchief.</span><span class="sxs-lookup"><span data-stu-id="178fb-225">Next, the data is copied from the staging data store to the sink data store.</span></span> <span data-ttu-id="178fb-226">De stroom twee fasen voor u worden beheerd, Data Factory.</span><span class="sxs-lookup"><span data-stu-id="178fb-226">Data Factory automatically manages the two-stage flow for you.</span></span> <span data-ttu-id="178fb-227">Tijdelijke gegevens uit de tijdelijke opslag ruimt Data Factory ook nadat de gegevensverplaatsing voltooid is.</span><span class="sxs-lookup"><span data-stu-id="178fb-227">Data Factory also cleans up temporary data from the staging storage after the data movement is complete.</span></span>

<span data-ttu-id="178fb-228">In het scenario cloud kopiëren (bron- en sink gegevens opslaat in de cloud zijn), is geen gateway gebruikt.</span><span class="sxs-lookup"><span data-stu-id="178fb-228">In the cloud copy scenario (both source and sink data stores are in the cloud), gateway is not used.</span></span> <span data-ttu-id="178fb-229">De Data Factory-service voert de kopieerbewerkingen.</span><span class="sxs-lookup"><span data-stu-id="178fb-229">The Data Factory service performs the copy operations.</span></span>

![Gefaseerde kopiëren: cloudscenario](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="178fb-231">In het scenario met hybride kopiëren (bron op lokale en sink is in de cloud), de gateway worden gegevens uit de gegevensopslag van de bron verplaatst naar een gefaseerde installatie gegevensarchief.</span><span class="sxs-lookup"><span data-stu-id="178fb-231">In the hybrid copy scenario (source is on-premises and sink is in the cloud), the gateway moves data from the source data store to a staging data store.</span></span> <span data-ttu-id="178fb-232">Data Factory-service worden gegevens uit de staging gegevensopslag verplaatst naar het gegevensarchief sink.</span><span class="sxs-lookup"><span data-stu-id="178fb-232">Data Factory service moves data from the staging data store to the sink data store.</span></span> <span data-ttu-id="178fb-233">Kopiëren van gegevens uit een gegevensopslag cloud naar een on-premises gegevensopslag via fasering wordt ook ondersteund met de omgekeerde stroom.</span><span class="sxs-lookup"><span data-stu-id="178fb-233">Copying data from a cloud data store to an on-premises data store via staging also is supported with the reversed flow.</span></span>

![Gefaseerde kopiëren: hybride scenario](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="178fb-235">Wanneer u verplaatsing van gegevens met behulp van een gefaseerde installatie archief activeert, kunt u opgeven of u wilt dat de gegevens te comprimeren voordat u gegevens uit de gegevensopslag van de bron naar een tijdelijke of staging gegevensarchief, en vervolgens gedecomprimeerd voordat het verplaatsen van gegevens vanuit een tussentijdse of staging-gegevens opslaan in het gegevensarchief sink.</span><span class="sxs-lookup"><span data-stu-id="178fb-235">When you activate data movement by using a staging store, you can specify whether you want the data to be compressed before moving data from the source data store to an interim or staging data store, and then decompressed before moving data from an interim or staging data store to the sink data store.</span></span>

<span data-ttu-id="178fb-236">Op dit moment kunt kopiëren u gegevens tussen twee on-premises gegevensopslagexemplaren met behulp van een gefaseerde installatie archief niet.</span><span class="sxs-lookup"><span data-stu-id="178fb-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="178fb-237">We verwachten dat deze optie om te zijn binnenkort beschikbaar.</span><span class="sxs-lookup"><span data-stu-id="178fb-237">We expect this option to be available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="178fb-238">Configuratie</span><span class="sxs-lookup"><span data-stu-id="178fb-238">Configuration</span></span>
<span data-ttu-id="178fb-239">Configureer de **enableStaging** instellen in de kopieerbewerking om op te geven of u wilt dat de gegevens naar het tijdelijk opgeslagen in blobopslag voordat u deze naar een doelgegevensopslagplaats laden.</span><span class="sxs-lookup"><span data-stu-id="178fb-239">Configure the **enableStaging** setting in Copy Activity to specify whether you want the data to be staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="178fb-240">Als u instelt **enableStaging** om op te geven waar, de aanvullende eigenschappen in de volgende tabel weergegeven.</span><span class="sxs-lookup"><span data-stu-id="178fb-240">When you set **enableStaging** to TRUE, specify the additional properties listed in the next table.</span></span> <span data-ttu-id="178fb-241">Als u niet hebt, moet u ook voor het maken van een Azure Storage of opslag gedeelde handtekening-gekoppelde access-service voor fasering.</span><span class="sxs-lookup"><span data-stu-id="178fb-241">If you don’t have one, you also need to create an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="178fb-242">Eigenschap</span><span class="sxs-lookup"><span data-stu-id="178fb-242">Property</span></span> | <span data-ttu-id="178fb-243">Beschrijving</span><span class="sxs-lookup"><span data-stu-id="178fb-243">Description</span></span> | <span data-ttu-id="178fb-244">Standaardwaarde</span><span class="sxs-lookup"><span data-stu-id="178fb-244">Default value</span></span> | <span data-ttu-id="178fb-245">Vereist</span><span class="sxs-lookup"><span data-stu-id="178fb-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="178fb-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="178fb-246">**enableStaging**</span></span> |<span data-ttu-id="178fb-247">Geef op of u wilt kopiëren van gegevens via een tussentijdse staging-store.</span><span class="sxs-lookup"><span data-stu-id="178fb-247">Specify whether you want to copy data via an interim staging store.</span></span> |<span data-ttu-id="178fb-248">False</span><span class="sxs-lookup"><span data-stu-id="178fb-248">False</span></span> |<span data-ttu-id="178fb-249">Nee</span><span class="sxs-lookup"><span data-stu-id="178fb-249">No</span></span> |
| <span data-ttu-id="178fb-250">**linkedServiceName**</span><span class="sxs-lookup"><span data-stu-id="178fb-250">**linkedServiceName**</span></span> |<span data-ttu-id="178fb-251">Geef de naam van een [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) of [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) gekoppelde service die verwijst naar het exemplaar van de opslag die u als een tussentijdse staging store gebruiken.</span><span class="sxs-lookup"><span data-stu-id="178fb-251">Specify the name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers to the instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="178fb-252">U kunt opslag met een shared access signature niet gebruiken om gegevens te laden in SQL Data Warehouse met PolyBase.</span><span class="sxs-lookup"><span data-stu-id="178fb-252">You cannot use Storage with a shared access signature to load data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="178fb-253">U kunt deze gebruiken in alle andere scenario's.</span><span class="sxs-lookup"><span data-stu-id="178fb-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="178fb-254">N.v.t.</span><span class="sxs-lookup"><span data-stu-id="178fb-254">N/A</span></span> |<span data-ttu-id="178fb-255">Ja, wanneer **enableStaging** is ingesteld op TRUE</span><span class="sxs-lookup"><span data-stu-id="178fb-255">Yes, when **enableStaging** is set to TRUE</span></span> |
| <span data-ttu-id="178fb-256">**pad**</span><span class="sxs-lookup"><span data-stu-id="178fb-256">**path**</span></span> |<span data-ttu-id="178fb-257">Geef het pad voor Blob-opslag die u wilt de voorbereide gegevens bevatten.</span><span class="sxs-lookup"><span data-stu-id="178fb-257">Specify the Blob storage path that you want to contain the staged data.</span></span> <span data-ttu-id="178fb-258">Als u niet een pad opgeeft, maakt de service een container voor het opslaan van tijdelijke gegevens.</span><span class="sxs-lookup"><span data-stu-id="178fb-258">If you do not provide a path, the service creates a container to store temporary data.</span></span> <br/><br/> <span data-ttu-id="178fb-259">Geef een pad op als u opslag met een shared access signature gebruiken of u tijdelijke gegevens op een specifieke locatie te vereisen.</span><span class="sxs-lookup"><span data-stu-id="178fb-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data to be in a specific location.</span></span> |<span data-ttu-id="178fb-260">N.v.t.</span><span class="sxs-lookup"><span data-stu-id="178fb-260">N/A</span></span> |<span data-ttu-id="178fb-261">Nee</span><span class="sxs-lookup"><span data-stu-id="178fb-261">No</span></span> |
| <span data-ttu-id="178fb-262">**enableCompression**</span><span class="sxs-lookup"><span data-stu-id="178fb-262">**enableCompression**</span></span> |<span data-ttu-id="178fb-263">Hiermee geeft u op of de gegevens moeten worden gecomprimeerd voordat deze is gekopieerd naar de bestemming.</span><span class="sxs-lookup"><span data-stu-id="178fb-263">Specifies whether data should be compressed before it is copied to the destination.</span></span> <span data-ttu-id="178fb-264">Deze instelling beperkt de hoeveelheid gegevens die worden overgedragen.</span><span class="sxs-lookup"><span data-stu-id="178fb-264">This setting reduces the volume of data being transferred.</span></span> |<span data-ttu-id="178fb-265">False</span><span class="sxs-lookup"><span data-stu-id="178fb-265">False</span></span> |<span data-ttu-id="178fb-266">Nee</span><span class="sxs-lookup"><span data-stu-id="178fb-266">No</span></span> |

<span data-ttu-id="178fb-267">Hier volgt een voorbeeld-definitie van de Kopieeractiviteit met de eigenschappen die worden beschreven in de voorgaande tabel:</span><span class="sxs-lookup"><span data-stu-id="178fb-267">Here's a sample definition of Copy Activity with the properties that are described in the preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="178fb-268">Gevolgen van facturering</span><span class="sxs-lookup"><span data-stu-id="178fb-268">Billing impact</span></span>
<span data-ttu-id="178fb-269">U kosten in rekening gebracht op basis van twee stappen: kopieer duur en type kopiëren.</span><span class="sxs-lookup"><span data-stu-id="178fb-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="178fb-270">Wanneer u in een cloud gekopieerde (gegevens uit een cloud-gegevensarchief kopiëren naar een andere cloud data store) voor fasering u in rekening worden gebracht de [som van de duur van de kopie voor stap 1 en 2] x [cloud kopie eenheidsprijs].</span><span class="sxs-lookup"><span data-stu-id="178fb-270">When you use staging during a cloud copy (copying data from a cloud data store to another cloud data store), you are charged the [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="178fb-271">Wanneer u in een hybride gekopieerde (gegevens uit een on-premises gegevensopslag kopiëren naar een gegevensopslag cloud) voor fasering u in rekening worden gebracht [duur hybride kopiëren] x [hybride kopie eenheidsprijs] + [cloud kopie duur] x [cloud kopie eenheidsprijs].</span><span class="sxs-lookup"><span data-stu-id="178fb-271">When you use staging during a hybrid copy (copying data from an on-premises data store to a cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="178fb-272">Prestaties afstemmen stappen</span><span class="sxs-lookup"><span data-stu-id="178fb-272">Performance tuning steps</span></span>
<span data-ttu-id="178fb-273">We raden aan dat u deze stappen nemen om afstemmen van de prestaties van uw Data Factory-service met de Kopieeractiviteit:</span><span class="sxs-lookup"><span data-stu-id="178fb-273">We suggest that you take these steps to tune the performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="178fb-274">**Stel een basislijn vast**.</span><span class="sxs-lookup"><span data-stu-id="178fb-274">**Establish a baseline**.</span></span> <span data-ttu-id="178fb-275">Tijdens de ontwikkelingsfase uw pijplijn te testen met behulp van de Kopieeractiviteit tegen een representatieve steekproef.</span><span class="sxs-lookup"><span data-stu-id="178fb-275">During the development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="178fb-276">Kunt u de Data Factory [segmentering model](data-factory-scheduling-and-execution.md) te beperken van de hoeveelheid gegevens die u samenwerkt.</span><span class="sxs-lookup"><span data-stu-id="178fb-276">You can use the Data Factory [slicing model](data-factory-scheduling-and-execution.md) to limit the amount of data you work with.</span></span>

   <span data-ttu-id="178fb-277">Uitvoeringstijd en prestatiekenmerken verzamelen met behulp van de **bewaking en beheer-App**.</span><span class="sxs-lookup"><span data-stu-id="178fb-277">Collect execution time and performance characteristics by using the **Monitoring and Management App**.</span></span> <span data-ttu-id="178fb-278">Kies **Monitor & beheren** op de startpagina van de Data Factory.</span><span class="sxs-lookup"><span data-stu-id="178fb-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="178fb-279">Kies in de structuurweergave de **uitvoergegevensset**.</span><span class="sxs-lookup"><span data-stu-id="178fb-279">In the tree view, choose the **output dataset**.</span></span> <span data-ttu-id="178fb-280">In de **Activiteitsvensters** Kies de Kopieeractiviteit uitvoeren.</span><span class="sxs-lookup"><span data-stu-id="178fb-280">In the **Activity Windows** list, choose the Copy Activity run.</span></span> <span data-ttu-id="178fb-281">**Activiteit Windows** geeft een lijst van de Kopieeractiviteit duur en de grootte van de gegevens die worden gekopieerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-281">**Activity Windows** lists the Copy Activity duration and the size of the data that's copied.</span></span> <span data-ttu-id="178fb-282">De doorvoer wordt vermeld in **activiteit venster Explorer**.</span><span class="sxs-lookup"><span data-stu-id="178fb-282">The throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="178fb-283">Zie voor meer informatie over de app, [bewaken en beheren van Azure Data Factory-pijplijnen met behulp van de bewaking en beheer-App](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="178fb-283">To learn more about the app, see [Monitor and manage Azure Data Factory pipelines by using the Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![Details uitvoering van activiteit](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="178fb-285">Later in dit artikel kunt u de prestaties en de configuratie van uw scenario om door te kopiëren van de activiteit vergelijken [prestaties verwijzing](#performance-reference) van onze tests.</span><span class="sxs-lookup"><span data-stu-id="178fb-285">Later in the article, you can compare the performance and configuration of your scenario to Copy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="178fb-286">**Diagnose en prestaties te optimaliseren**.</span><span class="sxs-lookup"><span data-stu-id="178fb-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="178fb-287">Als de prestaties die u merkt niet voldoet aan uw verwachtingen, moet u het identificeren van knelpunten.</span><span class="sxs-lookup"><span data-stu-id="178fb-287">If the performance you observe doesn't meet your expectations, you need to identify performance bottlenecks.</span></span> <span data-ttu-id="178fb-288">Vervolgens optimaliseren als u wilt verwijderen of verklein het effect van knelpunten.</span><span class="sxs-lookup"><span data-stu-id="178fb-288">Then, optimize performance to remove or reduce the effect of bottlenecks.</span></span> <span data-ttu-id="178fb-289">Een volledige beschrijving van de prestatiediagnose valt buiten het bereik van dit artikel, maar hier volgen enkele algemene overwegingen:</span><span class="sxs-lookup"><span data-stu-id="178fb-289">A full description of performance diagnosis is beyond the scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="178fb-290">Prestatiefuncties:</span><span class="sxs-lookup"><span data-stu-id="178fb-290">Performance features:</span></span>
     * [<span data-ttu-id="178fb-291">Parallelle kopie</span><span class="sxs-lookup"><span data-stu-id="178fb-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="178fb-292">Cloud data movement-eenheden</span><span class="sxs-lookup"><span data-stu-id="178fb-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="178fb-293">Gefaseerde kopiëren</span><span class="sxs-lookup"><span data-stu-id="178fb-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="178fb-294">Data Management Gateway-schaalbaarheid</span><span class="sxs-lookup"><span data-stu-id="178fb-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="178fb-295">Gegevensbeheergateway</span><span class="sxs-lookup"><span data-stu-id="178fb-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="178fb-296">Bron</span><span class="sxs-lookup"><span data-stu-id="178fb-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="178fb-297">Sink</span><span class="sxs-lookup"><span data-stu-id="178fb-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="178fb-298">Serialisatie en deserialisatie</span><span class="sxs-lookup"><span data-stu-id="178fb-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="178fb-299">Compressie</span><span class="sxs-lookup"><span data-stu-id="178fb-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="178fb-300">Kolomtoewijzing</span><span class="sxs-lookup"><span data-stu-id="178fb-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="178fb-301">Andere overwegingen</span><span class="sxs-lookup"><span data-stu-id="178fb-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="178fb-302">**Vouw de configuratie op uw volledige gegevensset**.</span><span class="sxs-lookup"><span data-stu-id="178fb-302">**Expand the configuration to your entire data set**.</span></span> <span data-ttu-id="178fb-303">Wanneer u tevreden met de prestaties en resultaten bent, kunt u de definitie en de actieve periode van de pijplijn voor uw volledige gegevensset uitvouwen.</span><span class="sxs-lookup"><span data-stu-id="178fb-303">When you're satisfied with the execution results and performance, you can expand the definition and pipeline active period to cover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="178fb-304">Overwegingen voor Data Management Gateway</span><span class="sxs-lookup"><span data-stu-id="178fb-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="178fb-305">**Gateway setup**: het is raadzaam dat u een specifieke host Data Management Gateway-machine.</span><span class="sxs-lookup"><span data-stu-id="178fb-305">**Gateway setup**: We recommend that you use a dedicated machine to host Data Management Gateway.</span></span> <span data-ttu-id="178fb-306">Zie [overwegingen voor het gebruik van Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span><span class="sxs-lookup"><span data-stu-id="178fb-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="178fb-307">**Bewaking van de gateway en scale-up/out**: één logische gateway met een of meer knooppunten van de gateway meerdere Kopieeractiviteit wordt uitgevoerd op hetzelfde moment gelijktijdig kan fungeren.</span><span class="sxs-lookup"><span data-stu-id="178fb-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at the same time concurrently.</span></span> <span data-ttu-id="178fb-308">U kunt vrijwel in realtime momentopname van Resourcegebruik (CPU, geheugen, network(in/out), enz.) weergeven op een computer met de gateway en het aantal gelijktijdige taken uitgevoerd versus limiet in de Azure portal, Zie [Monitor gateway in de portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span><span class="sxs-lookup"><span data-stu-id="178fb-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as the number of concurrent jobs running versus limit in the Azure portal, see [Monitor gateway in the portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="178fb-309">Als u een zware nodig op hybride gegevensverplaatsing met een groot aantal gelijktijdige kopie activiteit wordt uitgevoerd of grote hoeveelheid gegevens hebt te kopiëren, rekening moet houden, [omhoog schalen of uitschalen gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) om te voorkomen beter gebruikmaken van de bron- of inrichten meer resource zorgen kopiëren.</span><span class="sxs-lookup"><span data-stu-id="178fb-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data to copy, consider to [scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as to better utilize your resource or to provision more resource to empower copy.</span></span> 

## <a name="considerations-for-the-source"></a><span data-ttu-id="178fb-310">Overwegingen voor de bron</span><span class="sxs-lookup"><span data-stu-id="178fb-310">Considerations for the source</span></span>
### <a name="general"></a><span data-ttu-id="178fb-311">Algemeen</span><span class="sxs-lookup"><span data-stu-id="178fb-311">General</span></span>
<span data-ttu-id="178fb-312">Zorg ervoor dat het onderliggende gegevensarchief niet door andere werkbelastingen die worden uitgevoerd op of tegen deze wordt overbelast.</span><span class="sxs-lookup"><span data-stu-id="178fb-312">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="178fb-313">Zie voor Microsoft-gegevensarchieven, [controleren en afstemmen van onderwerpen](#performance-reference) die specifiek zijn voor de opgeslagen gegevens en u gegevens opslaan prestatiekenmerken, reactietijden minimaliseren en maximaliseren van doorvoer laten zien.</span><span class="sxs-lookup"><span data-stu-id="178fb-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific to data stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="178fb-314">Als u gegevens van Blob-opslag naar SQL Data Warehouse kopiëren, overweeg dan **PolyBase** op de prestaties verbeteren.</span><span class="sxs-lookup"><span data-stu-id="178fb-314">If you copy data from Blob storage to SQL Data Warehouse, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="178fb-315">Zie [gebruik PolyBase gegevens laadt in Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="178fb-315">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="178fb-316">Zie voor een overzicht met een gebruiksvoorbeeld [1 TB laden in Azure SQL Data Warehouse onder 15 minuten met Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="178fb-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="178fb-317">Opgeslagen gegevens op basis van bestanden</span><span class="sxs-lookup"><span data-stu-id="178fb-317">File-based data stores</span></span>
<span data-ttu-id="178fb-318">*(Inclusief Blob storage, Data Lake Store, Amazon S3, on-premises bestandssystemen en lokale HDFS)*</span><span class="sxs-lookup"><span data-stu-id="178fb-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="178fb-319">**Gemiddelde grootte en het aantal bestanden**: Kopieeractiviteit overgedragen gegevens één bestand tegelijk.</span><span class="sxs-lookup"><span data-stu-id="178fb-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="178fb-320">Met dezelfde hoeveelheid gegevens die moet worden verplaatst, is de totale doorvoer lagere als de gegevens van veel kleine bestanden in plaats van enkele grote bestanden vanwege de bootstrap-fase voor elk bestand bestaat.</span><span class="sxs-lookup"><span data-stu-id="178fb-320">With the same amount of data to be moved, the overall throughput is lower if the data consists of many small files rather than a few large files due to the bootstrap phase for each file.</span></span> <span data-ttu-id="178fb-321">Indien mogelijk, daarom kleine bestanden combineren in grote bestanden krijgen hogere doorvoer.</span><span class="sxs-lookup"><span data-stu-id="178fb-321">Therefore, if possible, combine small files into larger files to gain higher throughput.</span></span>
* <span data-ttu-id="178fb-322">**Bestand-indeling en compressie**: Zie voor meer manieren om prestaties te verbeteren de [overwegingen voor serialisatie en deserialisatie](#considerations-for-serialization-and-deserialization) en [overwegingen voor compressie](#considerations-for-compression) secties.</span><span class="sxs-lookup"><span data-stu-id="178fb-322">**File format and compression**: For more ways to improve performance, see the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="178fb-323">Voor de **lokaal bestandssysteem** scenario waarin **Data Management Gateway** is vereist, Zie de [overwegingen voor Data Management Gateway](#considerations-for-data-management-gateway) sectie.</span><span class="sxs-lookup"><span data-stu-id="178fb-323">For the **on-premises file system** scenario, in which **Data Management Gateway** is required, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="178fb-324">Opgeslagen relationele gegevens</span><span class="sxs-lookup"><span data-stu-id="178fb-324">Relational data stores</span></span>
<span data-ttu-id="178fb-325">*(Inclusief SQL-Database. SQL datawarehouse; Amazon Redshift; SQL Server-databases. (en Oracle, MySQL, DB2 Teradata, Sybase en PostgreSQL-databases, enz.)*</span><span class="sxs-lookup"><span data-stu-id="178fb-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="178fb-326">**Patroon voor gegevens**: uw tabelschema is van invloed op de doorvoer van de kopie.</span><span class="sxs-lookup"><span data-stu-id="178fb-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="178fb-327">Een grote rijgrootte biedt een betere prestaties dan kleine rijgrootte dezelfde hoeveelheid gegevens te kopiëren.</span><span class="sxs-lookup"><span data-stu-id="178fb-327">A large row size gives you a better performance than small row size, to copy the same amount of data.</span></span> <span data-ttu-id="178fb-328">De reden is dat de database minder batches van gegevens die minder rijen bevatten efficiënter kunt ophalen.</span><span class="sxs-lookup"><span data-stu-id="178fb-328">The reason is that the database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="178fb-329">**Query of opgeslagen procedure**: optimaliseren van de logica van de query of een opgeslagen procedure die u opgeeft in de bron van de Kopieeractiviteit efficiënter gegevens ophaalt.</span><span class="sxs-lookup"><span data-stu-id="178fb-329">**Query or stored procedure**: Optimize the logic of the query or stored procedure you specify in the Copy Activity source to fetch data more efficiently.</span></span>
* <span data-ttu-id="178fb-330">Voor **lokale relationele databases**, zoals SQL Server en Oracle, waarvoor het gebruik van **Data Management Gateway**, Zie de [overwegingen voor Data Management Gateway](#considerations-on-data-management-gateway) sectie.</span><span class="sxs-lookup"><span data-stu-id="178fb-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-the-sink"></a><span data-ttu-id="178fb-331">Overwegingen voor de sink</span><span class="sxs-lookup"><span data-stu-id="178fb-331">Considerations for the sink</span></span>
### <a name="general"></a><span data-ttu-id="178fb-332">Algemeen</span><span class="sxs-lookup"><span data-stu-id="178fb-332">General</span></span>
<span data-ttu-id="178fb-333">Zorg ervoor dat het onderliggende gegevensarchief niet door andere werkbelastingen die worden uitgevoerd op of tegen deze wordt overbelast.</span><span class="sxs-lookup"><span data-stu-id="178fb-333">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="178fb-334">Raadpleeg voor Microsoft-gegevensarchieven, [controleren en afstemmen van onderwerpen](#performance-reference) die specifiek zijn voor de gegevensarchieven.</span><span class="sxs-lookup"><span data-stu-id="178fb-334">For Microsoft data stores, refer to [monitoring and tuning topics](#performance-reference) that are specific to data stores.</span></span> <span data-ttu-id="178fb-335">Deze onderwerpen kunnen u helpen begrijpen data store prestatiekenmerken en hoe minimaliseren responstijden en het maximaliseren van doorvoer.</span><span class="sxs-lookup"><span data-stu-id="178fb-335">These topics can help you understand data store performance characteristics and how to minimize response times and maximize throughput.</span></span>

<span data-ttu-id="178fb-336">Als u gegevens van kopieert **Blob storage** naar **SQL Data Warehouse**, kunt u overwegen **PolyBase** op de prestaties verbeteren.</span><span class="sxs-lookup"><span data-stu-id="178fb-336">If you are copying data from **Blob storage** to **SQL Data Warehouse**, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="178fb-337">Zie [gebruik PolyBase gegevens laadt in Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="178fb-337">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="178fb-338">Zie voor een overzicht met een gebruiksvoorbeeld [1 TB laden in Azure SQL Data Warehouse onder 15 minuten met Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="178fb-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="178fb-339">Opgeslagen gegevens op basis van bestanden</span><span class="sxs-lookup"><span data-stu-id="178fb-339">File-based data stores</span></span>
<span data-ttu-id="178fb-340">*(Inclusief Blob storage, Data Lake Store, Amazon S3, on-premises bestandssystemen en lokale HDFS)*</span><span class="sxs-lookup"><span data-stu-id="178fb-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="178fb-341">**Kopieer gedrag**: als u gegevens in een store, andere bestandsgebaseerde gegevens kopieert, Kopieeractiviteit heeft drie opties via de **copyBehavior** eigenschap.</span><span class="sxs-lookup"><span data-stu-id="178fb-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via the **copyBehavior** property.</span></span> <span data-ttu-id="178fb-342">Deze hiërarchie van bewaart, hiërarchie worden samengevoegd of bestanden worden samengevoegd.</span><span class="sxs-lookup"><span data-stu-id="178fb-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="178fb-343">Voor het behouden of plat hiërarchie een weinig of geen prestatieoverhead, maar samenvoegen van bestanden veroorzaakt prestatieoverhead te verhogen.</span><span class="sxs-lookup"><span data-stu-id="178fb-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead to increase.</span></span>
* <span data-ttu-id="178fb-344">**Bestand-indeling en compressie**: Zie de [overwegingen voor serialisatie en deserialisatie](#considerations-for-serialization-and-deserialization) en [overwegingen voor compressie](#considerations-for-compression) secties voor meer manieren om prestaties te verbeteren.</span><span class="sxs-lookup"><span data-stu-id="178fb-344">**File format and compression**: See the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways to improve performance.</span></span>
* <span data-ttu-id="178fb-345">**BLOB-opslag**: op dit moment Blob storage ondersteunt alleen blok-blobs voor geoptimaliseerde gegevensoverdracht en doorvoer.</span><span class="sxs-lookup"><span data-stu-id="178fb-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="178fb-346">Voor **lokale bestandssystemen** scenario's waarvoor het gebruik van **Data Management Gateway**, Zie de [overwegingen voor Data Management Gateway](#considerations-for-data-management-gateway) sectie.</span><span class="sxs-lookup"><span data-stu-id="178fb-346">For **on-premises file systems** scenarios that require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="178fb-347">Opgeslagen relationele gegevens</span><span class="sxs-lookup"><span data-stu-id="178fb-347">Relational data stores</span></span>
<span data-ttu-id="178fb-348">*(Inclusief SQL-Database, SQL Data Warehouse, SQL Server-databases en Oracle-databases)*</span><span class="sxs-lookup"><span data-stu-id="178fb-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="178fb-349">**Kopieer gedrag**: afhankelijk van de eigenschappen die u hebt ingesteld voor **sqlSink**, Kopieeractiviteit schrijft gegevens naar de doeldatabase op verschillende manieren.</span><span class="sxs-lookup"><span data-stu-id="178fb-349">**Copy behavior**: Depending on the properties you've set for **sqlSink**, Copy Activity writes data to the destination database in different ways.</span></span>
  * <span data-ttu-id="178fb-350">Standaard toevoegen data movement service gebruikt de bulksgewijs kopiëren API om gegevens in te voegen modus, die de beste prestaties biedt.</span><span class="sxs-lookup"><span data-stu-id="178fb-350">By default, the data movement service uses the Bulk Copy API to insert data in append mode, which provides the best performance.</span></span>
  * <span data-ttu-id="178fb-351">Als u een opgeslagen procedure in de sink is geconfigureerd, geldt de database de ene gegevensrij tegelijk in plaats van als bulksgewijs laden.</span><span class="sxs-lookup"><span data-stu-id="178fb-351">If you configure a stored procedure in the sink, the database applies the data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="178fb-352">Prestaties aanzienlijk verwijderd.</span><span class="sxs-lookup"><span data-stu-id="178fb-352">Performance drops significantly.</span></span> <span data-ttu-id="178fb-353">Als uw gegevensset groot is, indien van toepassing, overweeg over te schakelen voor het gebruik van de **sqlWriterCleanupScript** eigenschap.</span><span class="sxs-lookup"><span data-stu-id="178fb-353">If your data set is large, when applicable, consider switching to using the **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="178fb-354">Als u configureert de **sqlWriterCleanupScript** eigenschap voor elke kopie-activiteit uitgevoerd, de service activeert het script en u de bulksgewijs kopiëren API gebruiken voor het invoegen van de gegevens.</span><span class="sxs-lookup"><span data-stu-id="178fb-354">If you configure the **sqlWriterCleanupScript** property for each Copy Activity run, the service triggers the script, and then you use the Bulk Copy API to insert the data.</span></span> <span data-ttu-id="178fb-355">Bijvoorbeeld, als u wilt overschrijven de gehele tabel met de meest recente gegevens, kunt u een script voor het eerst alle records verwijderd voordat de nieuwe gegevens van de bron voor bulksgewijs laden.</span><span class="sxs-lookup"><span data-stu-id="178fb-355">For example, to overwrite the entire table with the latest data, you can specify a script to first delete all records before bulk-loading the new data from the source.</span></span>
* <span data-ttu-id="178fb-356">**Gegevensgrootte patroon en batch**:</span><span class="sxs-lookup"><span data-stu-id="178fb-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="178fb-357">Uw tabelschema is van invloed op de doorvoer van de kopie.</span><span class="sxs-lookup"><span data-stu-id="178fb-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="178fb-358">Als u wilt kopiëren dezelfde hoeveelheid gegevens, biedt een grote rijgrootte u betere prestaties dan een kleine rijgrootte omdat de database kan efficiënter minder batches van gegevens worden doorgevoerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-358">To copy the same amount of data, a large row size gives you better performance than a small row size because the database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="178fb-359">Kopieeractiviteit voegt de gegevens in een reeks van batches.</span><span class="sxs-lookup"><span data-stu-id="178fb-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="178fb-360">U kunt het aantal rijen in een batch instellen met behulp van de **writeBatchSize** eigenschap.</span><span class="sxs-lookup"><span data-stu-id="178fb-360">You can set the number of rows in a batch by using the **writeBatchSize** property.</span></span> <span data-ttu-id="178fb-361">Als uw gegevens altijd kleine rijen, kunt u instellen de **writeBatchSize** eigenschap met een hogere waarde om te profiteren van lagere overhead van de batch- en hogere doorvoer.</span><span class="sxs-lookup"><span data-stu-id="178fb-361">If your data has small rows, you can set the **writeBatchSize** property with a higher value to benefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="178fb-362">Als de rijgrootte van uw gegevens te groot is, Wees voorzichtig wanneer u verhogen **writeBatchSize**.</span><span class="sxs-lookup"><span data-stu-id="178fb-362">If the row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="178fb-363">Een hoge waarde kan leiden tot een exemplaar is mislukt vanwege overbelasting van de database.</span><span class="sxs-lookup"><span data-stu-id="178fb-363">A high value might lead to a copy failure caused by overloading the database.</span></span>
* <span data-ttu-id="178fb-364">Voor **lokale relationele databases** , zoals SQL Server en Oracle, waarvoor het gebruik van **Data Management Gateway**, Zie de [overwegingen voor Data Management Gateway](#considerations-for-data-management-gateway)sectie.</span><span class="sxs-lookup"><span data-stu-id="178fb-364">For **on-premises relational databases** like SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="178fb-365">NoSQL-opslag</span><span class="sxs-lookup"><span data-stu-id="178fb-365">NoSQL stores</span></span>
<span data-ttu-id="178fb-366">*(Inclusief Table storage en Azure Cosmos DB)*</span><span class="sxs-lookup"><span data-stu-id="178fb-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="178fb-367">Voor **tabel opslag**:</span><span class="sxs-lookup"><span data-stu-id="178fb-367">For **Table storage**:</span></span>
  * <span data-ttu-id="178fb-368">**Partitie**: vermindert de prestaties aanzienlijk schrijven van gegevens naar interleaved partities.</span><span class="sxs-lookup"><span data-stu-id="178fb-368">**Partition**: Writing data to interleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="178fb-369">Sorteren van de brongegevens op partitiesleutel, zodat de gegevens efficiënt in één partitie wordt ingevoegd na de andere, of aanpassen van de logica voor het schrijven van de gegevens aan één partitie.</span><span class="sxs-lookup"><span data-stu-id="178fb-369">Sort your source data by partition key so that the data is inserted efficiently into one partition after another, or adjust the logic to write the data to a single partition.</span></span>
* <span data-ttu-id="178fb-370">Voor **Azure Cosmos DB**:</span><span class="sxs-lookup"><span data-stu-id="178fb-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="178fb-371">**Batchgrootte**: de **writeBatchSize** eigenschap stelt u het aantal parallelle aanvragen naar de service Azure Cosmos DB om documenten te maken.</span><span class="sxs-lookup"><span data-stu-id="178fb-371">**Batch size**: The **writeBatchSize** property sets the number of parallel requests to the Azure Cosmos DB service to create documents.</span></span> <span data-ttu-id="178fb-372">U kunt betere prestaties verwachten wanneer u verhogen **writeBatchSize** omdat meer parallelle aanvragen worden verzonden naar Azure Cosmos DB.</span><span class="sxs-lookup"><span data-stu-id="178fb-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent to Azure Cosmos DB.</span></span> <span data-ttu-id="178fb-373">Gecontroleerd echter beperken wanneer u schrijft naar Azure Cosmos-DB (het foutbericht is 'aanvraagsnelheid is hoog').</span><span class="sxs-lookup"><span data-stu-id="178fb-373">However, watch for throttling when you write to Azure Cosmos DB (the error message is "Request rate is large").</span></span> <span data-ttu-id="178fb-374">Verschillende factoren kunnen leiden tot het aantal termen in de documenten en de doelverzameling indexeringsbeleid beperking, met inbegrip van de grootte van het document.</span><span class="sxs-lookup"><span data-stu-id="178fb-374">Various factors can cause throttling, including document size, the number of terms in the documents, and the target collection's indexing policy.</span></span> <span data-ttu-id="178fb-375">Overweeg een betere verzameling, bijvoorbeeld S3 zodat hogere doorvoer van de kopie.</span><span class="sxs-lookup"><span data-stu-id="178fb-375">To achieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="178fb-376">Overwegingen voor serialisatie en deserialisatie</span><span class="sxs-lookup"><span data-stu-id="178fb-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="178fb-377">Serialisatie en deserialisatie kunnen optreden wanneer uw gegevensset invoer of uitvoer gegevensset een bestand is.</span><span class="sxs-lookup"><span data-stu-id="178fb-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="178fb-378">Zie [ondersteunde indelingen voor bestands- en compressie](data-factory-supported-file-and-compression-formats.md) met meer informatie over ondersteunde bestandsindelingen door Kopieeractiviteit.</span><span class="sxs-lookup"><span data-stu-id="178fb-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="178fb-379">**Kopieer gedrag**:</span><span class="sxs-lookup"><span data-stu-id="178fb-379">**Copy behavior**:</span></span>

* <span data-ttu-id="178fb-380">Kopiëren van bestanden tussen gegevensarchieven op basis van bestanden:</span><span class="sxs-lookup"><span data-stu-id="178fb-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="178fb-381">Een binaire kopiëren zonder een serialiseren of deserialiseren als invoer en uitvoer gegevenssets beide zijn met dezelfde of geen bestandsindelingsinstellingen, data movement service worden uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-381">When input and output data sets both have the same or no file format settings, the data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="178fb-382">Er is een hogere doorvoer in vergelijking met het scenario, waarin de bron- en sink-bestandsindelingsinstellingen zich van elkaar verschillen.</span><span class="sxs-lookup"><span data-stu-id="178fb-382">You see a higher throughput compared to the scenario, in which the source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="178fb-383">Als invoer en uitvoer gegevenssets beide zijn in tekstindeling en alleen de codering type anders is, data movement service biedt alleen codering conversie.</span><span class="sxs-lookup"><span data-stu-id="178fb-383">When input and output data sets both are in text format and only the encoding type is different, the data movement service only does encoding conversion.</span></span> <span data-ttu-id="178fb-384">Deze bevat niet alle serialisatie en deserialisatie, waardoor overhead vergeleken met een kopie van de binaire prestaties.</span><span class="sxs-lookup"><span data-stu-id="178fb-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared to a binary copy.</span></span>
  * <span data-ttu-id="178fb-385">Als invoer en uitvoer gegevenssets beide zijn met verschillende bestandsindelingen of verschillende configuraties, zoals scheidingstekens, data movement service deserializes brongegevens stream, transformeren en deze vervolgens in de indeling van de uitvoer die u hebt opgegeven te serialiseren.</span><span class="sxs-lookup"><span data-stu-id="178fb-385">When input and output data sets both have different file formats or different configurations, like delimiters, the data movement service deserializes source data to stream, transform, and then serialize it into the output format you indicated.</span></span> <span data-ttu-id="178fb-386">Deze bewerking leidt tot een veel grotere rol performance overhead ten opzichte van andere scenario's.</span><span class="sxs-lookup"><span data-stu-id="178fb-386">This operation results in a much more significant performance overhead compared to other scenarios.</span></span>
* <span data-ttu-id="178fb-387">Als u kopieert bestanden naar een gegevensopslag die niet op basis van bestanden (bijvoorbeeld in een store, op basis van bestanden naar een relationele opslag), is het serialiseren of deserialiseren stap vereist.</span><span class="sxs-lookup"><span data-stu-id="178fb-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store to a relational store), the serialization or deserialization step is required.</span></span> <span data-ttu-id="178fb-388">Deze stap resulteert in belangrijke prestatieverbetering overhead.</span><span class="sxs-lookup"><span data-stu-id="178fb-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="178fb-389">**Bestandsindeling**: de door u gekozen bestandsindeling kan invloed hebben op prestaties van de kopie.</span><span class="sxs-lookup"><span data-stu-id="178fb-389">**File format**: The file format you choose might affect copy performance.</span></span> <span data-ttu-id="178fb-390">Avro is bijvoorbeeld een compacte binaire indeling die de metagegevens met gegevens opslaat.</span><span class="sxs-lookup"><span data-stu-id="178fb-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="178fb-391">Brede ondersteuning heeft in het Hadoop-ecosysteem voor het verwerken en het uitvoeren van query's.</span><span class="sxs-lookup"><span data-stu-id="178fb-391">It has broad support in the Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="178fb-392">Avro is echter kostbaar voor serialisatie en deserialisatie, wat tot lagere kopie doorvoer in vergelijking met tekst leidt.</span><span class="sxs-lookup"><span data-stu-id="178fb-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared to text format.</span></span> <span data-ttu-id="178fb-393">Controleer uw keuze van de bestandsindeling in de stroom verwerken holistische.</span><span class="sxs-lookup"><span data-stu-id="178fb-393">Make your choice of file format throughout the processing flow holistically.</span></span> <span data-ttu-id="178fb-394">Beginnen met welke vorm van de gegevens wordt opgeslagen in de gegevensarchieven bron of moet worden geëxtraheerd in externe systemen; de beste indeling voor opslag, analytische verwerking en doorzoeken; en in welke indeling moet de gegevens worden geëxporteerd naar de datamarts voor hulpprogramma's voor rapportage en visualisatie.</span><span class="sxs-lookup"><span data-stu-id="178fb-394">Start with what form the data is stored in, source data stores or to be extracted from external systems; the best format for storage, analytical processing, and querying; and in what format the data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="178fb-395">Soms een bestandsindeling die is suboptimale voor lees- en schrijfprestaties mogelijk zijn een goede keuze wanneer u rekening houden met het algemene analytische proces.</span><span class="sxs-lookup"><span data-stu-id="178fb-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider the overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="178fb-396">Overwegingen voor compressie</span><span class="sxs-lookup"><span data-stu-id="178fb-396">Considerations for compression</span></span>
<span data-ttu-id="178fb-397">Als uw gegevensset invoer- of een bestand is, kunt u Kopieeractiviteit compressie of decompressie uitvoeren zoals het schrijft gegevens naar de bestemming instellen.</span><span class="sxs-lookup"><span data-stu-id="178fb-397">When your input or output data set is a file, you can set Copy Activity to perform compression or decompression as it writes data to the destination.</span></span> <span data-ttu-id="178fb-398">Wanneer u compressie kiest, maakt u een afweging tussen het input/output (I/O) en de CPU.</span><span class="sxs-lookup"><span data-stu-id="178fb-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="178fb-399">Comprimeren van de gegevens van in rekenresources extra kosten.</span><span class="sxs-lookup"><span data-stu-id="178fb-399">Compressing the data costs extra in compute resources.</span></span> <span data-ttu-id="178fb-400">Maar in ruil vermindert het i/o-netwerk en opslag.</span><span class="sxs-lookup"><span data-stu-id="178fb-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="178fb-401">Afhankelijk van uw gegevens ziet u een verbetering van de totale doorvoer van de kopie.</span><span class="sxs-lookup"><span data-stu-id="178fb-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="178fb-402">**Codec**: Kopieeractiviteit gzip, bzip2 en Deflate compressietypen ondersteunt.</span><span class="sxs-lookup"><span data-stu-id="178fb-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="178fb-403">Azure HDInsight gebruiken alle drie typen voor verwerking.</span><span class="sxs-lookup"><span data-stu-id="178fb-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="178fb-404">Elke compressiecodec heeft voordelen.</span><span class="sxs-lookup"><span data-stu-id="178fb-404">Each compression codec has advantages.</span></span> <span data-ttu-id="178fb-405">Bijvoorbeeld, bzip2 heeft de laagste kopie doorvoer, maar u de beste prestaties van Hive-query met bzip2 niet ophalen omdat u deze voor verwerking verdelen kunt.</span><span class="sxs-lookup"><span data-stu-id="178fb-405">For example, bzip2 has the lowest copy throughput, but you get the best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="178fb-406">Gzip is de optie meest taakverdeling en het vaakst wordt gebruikt.</span><span class="sxs-lookup"><span data-stu-id="178fb-406">Gzip is the most balanced option, and it is used the most often.</span></span> <span data-ttu-id="178fb-407">Kies de codec die het beste past bij uw scenario end-to-end.</span><span class="sxs-lookup"><span data-stu-id="178fb-407">Choose the codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="178fb-408">**Niveau**: U kunt kiezen uit twee opties voor elke compressiecodec: snelste gecomprimeerd en optimaal gecomprimeerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="178fb-409">De snelste gecomprimeerde optie comprimeert de gegevens zo snel mogelijk, zelfs als het resulterende bestand is niet optimaal gecomprimeerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-409">The fastest compressed option compresses the data as quickly as possible, even if the resulting file is not optimally compressed.</span></span> <span data-ttu-id="178fb-410">De optie optimaal gecomprimeerde veel meer tijd kwijt is aan compressie en resulteert in een minimale hoeveelheid gegevens.</span><span class="sxs-lookup"><span data-stu-id="178fb-410">The optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="178fb-411">U kunt beide opties om te zien waarmee u betere algehele prestaties in uw geval testen.</span><span class="sxs-lookup"><span data-stu-id="178fb-411">You can test both options to see which provides better overall performance in your case.</span></span>

<span data-ttu-id="178fb-412">**Overweging**: overweeg het gebruik van tussentijdse blob-opslag met compressie voor het kopiëren van een grote hoeveelheid gegevens tussen een winkel lokale en de cloud.</span><span class="sxs-lookup"><span data-stu-id="178fb-412">**A consideration**: To copy a large amount of data between an on-premises store and the cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="178fb-413">Tijdelijke opslag is nuttig wanneer de bandbreedte van het bedrijfsnetwerk en uw Azure-services de beperkende factor is en u wilt dat de gegevensset invoer en uitvoer gegevensset beide in niet-gecomprimeerde vorm.</span><span class="sxs-lookup"><span data-stu-id="178fb-413">Using interim storage is helpful when the bandwidth of your corporate network and your Azure services is the limiting factor, and you want the input data set and output data set both to be in uncompressed form.</span></span> <span data-ttu-id="178fb-414">U kunt meer specifiek, een enkel kopieeractiviteit opsplitsen in twee kopie activiteiten.</span><span class="sxs-lookup"><span data-stu-id="178fb-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="178fb-415">Het kopiëren van de eerste activiteit wordt opgehaald uit de bron naar een tijdelijke of staging-blob in gecomprimeerde vorm.</span><span class="sxs-lookup"><span data-stu-id="178fb-415">The first copy activity copies from the source to an interim or staging blob in compressed form.</span></span> <span data-ttu-id="178fb-416">De tweede kopieeractiviteit kopieert de gecomprimeerde gegevens van fasering, en vervolgens decomprimeert terwijl deze naar de sink schrijft.</span><span class="sxs-lookup"><span data-stu-id="178fb-416">The second copy activity copies the compressed data from staging, and then decompresses while it writes to the sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="178fb-417">Overwegingen voor kolomtoewijzing</span><span class="sxs-lookup"><span data-stu-id="178fb-417">Considerations for column mapping</span></span>
<span data-ttu-id="178fb-418">U kunt instellen de **columnMappings** eigenschap in de kopieerbewerking alle kaart of een subset van de invoerkolommen voor de uitvoerkolommen.</span><span class="sxs-lookup"><span data-stu-id="178fb-418">You can set the **columnMappings** property in Copy Activity to map all or a subset of the input columns to the output columns.</span></span> <span data-ttu-id="178fb-419">Nadat data movement service de gegevens van de bron leest, moet deze kolomtoewijzing uitvoeren op de gegevens voordat deze de gegevens naar de sink schrijft.</span><span class="sxs-lookup"><span data-stu-id="178fb-419">After the data movement service reads the data from the source, it needs to perform column mapping on the data before it writes the data to the sink.</span></span> <span data-ttu-id="178fb-420">Deze extra verwerking, vermindert kopie doorvoer.</span><span class="sxs-lookup"><span data-stu-id="178fb-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="178fb-421">Als uw brongegevensarchief waarop, bijvoorbeeld als het een relationele archief zoals SQL-Database of SQL Server of als het een NoSQL-archief zoals Table storage of Azure Cosmos DB, kunt u pushen van de kolom voor het filteren en volgorde van de logica voor de **query** eigenschap in plaats van de kolomtoewijzing.</span><span class="sxs-lookup"><span data-stu-id="178fb-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing the column filtering and reordering logic to the **query** property instead of using column mapping.</span></span> <span data-ttu-id="178fb-422">Op deze manier de projectie treedt op wanneer data movement service leest de gegevens uit het brongegevensarchief waar het is veel efficiënter.</span><span class="sxs-lookup"><span data-stu-id="178fb-422">This way, the projection occurs while the data movement service reads data from the source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="178fb-423">Andere overwegingen</span><span class="sxs-lookup"><span data-stu-id="178fb-423">Other considerations</span></span>
<span data-ttu-id="178fb-424">Als de grootte van gegevens die u wilt kopiëren groot is, kunt u uw bedrijfslogica aan verdere partitie de gegevens met behulp van het mechanisme voor segmenteringshulplijnen in Gegevensfactory aanpassen.</span><span class="sxs-lookup"><span data-stu-id="178fb-424">If the size of data you want to copy is large, you can adjust your business logic to further partition the data using the slicing mechanism in Data Factory.</span></span> <span data-ttu-id="178fb-425">Plan de Kopieeractiviteit vaker uitgevoerd om deze te verkleinen van de gegevens voor elke activiteit kopie die wordt uitgevoerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-425">Then, schedule Copy Activity to run more frequently to reduce the data size for each Copy Activity run.</span></span>

<span data-ttu-id="178fb-426">Wees voorzichtig bij het aantal gegevenssets en kopiëren activiteiten Data Factory met hetzelfde gegevensarchief-connector op hetzelfde moment vereisen.</span><span class="sxs-lookup"><span data-stu-id="178fb-426">Be cautious about the number of data sets and copy activities requiring Data Factory to connector to the same data store at the same time.</span></span> <span data-ttu-id="178fb-427">Veel gelijktijdige kopie taken mogelijk een gegevensarchief beperken en leiden tot verminderde prestaties, kopie taak interne nieuwe pogingen, en in sommige gevallen kan fouten bij de uitvoering.</span><span class="sxs-lookup"><span data-stu-id="178fb-427">Many concurrent copy jobs might throttle a data store and lead to degraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a><span data-ttu-id="178fb-428">Voorbeeldscenario: kopiëren vanuit een lokale SQL Server naar Blob storage</span><span class="sxs-lookup"><span data-stu-id="178fb-428">Sample scenario: Copy from an on-premises SQL Server to Blob storage</span></span>
<span data-ttu-id="178fb-429">**Scenario**: een pijplijn om gegevens te kopiëren van een lokale SQL Server naar Blob storage in CSV-indeling is gebouwd.</span><span class="sxs-lookup"><span data-stu-id="178fb-429">**Scenario**: A pipeline is built to copy data from an on-premises SQL Server to Blob storage in CSV format.</span></span> <span data-ttu-id="178fb-430">Als u de kopieertaak sneller, moeten de CSV-bestanden in de notatie bzip2 worden gecomprimeerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-430">To make the copy job faster, the CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="178fb-431">**Test- en analyse**: de doorvoer van de kopieerbewerking is minder dan 2 MBps veel lager is dan de benchmark prestaties.</span><span class="sxs-lookup"><span data-stu-id="178fb-431">**Test and analysis**: The throughput of Copy Activity is less than 2 MBps, which is much slower than the performance benchmark.</span></span>

<span data-ttu-id="178fb-432">**Analyse van prestaties en het afstemmen**: voor het oplossen van het prestatieprobleem bekijken we hoe de gegevens worden verwerkt en verplaatst.</span><span class="sxs-lookup"><span data-stu-id="178fb-432">**Performance analysis and tuning**: To troubleshoot the performance issue, let’s look at how the data is processed and moved.</span></span>

1. <span data-ttu-id="178fb-433">**Gegevens lezen**: Gateway opent een verbinding met SQL Server en de query te verzenden.</span><span class="sxs-lookup"><span data-stu-id="178fb-433">**Read data**: Gateway opens a connection to SQL Server and sends the query.</span></span> <span data-ttu-id="178fb-434">SQL Server reageert met de gegevensstroom Gateway verzenden via het intranet.</span><span class="sxs-lookup"><span data-stu-id="178fb-434">SQL Server responds by sending the data stream to Gateway via the intranet.</span></span>
2. <span data-ttu-id="178fb-435">**Serialiseren en gegevens comprimeren**: Gateway serialiseert de gegevensstroom naar de CSV-indeling en de gegevens naar een stream bzip2 worden gecomprimeerd.</span><span class="sxs-lookup"><span data-stu-id="178fb-435">**Serialize and compress data**: Gateway serializes the data stream to CSV format, and compresses the data to a bzip2 stream.</span></span>
3. <span data-ttu-id="178fb-436">**Schrijven van gegevens**: Gateway bzip2 stream uploadt naar blobopslag via Internet.</span><span class="sxs-lookup"><span data-stu-id="178fb-436">**Write data**: Gateway uploads the bzip2 stream to Blob storage via the Internet.</span></span>

<span data-ttu-id="178fb-437">Zoals u ziet de gegevens worden verwerkt en verplaatst streaming redirector: SQL Server > LAN > Gateway > WAN > Blob storage.</span><span class="sxs-lookup"><span data-stu-id="178fb-437">As you can see, the data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="178fb-438">**De algehele prestaties worden geregeld door de minimale doorvoer in de pijplijn**.</span><span class="sxs-lookup"><span data-stu-id="178fb-438">**The overall performance is gated by the minimum throughput across the pipeline**.</span></span>

![Gegevensstroom](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="178fb-440">De prestatieknelpunt mogelijk worden veroorzaakt door een of meer van de volgende factoren:</span><span class="sxs-lookup"><span data-stu-id="178fb-440">One or more of the following factors might cause the performance bottleneck:</span></span>

* <span data-ttu-id="178fb-441">**Bron**: SQL-Server zelf lage doorvoer is vanwege een zware belasting.</span><span class="sxs-lookup"><span data-stu-id="178fb-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="178fb-442">**Data Management Gateway**:</span><span class="sxs-lookup"><span data-stu-id="178fb-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="178fb-443">**LAN**: Gateway bevindt deze formule de SQL Server-machine en een lage bandbreedte verbinding heeft.</span><span class="sxs-lookup"><span data-stu-id="178fb-443">**LAN**: Gateway is located far from the SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="178fb-444">**Gateway**: Gateway heeft bereikt load beperkingen als u wilt de volgende bewerkingen uitvoeren:</span><span class="sxs-lookup"><span data-stu-id="178fb-444">**Gateway**: Gateway has reached its load limitations to perform the following operations:</span></span>
    * <span data-ttu-id="178fb-445">**Serialisatie**: trage doorvoer serialiseren van de gegevensstroom naar de CSV-indeling heeft.</span><span class="sxs-lookup"><span data-stu-id="178fb-445">**Serialization**: Serializing the data stream to CSV format has slow throughput.</span></span>
    * <span data-ttu-id="178fb-446">**Compressie**: U hebt ervoor gekozen een trage compressiecodec (bijvoorbeeld, bzip2, namelijk 2,8 MBps met Core i7).</span><span class="sxs-lookup"><span data-stu-id="178fb-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="178fb-447">**WAN**: is een lage bandbreedte tussen het bedrijfsnetwerk en uw Azure-services (bijvoorbeeld T1 = 1,544 kbps. T2 = 6,312 kbps).</span><span class="sxs-lookup"><span data-stu-id="178fb-447">**WAN**: The bandwidth between the corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="178fb-448">**Sink**: Blob-opslag heeft lage doorvoer.</span><span class="sxs-lookup"><span data-stu-id="178fb-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="178fb-449">(Dit scenario is niet waarschijnlijk omdat een minimum van 60 MBps wordt gegarandeerd dat de SLA.)</span><span class="sxs-lookup"><span data-stu-id="178fb-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="178fb-450">In dit geval kan bzip2 gegevenscompressie worden vertraagd de hele pijplijn.</span><span class="sxs-lookup"><span data-stu-id="178fb-450">In this case, bzip2 data compression might be slowing down the entire pipeline.</span></span> <span data-ttu-id="178fb-451">Overschakelen naar een compressiecodec gzip, kan dit knelpunt vereenvoudigen.</span><span class="sxs-lookup"><span data-stu-id="178fb-451">Switching to a gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="178fb-452">Voorbeeld van scenario's: parallelle kopie gebruiken</span><span class="sxs-lookup"><span data-stu-id="178fb-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="178fb-453">**Scenario I:** kopie 1.000 1 MB bestanden van de on-premises bestandssysteem naar Blob storage.</span><span class="sxs-lookup"><span data-stu-id="178fb-453">**Scenario I:** Copy 1,000 1-MB files from the on-premises file system to Blob storage.</span></span>

<span data-ttu-id="178fb-454">**Analyse en prestatieafstemming**: voor een voorbeeld: als u gateway hebt geïnstalleerd op een machine quad-core, Data Factory maakt gebruik van 16 parallelle kopieën om bestanden te verplaatsen van het bestandssysteem naar Blob storage gelijktijdig.</span><span class="sxs-lookup"><span data-stu-id="178fb-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies to move files from the file system to Blob storage concurrently.</span></span> <span data-ttu-id="178fb-455">Deze parallelle uitvoering moet resulteren in hoge doorvoersnelheden.</span><span class="sxs-lookup"><span data-stu-id="178fb-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="178fb-456">U kunt ook expliciet opgeven het aantal parallelle exemplaren.</span><span class="sxs-lookup"><span data-stu-id="178fb-456">You also can explicitly specify the parallel copies count.</span></span> <span data-ttu-id="178fb-457">Wanneer u veel kleine bestanden kopieert, helpen parallelle kopieën doorvoer aanzienlijk bij het effectiever gebruik van bronnen.</span><span class="sxs-lookup"><span data-stu-id="178fb-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![Scenario 1](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="178fb-459">**Scenario II**: 20 blobs van 500 MB kopiëren van Blob-opslag naar Data Lake Store Analytics en vervolgens prestaties afstemmen.</span><span class="sxs-lookup"><span data-stu-id="178fb-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage to Data Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="178fb-460">**Analyse en prestatieafstemming**: In dit scenario Data Factory kopieert de gegevens uit Blob storage naar Data Lake Store met behulp van één exemplaar (**parallelCopies** ingesteld op 1) en één cloud data movement eenheden.</span><span class="sxs-lookup"><span data-stu-id="178fb-460">**Analysis and performance tuning**: In this scenario, Data Factory copies the data from Blob storage to Data Lake Store by using single-copy (**parallelCopies** set to 1) and single-cloud data movement units.</span></span> <span data-ttu-id="178fb-461">De doorvoer u merkt dicht bij die een beschrijving van de [prestaties verwijzing sectie](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="178fb-461">The throughput you observe will be close to that described in the [performance reference section](#performance-reference).</span></span>   

![Scenario 2](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="178fb-463">**Scenario III**: afzonderlijk bestand is groter dan tientallen MB en het totale volume is groot.</span><span class="sxs-lookup"><span data-stu-id="178fb-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="178fb-464">**Analyse en prestaties schakelen**: verhogen **parallelCopies** vanwege de bronbeperkingen van een één-cloud-DMU niet resulteren in betere prestaties van de kopie.</span><span class="sxs-lookup"><span data-stu-id="178fb-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of the resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="178fb-465">In plaats daarvan moet u meer cloud DMUs meer bronnen voor het uitvoeren van de gegevensverplaatsing ophalen.</span><span class="sxs-lookup"><span data-stu-id="178fb-465">Instead, you should specify more cloud DMUs to get more resources to perform the data movement.</span></span> <span data-ttu-id="178fb-466">Geef een waarde op voor de **parallelCopies** eigenschap.</span><span class="sxs-lookup"><span data-stu-id="178fb-466">Do not specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="178fb-467">Data Factory verwerkt de parallelle uitvoering voor u.</span><span class="sxs-lookup"><span data-stu-id="178fb-467">Data Factory handles the parallelism for you.</span></span> <span data-ttu-id="178fb-468">In dit geval als u instelt **cloudDataMovementUnits** moet 4, een doorvoer van over vier keer voordoet.</span><span class="sxs-lookup"><span data-stu-id="178fb-468">In this case, if you set **cloudDataMovementUnits** to 4, a throughput of about four times occurs.</span></span>

![Scenario 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="178fb-470">Naslaginformatie</span><span class="sxs-lookup"><span data-stu-id="178fb-470">Reference</span></span>
<span data-ttu-id="178fb-471">Hier zijn prestaties controleren en afstemmen verwijzingen voor enkele van de ondersteunde gegevensarchieven:</span><span class="sxs-lookup"><span data-stu-id="178fb-471">Here are performance monitoring and tuning references for some of the supported data stores:</span></span>

* <span data-ttu-id="178fb-472">Azure-opslag (inclusief Blob storage en Table storage): [schaalbaarheidsdoelen van Azure Storage](../storage/common/storage-scalability-targets.md) en [controlelijst voor prestaties en schaalbaarheid van Azure Storage](../storage/common/storage-performance-checklist.md)</span><span class="sxs-lookup"><span data-stu-id="178fb-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="178fb-473">Azure SQL Database: U kunt [de prestaties controleren](../sql-database/sql-database-single-database-monitor.md) en controleert u het percentage database transaction unit (DTU)</span><span class="sxs-lookup"><span data-stu-id="178fb-473">Azure SQL Database: You can [monitor the performance](../sql-database/sql-database-single-database-monitor.md) and check the database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="178fb-474">Azure SQL datawarehouse: De mogelijkheid wordt gemeten in datawarehouse units (dwu's); Zie [beheren rekencapaciteit in Azure SQL Data Warehouse (overzicht)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span><span class="sxs-lookup"><span data-stu-id="178fb-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="178fb-475">Azure Cosmos DB: [prestatieniveaus in Azure Cosmos-DB](../documentdb/documentdb-performance-levels.md)</span><span class="sxs-lookup"><span data-stu-id="178fb-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="178fb-476">Lokale SQL Server: [bewaakt en geoptimaliseerd voor prestaties](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="178fb-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="178fb-477">Lokale bestandsserver: [prestaties afstemmen voor bestandsservers](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="178fb-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>
