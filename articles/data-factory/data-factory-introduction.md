---
title: aaaIntroduction tooData Factory, een gegevensservice integratie | Microsoft Docs
description: 'Leer wat een Data Factory is: een cloudgebaseerde gegevensintegratieservice waarmee de verplaatsing en transformatie van gegevens wordt beheerd en geautomatiseerd.'
keywords: gegevensintegratie, cloudgegevensintegratie, wat is Azure Data Factory
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: 4cc30515315efc938951057743ff8eb3701214ef
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 10/06/2017
---
# <a name="introduction-tooazure-data-factory"></a><span data-ttu-id="58c54-104">Inleiding tooAzure Data Factory</span><span class="sxs-lookup"><span data-stu-id="58c54-104">Introduction tooAzure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="58c54-105">Wat is Azure Data Factory?</span><span class="sxs-lookup"><span data-stu-id="58c54-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="58c54-106">In Hallo wereld van big data, hoe wordt bestaande gegevens gebruikt in bedrijf?</span><span class="sxs-lookup"><span data-stu-id="58c54-106">In hello world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="58c54-107">Is het mogelijk tooenrich gegevens gegenereerd in de cloud Hallo referentiegegevens van on-premises gegevensbronnen of andere verschillende gegevensbronnen met?</span><span class="sxs-lookup"><span data-stu-id="58c54-107">Is it possible tooenrich data generated in hello cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="58c54-108">Een bedrijf games verzamelt bijvoorbeeld veel logboeken die wordt geproduceerd door games in Hallo cloud.</span><span class="sxs-lookup"><span data-stu-id="58c54-108">For example, a gaming company collects many logs produced by games in hello cloud.</span></span> <span data-ttu-id="58c54-109">Deze tooanalyze wil deze logboeken toogain inzichten in toocustomer voorkeuren, demografische gegevens, gebruik gedrag enzovoort tooidentify Upsell en cross-verkopen verkoopkansen, nieuwe functies toodrive zakelijke groei dwingende ontwikkelen en bieden een betere ervaring toocustomers.</span><span class="sxs-lookup"><span data-stu-id="58c54-109">It wants tooanalyze these logs toogain insights in toocustomer preferences, demographics, usage behavior etc. tooidentify up-sell and cross-sell opportunities, develop new compelling features toodrive business growth, and provide a better experience toocustomers.</span></span> 

<span data-ttu-id="58c54-110">tooanalyze deze logboeken, Hallo bedrijf moet toouse Hallo referentiegegevens zoals klantgegevens, game informatie campagne marketinggegevens die zich in een on-premises gegevensopslag.</span><span class="sxs-lookup"><span data-stu-id="58c54-110">tooanalyze these logs, hello company needs toouse hello reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="58c54-111">Hallo bedrijf wil daarom tooingest logboekgegevens van gegevensarchief Hallo-cloud- en referentiegegevens van Hallo on-premises gegevensopslag.</span><span class="sxs-lookup"><span data-stu-id="58c54-111">Therefore, hello company wants tooingest log data from hello cloud data store and reference data from hello on-premises data store.</span></span> <span data-ttu-id="58c54-112">Vervolgens proces Hallo gegevens met behulp van Hadoop in Hallo cloud (Azure HDInsight) en publiceren van Hallo resultaat opslaan van gegevens in een cloud datawarehouse zoals Azure SQL Data Warehouse of een on-premises gegevens zoals SQL Server.</span><span class="sxs-lookup"><span data-stu-id="58c54-112">Then, process hello data by using Hadoop in hello cloud (Azure HDInsight) and publish hello result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="58c54-113">Dit wil deze werkstroom toorun wekelijks eenmaal.</span><span class="sxs-lookup"><span data-stu-id="58c54-113">It wants this workflow toorun weekly once.</span></span> 

<span data-ttu-id="58c54-114">Wat u nodig hebt, is een platform waarmee Hallo bedrijf toocreate een werkstroom die u kunt gegevens uit zowel on-premises en gegevensarchieven cloud, en transformeren of proces opnemen met behulp van bestaande compute services zoals Hadoop en Hallo resultaten tooan lokale publiceren of gegevensopslag voor BI toepassingen tooconsume cloud.</span><span class="sxs-lookup"><span data-stu-id="58c54-114">What is needed is a platform that allows hello company toocreate a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish hello results tooan on-premises or cloud data store for BI applications tooconsume.</span></span> 

![Overzicht van Data Factory](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="58c54-116">Azure Data Factory is Hallo platform voor dit soort scenario's.</span><span class="sxs-lookup"><span data-stu-id="58c54-116">Azure Data Factory is hello platform for this kind of scenarios.</span></span> <span data-ttu-id="58c54-117">Het is een **gegevens cloud-gebaseerde integration-service waarmee u toocreate gegevensgestuurde werkstromen in Hallo cloud voor organiseren en te automatiseren verplaatsing van gegevens en gegevenstransformatie**.</span><span class="sxs-lookup"><span data-stu-id="58c54-117">It is a **cloud-based data integration service that allows you toocreate data-driven workflows in hello cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="58c54-118">Met behulp van Azure Data Factory, kunt u maken en plannen van gegevensgestuurde werkstromen (pijplijnen genoemd) die kan worden voor het opnemen van gegevens uit verschillende gegevensarchieven transformatie/proces Hallo gegevens met behulp van compute services zoals Azure HDInsight Hadoop, Spark, Azure Data Lake Analyse en Azure Machine Learning en publiceren van gegevens toodata zoals Azure SQL Data Warehouse voor business intelligence (BI) toepassingen tooconsume slaat uitvoer.</span><span class="sxs-lookup"><span data-stu-id="58c54-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform hello data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data toodata stores such as Azure SQL Data Warehouse for business intelligence (BI) applications tooconsume.</span></span>  

<span data-ttu-id="58c54-119">Het is eerder een EL-platform (Extract-and-Load) en vervolgens een TL-platform (Transform-and-Load) dan een traditioneel ETL-platform (Extract-Transform-and-Load).</span><span class="sxs-lookup"><span data-stu-id="58c54-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="58c54-120">Hallo-transformaties die worden uitgevoerd worden tootransform/proces gegevens met behulp van compute services in plaats van tooperform transformaties zoals Hallo die voor het toevoegen van afgeleide kolommen, tellen van het aantal rijen, voor het sorteren van gegevens, enzovoort.</span><span class="sxs-lookup"><span data-stu-id="58c54-120">hello transformations that are performed are tootransform/process data by using compute services rather than tooperform transformations like hello ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="58c54-121">In Azure Data Factory Hallo-gegevens die wordt gebruikt en die wordt geproduceerd door werkstromen is momenteel **tijd gesegmenteerd gegevens** (elk uur, dagelijks, wekelijks, enz.).</span><span class="sxs-lookup"><span data-stu-id="58c54-121">Currently, in Azure Data Factory, hello data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="58c54-122">Een pijplijn kan bijvoorbeeld één keer per dag invoergegevens lezen, gegevens verwerken en uitvoer produceren.</span><span class="sxs-lookup"><span data-stu-id="58c54-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="58c54-123">U kunt er ook voor kiezen om een werkstroom slechts één keer uit te voeren.</span><span class="sxs-lookup"><span data-stu-id="58c54-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="58c54-124">Hoe werkt het?</span><span class="sxs-lookup"><span data-stu-id="58c54-124">How does it work?</span></span> 
<span data-ttu-id="58c54-125">Hallo pijplijnen (gegevensgestuurde werkstromen) in Azure Data Factory wordt normaal gesproken uitvoert Hallo drie stappen te volgen:</span><span class="sxs-lookup"><span data-stu-id="58c54-125">hello pipelines (data-driven workflows) in Azure Data Factory typically perform hello following three steps:</span></span>

![Drie fasen van Azure Data Factory](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="58c54-127">Verbinding maken en verzamelen</span><span class="sxs-lookup"><span data-stu-id="58c54-127">Connect and collect</span></span>
<span data-ttu-id="58c54-128">Ondernemingen hebben verschillende typen gegevens, opgeslagen op verschillende bronnen.</span><span class="sxs-lookup"><span data-stu-id="58c54-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="58c54-129">Hallo eerste stap bij het bouwen van een productiesysteem tooconnect tooall Hallo vereist gegevensbronnen en verwerken, zoals SaaS-services, bestand shares, FTP, webservices en verplaatsen Hallo gegevens nodig tooa centrale locatie voor verdere verwerking.</span><span class="sxs-lookup"><span data-stu-id="58c54-129">hello first step in building an information production system is tooconnect tooall hello required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move hello data as-needed tooa centralized location for subsequent processing.</span></span>

<span data-ttu-id="58c54-130">Ondernemingen moeten zonder Data Factory bouwen van aangepaste gegevens gegevensverplaatsing onderdelen of schrijven van aangepaste services toointegrate deze gegevensbronnen en de verwerking.</span><span class="sxs-lookup"><span data-stu-id="58c54-130">Without Data Factory, enterprises must build custom data movement components or write custom services toointegrate these data sources and processing.</span></span> <span data-ttu-id="58c54-131">Het is duur en moeilijk toointegrate en onderhouden van dergelijke systemen en vaak ontbreekt Hallo enterprise hoogwaardige bewaking en waarschuwingen en Hallo-besturingselementen die worden geboden door een volledig beheerde service.</span><span class="sxs-lookup"><span data-stu-id="58c54-131">It is expensive and hard toointegrate and maintain such systems, and it often lacks hello enterprise grade monitoring and alerting, and hello controls that a fully managed service can offer.</span></span>

<span data-ttu-id="58c54-132">U kunt met Data Factory gebruiken Hallo Kopieeractiviteit in een data pipeline toomove gegevens uit zowel on-premises en cloud winkels tooa centralisering gegevens brongegevensarchief in Hallo cloud voor verdere analyse.</span><span class="sxs-lookup"><span data-stu-id="58c54-132">With Data Factory, you can use hello Copy Activity in a data pipeline toomove data from both on-premises and cloud source data stores tooa centralization data store in hello cloud for further analysis.</span></span> <span data-ttu-id="58c54-133">Bijvoorbeeld, kunt u de gegevens in een Azure Data Lake Store en transformatie hello later verzamelen met behulp van een Azure Data Lake Analytics compute-service.</span><span class="sxs-lookup"><span data-stu-id="58c54-133">For example, you can collect data in an Azure Data Lake Store and transform hello data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="58c54-134">Of u kunt gegevens verzamelen in Azure Blob Storage en later transformeren met behulp van een Hadoop-cluster van Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="58c54-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="58c54-135">Transformeren en verrijken</span><span class="sxs-lookup"><span data-stu-id="58c54-135">Transform and enrich</span></span>
<span data-ttu-id="58c54-136">Nadat de gegevens in een gecentraliseerde gegevensopslag in Hallo cloud aanwezig is, wilt u Hallo verzamelde gegevens toobe omgezet met behulp van compute services zoals HDInsight Hadoop, Spark, Data Lake Analytics en Machine Learning of verwerkt.</span><span class="sxs-lookup"><span data-stu-id="58c54-136">Once data is present in a centralized data store in hello cloud, you want hello collected data toobe processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="58c54-137">Wilt u tooreliably produceren getransformeerd gegevens op een bruikbaar en gecontroleerde planning toofeed-productieomgevingen met vertrouwde gegevens.</span><span class="sxs-lookup"><span data-stu-id="58c54-137">You want tooreliably produce transformed data on a maintainable and controlled schedule toofeed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="58c54-138">Publiceren</span><span class="sxs-lookup"><span data-stu-id="58c54-138">Publish</span></span> 
<span data-ttu-id="58c54-139">Leveren getransformeerde gegevens uit de cloud Hallo tooon lokale bronnen, zoals SQL Server of behouden blijft in uw cloud opslag bronnen voor verbruik door business intelligence (BI) en hulpprogramma's voor webanalyse en andere toepassingen.</span><span class="sxs-lookup"><span data-stu-id="58c54-139">Deliver transformed data from hello cloud tooon-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="58c54-140">Belangrijkste onderdelen</span><span class="sxs-lookup"><span data-stu-id="58c54-140">Key components</span></span>
<span data-ttu-id="58c54-141">Een Azure-abonnement kan een of meer Azure Data Factory-exemplaren (oftewel 'data factory's') hebben.</span><span class="sxs-lookup"><span data-stu-id="58c54-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="58c54-142">Azure Data Factory bestaat uit vier belangrijke onderdelen die samenwerken tooprovide Hallo platform waarop u gegevensgestuurde werkstromen met stappen toomove en transformatie gegevens kunt samenstellen.</span><span class="sxs-lookup"><span data-stu-id="58c54-142">Azure Data Factory is composed of four key components that work together tooprovide hello platform on which you can compose data-driven workflows with steps toomove and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="58c54-143">Pijplijn</span><span class="sxs-lookup"><span data-stu-id="58c54-143">Pipeline</span></span>
<span data-ttu-id="58c54-144">Een data factory kan één of meer pijplijnen hebben.</span><span class="sxs-lookup"><span data-stu-id="58c54-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="58c54-145">Een pijplijn is een groep activiteiten.</span><span class="sxs-lookup"><span data-stu-id="58c54-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="58c54-146">Hallo-activiteiten in een pijplijn worden samen een taak uitvoeren.</span><span class="sxs-lookup"><span data-stu-id="58c54-146">Together, hello activities in a pipeline perform a task.</span></span> <span data-ttu-id="58c54-147">Een pijplijn kan bijvoorbeeld een groep activiteiten die gegevens uit een Azure-blob opgenomen bevatten en voer vervolgens een Hive-query op een HDInsight-cluster toopartition Hallo gegevens.</span><span class="sxs-lookup"><span data-stu-id="58c54-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster toopartition hello data.</span></span> <span data-ttu-id="58c54-148">Hallo voordeel hiervan is dat pijplijn Hallo kunt u toomanage Hallo activiteiten als een set in plaats van elk afzonderlijk.</span><span class="sxs-lookup"><span data-stu-id="58c54-148">hello benefit of this is that hello pipeline allows you toomanage hello activities as a set instead of each one individually.</span></span> <span data-ttu-id="58c54-149">U kunt bijvoorbeeld implementeren en onafhankelijk Hallo pipeline, in plaats van Hallo-activiteiten plannen.</span><span class="sxs-lookup"><span data-stu-id="58c54-149">For example, you can deploy and schedule hello pipeline, instead of hello activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="58c54-150">Activiteit</span><span class="sxs-lookup"><span data-stu-id="58c54-150">Activity</span></span>
<span data-ttu-id="58c54-151">Een pijplijn kan één of meer activiteiten bevatten.</span><span class="sxs-lookup"><span data-stu-id="58c54-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="58c54-152">Hallo acties tooperform definiëren activiteiten voor uw gegevens.</span><span class="sxs-lookup"><span data-stu-id="58c54-152">Activities define hello actions tooperform on your data.</span></span> <span data-ttu-id="58c54-153">U kunt bijvoorbeeld toocopy activiteitsgegevens van een kopie van één data store tooanother gegevensarchief.</span><span class="sxs-lookup"><span data-stu-id="58c54-153">For example, you may use a Copy activity toocopy data from one data store tooanother data store.</span></span> <span data-ttu-id="58c54-154">U kunt op dezelfde manier een Hive-activiteit die wordt uitgevoerd een Hive-query op een Azure HDInsight-cluster tootransform gebruiken of uw gegevens analyseren.</span><span class="sxs-lookup"><span data-stu-id="58c54-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster tootransform or analyze your data.</span></span> <span data-ttu-id="58c54-155">Data Factory ondersteunt twee soorten activiteiten: activiteiten voor gegevensverplaatsing en activiteiten voor gegevenstransformatie.</span><span class="sxs-lookup"><span data-stu-id="58c54-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="58c54-156">Activiteiten voor gegevensverplaatsing</span><span class="sxs-lookup"><span data-stu-id="58c54-156">Data movement activities</span></span>
<span data-ttu-id="58c54-157">Kopieeractiviteit in Data Factory kopieert gegevens van een gegevensarchief bron data store tooa sink.</span><span class="sxs-lookup"><span data-stu-id="58c54-157">Copy Activity in Data Factory copies data from a source data store tooa sink data store.</span></span> <span data-ttu-id="58c54-158">Data Factory ondersteunt Hallo gegevensarchieven te volgen.</span><span class="sxs-lookup"><span data-stu-id="58c54-158">Data Factory supports hello following data stores.</span></span> <span data-ttu-id="58c54-159">Gegevens van elke bron kan worden geschreven als tooany sink.</span><span class="sxs-lookup"><span data-stu-id="58c54-159">Data from any source can be written tooany sink.</span></span> <span data-ttu-id="58c54-160">Hoe klikt u op een data store toolearn toocopy gegevens tooand van dat archief.</span><span class="sxs-lookup"><span data-stu-id="58c54-160">Click a data store toolearn how toocopy data tooand from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="58c54-161">Zie het artikel [Activiteiten voor gegevensverplaatsing](data-factory-data-movement-activities.md) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="58c54-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="58c54-162">Activiteiten voor gegevenstransformatie</span><span class="sxs-lookup"><span data-stu-id="58c54-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="58c54-163">Zie het artikel [Activiteiten voor gegevenstransformatie](data-factory-data-transformation-activities.md) voor meer informatie.</span><span class="sxs-lookup"><span data-stu-id="58c54-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="58c54-164">Aangepaste .NET-activiteiten</span><span class="sxs-lookup"><span data-stu-id="58c54-164">Custom .NET activities</span></span>
<span data-ttu-id="58c54-165">Als u moet toomove gegevens naar/van een gegevensarchief die Kopieeractiviteit niet ondersteunen, of gegevens met behulp van uw eigen logica transformeren, maken een **aangepaste .NET-activiteit**.</span><span class="sxs-lookup"><span data-stu-id="58c54-165">If you need toomove data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="58c54-166">Zie [Aangepaste activiteiten gebruiken in een Azure Data Factory-pijplijn](data-factory-use-custom-activities.md) voor meer informatie over het maken en gebruiken van een aangepaste activiteit.</span><span class="sxs-lookup"><span data-stu-id="58c54-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="58c54-167">Gegevenssets</span><span class="sxs-lookup"><span data-stu-id="58c54-167">Datasets</span></span>
<span data-ttu-id="58c54-168">Voor een activiteit zijn nul of meer gegevenssets nodig als invoer en één of meer gegevenssets als uitvoer.</span><span class="sxs-lookup"><span data-stu-id="58c54-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="58c54-169">Gegevenssets vertegenwoordigen gegevensstructuren binnen Hallo gegevensarchieven die of gewoon Hallo referentiegegevens gewenste toouse in uw activiteiten als invoer of uitvoer van gegevenspunt.</span><span class="sxs-lookup"><span data-stu-id="58c54-169">Datasets represent data structures within hello data stores, which simply point or reference hello data you want toouse in your activities as inputs or outputs.</span></span> <span data-ttu-id="58c54-170">Een Azure Blob-gegevensset bevat bijvoorbeeld Hallo blob-container en map in hello Azure Blob Storage uit welke Hallo pijplijn Hallo gegevens moet lezen.</span><span class="sxs-lookup"><span data-stu-id="58c54-170">For example, an Azure Blob dataset specifies hello blob container and folder in hello Azure Blob Storage from which hello pipeline should read hello data.</span></span> <span data-ttu-id="58c54-171">Of een Azure SQL-tabel gegevensset geeft Hallo tabel toowhich Hallo uitvoergegevens worden geschreven door Hallo-activiteit.</span><span class="sxs-lookup"><span data-stu-id="58c54-171">Or, an Azure SQL Table dataset specifies hello table toowhich hello output data is written by hello activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="58c54-172">Gekoppelde services</span><span class="sxs-lookup"><span data-stu-id="58c54-172">Linked services</span></span>
<span data-ttu-id="58c54-173">Gekoppelde services zijn veel zoals verbindingsreeksen die Hallo verbindingsinformatie die nodig is voor Data Factory tooconnect tooexternal bronnen definiëren.</span><span class="sxs-lookup"><span data-stu-id="58c54-173">Linked services are much like connection strings, which define hello connection information needed for Data Factory tooconnect tooexternal resources.</span></span> <span data-ttu-id="58c54-174">Beschouw deze manier: een gekoppelde service definieert Hallo verbinding toohello gegevensbron en een gegevensset Hallo-structuur van Hallo gegevens vertegenwoordigt.</span><span class="sxs-lookup"><span data-stu-id="58c54-174">Think of it this way - a linked service defines hello connection toohello data source and a dataset represents hello structure of hello data.</span></span> <span data-ttu-id="58c54-175">Een gekoppelde Azure Storage-service geeft bijvoorbeeld verbinding tekenreeks tooconnect toohello Azure Storage-account.</span><span class="sxs-lookup"><span data-stu-id="58c54-175">For example, an Azure Storage linked service specifies connection string tooconnect toohello Azure Storage account.</span></span> <span data-ttu-id="58c54-176">En een Azure Blob-gegevensset geeft Hallo blob-container en de Hallo map Hallo gegevens bevat.</span><span class="sxs-lookup"><span data-stu-id="58c54-176">And, an Azure Blob dataset specifies hello blob container and hello folder that contains hello data.</span></span>   

<span data-ttu-id="58c54-177">Gekoppelde services worden voor twee doeleinden gebruikt in een Data Factory:</span><span class="sxs-lookup"><span data-stu-id="58c54-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="58c54-178">toorepresent een **gegevensarchief** inclusief, maar niet beperkt tot een lokale SQL Server, Oracle-database, bestandsshare of een Azure Blob Storage-account.</span><span class="sxs-lookup"><span data-stu-id="58c54-178">toorepresent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="58c54-179">Zie Hallo [activiteiten voor gegevensverplaatsing](#data-movement-activities) sectie voor een lijst van ondersteunde gegevensarchieven.</span><span class="sxs-lookup"><span data-stu-id="58c54-179">See hello [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="58c54-180">toorepresent een **compute resource** die Hallo uitvoering van een activiteit kan hosten.</span><span class="sxs-lookup"><span data-stu-id="58c54-180">toorepresent a **compute resource** that can host hello execution of an activity.</span></span> <span data-ttu-id="58c54-181">Hallo activiteit Hdinsightahive wordt bijvoorbeeld uitgevoerd op een HDInsight Hadoop-cluster.</span><span class="sxs-lookup"><span data-stu-id="58c54-181">For example, hello HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="58c54-182">Zie de sectie [Activiteiten voor gegevenstransformatie](#data-transformation-activities) voor een lijst met ondersteunde rekenomgevingen.</span><span class="sxs-lookup"><span data-stu-id="58c54-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="58c54-183">Relatie tussen Data Factory-entiteiten</span><span class="sxs-lookup"><span data-stu-id="58c54-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="58c54-184">![Diagram: Data Factory, een service voor gegevensintegratie in de cloud - belangrijkste concepten](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Afbeelding 2.**</span><span class="sxs-lookup"><span data-stu-id="58c54-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="58c54-185">Relaties tussen de gegevensset, de activiteit, de pijplijn en de gekoppelde service</span><span class="sxs-lookup"><span data-stu-id="58c54-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="58c54-186">Ondersteunde regio’s</span><span class="sxs-lookup"><span data-stu-id="58c54-186">Supported regions</span></span>
<span data-ttu-id="58c54-187">Op dit moment kunt u data factory maken in Hallo **VS-West**, **VS-Oost**, en **Noord-Europa** regio's.</span><span class="sxs-lookup"><span data-stu-id="58c54-187">Currently, you can create data factories in hello **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="58c54-188">Echter een gegevensfactory kan toegang tot gegevensarchieven en compute services in andere Azure-regio's toomove gegevens tussen gegevensarchieven of compute-procesgegevens met behulp van services.</span><span class="sxs-lookup"><span data-stu-id="58c54-188">However, a data factory can access data stores and compute services in other Azure regions toomove data between data stores or process data using compute services.</span></span>

<span data-ttu-id="58c54-189">Azure Data Factory zelf slaat geen gegevens op.</span><span class="sxs-lookup"><span data-stu-id="58c54-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="58c54-190">Hiermee kunt u gegevensgestuurde werkstromen tooorchestrate verplaatsing van gegevens tussen maken [ondersteunde gegevensarchieven](#data-movement-activities) en het verwerken van gegevens met [compute-services](#data-transformation-activities) in andere regio's of in een on-premises -omgeving.</span><span class="sxs-lookup"><span data-stu-id="58c54-190">It lets you create data-driven workflows tooorchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="58c54-191">U kunt er ook te[bewaken en beheren van werkstromen](data-factory-monitor-manage-pipelines.md) met zowel programmatische als gebruikersinterfacemechanismen.</span><span class="sxs-lookup"><span data-stu-id="58c54-191">It also allows you too[monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="58c54-192">Hoewel Data Factory is alleen beschikbaar in **VS-West**, **VS-Oost**, en **Noord-Europa** regio's, Hallo-service dat Hallo gegevensverplaatsing in Data Factory is beschikbaar [globaal](data-factory-data-movement-activities.md#global) in meerdere regio's.</span><span class="sxs-lookup"><span data-stu-id="58c54-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, hello service powering hello data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="58c54-193">Als een gegevensarchief zich achter een firewall, en vervolgens een [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) geïnstalleerd in uw on-premises omgeving verplaatst Hallo gegevens in plaats daarvan.</span><span class="sxs-lookup"><span data-stu-id="58c54-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves hello data instead.</span></span>

<span data-ttu-id="58c54-194">Voorbeeld: uw berekeningsomgevingen, zoals een Azure HDInsight-cluster en Azure Machine Learning, worden uitgevoerd in de regio West-Europa.</span><span class="sxs-lookup"><span data-stu-id="58c54-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="58c54-195">U kunt maken en gebruiken van een Azure Data Factory-exemplaar in Noord-Europa en tooschedule taken in uw berekeningsomgevingen in West-Europa gebruiken.</span><span class="sxs-lookup"><span data-stu-id="58c54-195">You can create and use an Azure Data Factory instance in North Europe and use it tooschedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="58c54-196">Het duurt enkele milliseconden voor de Data Factory tootrigger Hallo taak van uw omgeving compute maar Hallo tijd voor het Hallo-taak uitvoeren op uw computeromgeving worden niet gewijzigd.</span><span class="sxs-lookup"><span data-stu-id="58c54-196">It takes a few milliseconds for Data Factory tootrigger hello job on your compute environment but hello time for running hello job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="58c54-197">Aan de slag met het maken van een pijplijn</span><span class="sxs-lookup"><span data-stu-id="58c54-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="58c54-198">U kunt een van deze hulpprogramma's of API's toocreate gegevenspijplijnen in Azure Data Factory:</span><span class="sxs-lookup"><span data-stu-id="58c54-198">You can use one of these tools or APIs toocreate data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="58c54-199">Azure Portal</span><span class="sxs-lookup"><span data-stu-id="58c54-199">Azure portal</span></span>
- <span data-ttu-id="58c54-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="58c54-200">Visual Studio</span></span>
- <span data-ttu-id="58c54-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="58c54-201">PowerShell</span></span>
- <span data-ttu-id="58c54-202">.NET API</span><span class="sxs-lookup"><span data-stu-id="58c54-202">.NET API</span></span>
- <span data-ttu-id="58c54-203">REST API</span><span class="sxs-lookup"><span data-stu-id="58c54-203">REST API</span></span>
- <span data-ttu-id="58c54-204">Azure Resource Manager-sjabloon.</span><span class="sxs-lookup"><span data-stu-id="58c54-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="58c54-205">toolearn hoe toobuild data Factory met gegevens pijplijnen, volg de stapsgewijze instructies in de volgende zelfstudies Hallo:</span><span class="sxs-lookup"><span data-stu-id="58c54-205">toolearn how toobuild data factories with data pipelines, follow step-by-step instructions in hello following tutorials:</span></span>

| <span data-ttu-id="58c54-206">Zelfstudie</span><span class="sxs-lookup"><span data-stu-id="58c54-206">Tutorial</span></span> | <span data-ttu-id="58c54-207">Beschrijving</span><span class="sxs-lookup"><span data-stu-id="58c54-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="58c54-208">Gegevens verplaatsen tussen twee cloudlocaties voor gegevensopslag</span><span class="sxs-lookup"><span data-stu-id="58c54-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="58c54-209">In deze zelfstudie maakt u een gegevensfactory maken met een pipeline die **gegevens verplaatst** uit Blob storage tooSQL database.</span><span class="sxs-lookup"><span data-stu-id="58c54-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage tooSQL database.</span></span> |
| [<span data-ttu-id="58c54-210">Gegevens transformeren met een Hadoop-cluster</span><span class="sxs-lookup"><span data-stu-id="58c54-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="58c54-211">In deze zelfstudie bouwt u uw eerste Azure-gegevensfactory met een gegevenspijplijn die **gegevens verwerkt** door Hive-script uit te voeren op een Azure HDInsight-cluster (Hadoop).</span><span class="sxs-lookup"><span data-stu-id="58c54-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="58c54-212">Gegevens verplaatsen tussen een on-premises gegevensopslag en een gegevensarchief in de cloud met behulp van Data Management Gateway</span><span class="sxs-lookup"><span data-stu-id="58c54-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="58c54-213">In deze zelfstudie maakt u een gegevensfactory bouwen met een pipeline die **gegevens verplaatst** van een **lokale** SQL Server-database tooan Azure-blob.</span><span class="sxs-lookup"><span data-stu-id="58c54-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database tooan Azure blob.</span></span> <span data-ttu-id="58c54-214">Als onderdeel van het Hallo-scenario, installeren en configureren Hallo Data Management Gateway op uw computer.</span><span class="sxs-lookup"><span data-stu-id="58c54-214">As part of hello walkthrough, you install and configure hello Data Management Gateway on your machine.</span></span> |
